{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from utils import ROOT_DIR, RAW_FILES, NEURONS_302, VALID_DATASETS, MATLAB_FILES\n",
    "import torch\n",
    "import logging\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.linalg import solve\n",
    "from typing import Tuple, Union\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "processed_path = os.path.join(ROOT_DIR, \"data/processed/neural\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Define the log message format\n",
    "    datefmt='%d-%b-%y %H:%M:%S',  # Define the date/time format\n",
    "    filename= ROOT_DIR+\"/logs/execution/preprocess_notebook.log\",  # Specify the log file (optional)\n",
    "    filemode='w'  # Set the file mode (optional, default is 'a' for appending)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffTVR:\n",
    "    def __init__(self, n: int, dx: float):\n",
    "        \"\"\"Initialize DiffTVR class to differentiate with TVR.\n",
    "\n",
    "        Args:\n",
    "            n (int): Number of points in data.\n",
    "            dx (float): Spacing of data.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.dx = dx\n",
    "\n",
    "        self.d_mat = self._make_d_mat()\n",
    "        self.a_mat = self._make_a_mat()\n",
    "        self.a_mat_t = self._make_a_mat_t()\n",
    "\n",
    "    def _make_d_mat(self) -> np.array:\n",
    "        \"\"\"Construct differentiation matrix using central differences.\n",
    "\n",
    "        Note:\n",
    "            This method is not efficient.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Differentiation matrix of shape (N, N+1)\n",
    "        \"\"\"\n",
    "        arr = np.zeros((self.n, self.n + 1))\n",
    "        for i in range(0, self.n):\n",
    "            arr[i, i] = -1.0\n",
    "            arr[i, i + 1] = 1.0\n",
    "        return arr / self.dx\n",
    "\n",
    "    def _make_a_mat(self) -> np.array:\n",
    "        \"\"\"Construct integration matrix using trapezoidal rule.\n",
    "\n",
    "        Note:\n",
    "            This method is not efficient.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Integration matrix of shape (N, N+1)\n",
    "        \"\"\"\n",
    "        arr = np.zeros((self.n + 1, self.n + 1))\n",
    "        for i in range(0, self.n + 1):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            for j in range(0, self.n + 1):\n",
    "                if j == 0:\n",
    "                    arr[i, j] = 0.5\n",
    "                elif j < i:\n",
    "                    arr[i, j] = 1.0\n",
    "                elif i == j:\n",
    "                    arr[i, j] = 0.5\n",
    "\n",
    "        return arr[1:] * self.dx\n",
    "\n",
    "    def _make_a_mat_t(self) -> np.array:\n",
    "        \"\"\"Construct transpose of the integration matrix using trapezoidal rule.\n",
    "\n",
    "        Note:\n",
    "            This method is not efficient.\n",
    "\n",
    "        Returns:\n",
    "            np.array: Transpose of the integration matrix of shape (N+1, N)\n",
    "        \"\"\"\n",
    "        smat = np.ones((self.n + 1, self.n))\n",
    "\n",
    "        cmat = np.zeros((self.n, self.n))\n",
    "        li = np.tril_indices(self.n)\n",
    "        cmat[li] = 1.0\n",
    "\n",
    "        dmat = np.diag(np.full(self.n, 0.5))\n",
    "\n",
    "        vec = np.array([np.full(self.n, 0.5)])\n",
    "        combmat = np.concatenate((vec, cmat - dmat))\n",
    "\n",
    "        return (smat - combmat) * self.dx\n",
    "\n",
    "    def make_en_mat(self, deriv_curr: np.array) -> np.array:\n",
    "        \"\"\"Create diffusion matrix.\n",
    "\n",
    "        Args:\n",
    "            deriv_curr (np.array): Current derivative of length N+1\n",
    "\n",
    "        Returns:\n",
    "            np.array: Diffusion matrix of shape (N, N)\n",
    "        \"\"\"\n",
    "        eps = pow(10, -6)\n",
    "        vec = 1.0 / np.sqrt(pow(self.d_mat @ deriv_curr, 2) + eps)\n",
    "        return np.diag(vec)\n",
    "\n",
    "    def make_ln_mat(self, en_mat: np.array) -> np.array:\n",
    "        \"\"\"Calculate diffusivity term.\n",
    "\n",
    "        Args:\n",
    "            en_mat (np.array): Result from make_en_mat\n",
    "\n",
    "        Returns:\n",
    "            np.array: Diffusivity term of shape (N+1, N+1)\n",
    "        \"\"\"\n",
    "        return self.dx * np.transpose(self.d_mat) @ en_mat @ self.d_mat\n",
    "\n",
    "    def make_gn_vec(\n",
    "        self,\n",
    "        deriv_curr: np.array,\n",
    "        data: np.array,\n",
    "        alpha: float,\n",
    "        ln_mat: np.array,\n",
    "    ) -> np.array:\n",
    "        \"\"\"Calculate the negative right hand side of the linear problem.\n",
    "\n",
    "        Args:\n",
    "            deriv_curr (np.array): Current derivative of size N+1\n",
    "            data (np.array): Data of size N\n",
    "            alpha (float): Regularization parameter\n",
    "            ln_mat (np.array): Diffusivity term from make_ln_mat\n",
    "\n",
    "        Returns:\n",
    "            np.array: Vector of length N+1\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.a_mat_t @ self.a_mat @ deriv_curr\n",
    "            - self.a_mat_t @ (data - data[0])\n",
    "            + alpha * ln_mat @ deriv_curr\n",
    "        )\n",
    "\n",
    "    def make_hn_mat(self, alpha: float, ln_mat: np.array) -> np.array:\n",
    "        \"\"\"Construct matrix in linear problem.\n",
    "\n",
    "        Args:\n",
    "            alpha (float): Regularization parameter\n",
    "            ln_mat (np.array): Diffusivity term from make_ln_mat\n",
    "\n",
    "        Returns:\n",
    "            np.array: Matrix of shape (N+1, N+1)\n",
    "        \"\"\"\n",
    "        return self.a_mat_t @ self.a_mat + alpha * ln_mat\n",
    "\n",
    "    def get_deriv_tvr_update(\n",
    "        self,\n",
    "        data: np.array,\n",
    "        deriv_curr: np.array,\n",
    "        alpha: float,\n",
    "    ) -> np.array:\n",
    "        \"\"\"Compute the TVR update.\n",
    "\n",
    "        Args:\n",
    "            data (np.array): Data of size N\n",
    "            deriv_curr (np.array): Current derivative of size N+1\n",
    "            alpha (float): Regularization parameter\n",
    "\n",
    "        Returns:\n",
    "            np.array: Update vector of size N+1\n",
    "        \"\"\"\n",
    "        n = len(data)\n",
    "\n",
    "        en_mat = self.make_en_mat(deriv_curr=deriv_curr)\n",
    "\n",
    "        ln_mat = self.make_ln_mat(en_mat=en_mat)\n",
    "\n",
    "        hn_mat = self.make_hn_mat(alpha=alpha, ln_mat=ln_mat)\n",
    "\n",
    "        gn_vec = self.make_gn_vec(\n",
    "            deriv_curr=deriv_curr, data=data, alpha=alpha, ln_mat=ln_mat\n",
    "        )\n",
    "\n",
    "        return solve(hn_mat, -gn_vec)\n",
    "\n",
    "    def get_deriv_tvr(\n",
    "        self,\n",
    "        data: np.array,\n",
    "        deriv_guess: np.array,\n",
    "        alpha: float,\n",
    "        no_opt_steps: int,\n",
    "        return_progress: bool = False,\n",
    "        return_interval: int = 1,\n",
    "    ) -> Tuple[np.array, np.array]:\n",
    "        \"\"\"Compute derivative using TVR over optimization steps.\n",
    "\n",
    "        Args:\n",
    "            data (np.array): Data of size N\n",
    "            deriv_guess (np.array): Guess for derivative of size N+1\n",
    "            alpha (float): Regularization parameter\n",
    "            no_opt_steps (int): Number of optimization steps to run\n",
    "            return_progress (bool, optional): If True, return derivative progress during optimization.\n",
    "                                              Defaults to False.\n",
    "            return_interval (int, optional): Interval at which to store derivative if returning progress.\n",
    "                                              Defaults to 1.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[np.array,np.array]: First element is the final derivative of size N+1, second element is\n",
    "                                      the stored derivatives if return_progress=True of shape\n",
    "                                      (no_opt_steps+1, N+1), else an empty array.\n",
    "        \"\"\"\n",
    "        deriv_curr = deriv_guess\n",
    "\n",
    "        if return_progress:\n",
    "            deriv_st = np.full((no_opt_steps + 1, len(deriv_guess)), 0)\n",
    "        else:\n",
    "            deriv_st = np.array([])\n",
    "\n",
    "        for opt_step in range(0, no_opt_steps):\n",
    "            update = self.get_deriv_tvr_update(\n",
    "                data=data, deriv_curr=deriv_curr, alpha=alpha\n",
    "            )\n",
    "\n",
    "            deriv_curr += update\n",
    "\n",
    "            if return_progress:\n",
    "                if opt_step % return_interval == 0:\n",
    "                    deriv_st[int(opt_step / return_interval)] = deriv_curr\n",
    "\n",
    "        return (deriv_curr, deriv_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = MinMaxScaler(feature_range=(-1,1))\n",
    "smooth_method = 'fft'\n",
    "resample_dt = .1\n",
    "norm_dim = 'neurons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessDataset:\n",
    "    \"\"\"Preprocesses the data for a given dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, transform, smooth_method, resample_dt, norm_dim):\n",
    "        # Saving the arguments\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.resample_dt = resample_dt\n",
    "\n",
    "        assert smooth_method.lower() in ['fft', 'sg', 'tvr'], \\\n",
    "            \"Invalid smooth_method! Please pick one from: ['fft', 'sg', 'tvr']\"\n",
    "        self.smooth_method = smooth_method.lower()\n",
    "\n",
    "        assert norm_dim.lower() in ['neurons', 'time'], \\\n",
    "            \"Invalid norm_dim! Please pick one from: ['neurons', 'time']\" \n",
    "        self.norm_dim = norm_dim.lower()\n",
    "\n",
    "        self.all_raw_data = {}\n",
    "\n",
    "    def get_files_and_features(self):\n",
    "        # Verify if the dataset is valid\n",
    "        assert (self.dataset in VALID_DATASETS\n",
    "        ), \"Invalid dataset requested! Please pick one from:\\n{}\".format(\n",
    "            list(VALID_DATASETS)\n",
    "        )\n",
    "\n",
    "        matfiles = MATLAB_FILES[self.dataset][0]\n",
    "        features = MATLAB_FILES[self.dataset][1]\n",
    "\n",
    "        return matfiles, features\n",
    "    \n",
    "    def load_mat(self):\n",
    "        \"\"\"Load all the .mat files of a given dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : str\n",
    "            Name of the dataset to be loaded.\n",
    "            Options are {Kato2015, Nichols2017, Skora2018, Kaplan2020,\n",
    "                         Uzel2022}\n",
    "        matlabfiles : list\n",
    "            List containing the names of the .mat files to be loaded.\n",
    "            Don't include the .mat extension in the names.\n",
    "        features : list\n",
    "            List containing the dictionaries with the arguments corresponding\n",
    "            to each .mat file.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        data : dict\n",
    "            Dictionary containing the loaded data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the files and features for the dataset\n",
    "        matfiles, features = self.get_files_and_features()\n",
    "\n",
    "        # Load the data and save in a dict. The keys are the .mat files names\n",
    "\n",
    "        for i, matf in enumerate(matfiles):\n",
    "            \n",
    "            ft = features[i] # Get the features for this file\n",
    "\n",
    "            raw_data = mat73.loadmat(os.path.join(ROOT_DIR, 'opensource_data', self.dataset, matf+'.mat'))[matf] # Get raw data (dict)\n",
    "            #logging.info(\"{} - Raw keys ({}) = {}\".format(self.dataset+'/'+matf, matf, list(raw_data.keys())))\n",
    "\n",
    "            # Extract relevant data (all worms)\n",
    "            all_IDs = raw_data[ft['ids']]  # Identified neuron IDs (only subset have neuron names) # (num_worms, id_len:vary)\n",
    "            all_traces = raw_data[ft['traces']]  # Neural activity traces corrected for bleaching (worms) # (num_worms, traces:vary)\n",
    "            timeVectorSeconds = raw_data[ft['tv']] # (num_worms, traces:vary)\n",
    "            #logging.info(\"{} - Num. worms ({}) = {}\".format(self.dataset+'/'+matf, matf, len(all_IDs)))\n",
    "\n",
    "            self.all_raw_data[matf] = {\n",
    "                'ids': all_IDs,\n",
    "                'traces': all_traces,\n",
    "                'tvs': timeVectorSeconds\n",
    "            }\n",
    "\n",
    "            logging.info(\"{}/{} loaded.\".format(self.dataset, matf))\n",
    "\n",
    "    def _pick_non_none(self, l):\n",
    "        \"\"\"Returns the first non-None element in a list (l).\n",
    "        \"\"\"\n",
    "        for i in range(len(l)):\n",
    "            if l[i] is not None:\n",
    "                return l[i]\n",
    "\n",
    "    def find_unique(self, ids, calcium_data):\n",
    "        \"\"\"Makes a mapping between the neuron IDs and their indices.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ids : list\n",
    "            List containing the neuron IDs of a single worm.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        idx : list\n",
    "            List containing the indices of the unique neurons of this worm.\n",
    "        neuron_to_idx : dict\n",
    "            Dictionary mapping the neuron IDs to their indices.\n",
    "        \"\"\"\n",
    "\n",
    "        # Pre-processing the neuron IDs\n",
    "        ids = [\n",
    "            (str(_) if j is None or isinstance(j, np.ndarray) else str(j))\n",
    "            for _, j in enumerate(ids)\n",
    "        ] # Position on the list or name of the neuron\n",
    "\n",
    "        _, idx = np.unique(\n",
    "            ids, return_index=True\n",
    "        ) # Get unique neurons and their indices\n",
    "\n",
    "        ids = [ids[_] for _ in idx]  # Only keep unique neuron IDs\n",
    "        calcium_data = calcium_data[:, idx.astype(int)]  # Only get data for unique neurons\n",
    "\n",
    "        # Mapping unique neuron IDs to indices\n",
    "        neuron_to_idx = {\n",
    "            nid: (str(nid) if (j is None or isinstance(j, np.ndarray)) else str(j))\n",
    "            for nid, j in enumerate(ids)\n",
    "        } # Unlabeled neurons are given their index as name, labeled neurons are given their name\n",
    "\n",
    "        # Format the neuron names if it finishes with 0\n",
    "        neuron_to_idx = {\n",
    "            nid: (\n",
    "                name.replace(\"0\", \"\")\n",
    "                if not name.endswith(\"0\") and not name.isnumeric()\n",
    "                else name\n",
    "            )\n",
    "            for nid, name in neuron_to_idx.items()\n",
    "        }\n",
    "\n",
    "        # Invert the mapping\n",
    "        neuron_to_idx = dict(\n",
    "            (v, k) for k, v in neuron_to_idx.items()\n",
    "        )\n",
    "\n",
    "        return ids, calcium_data, neuron_to_idx\n",
    "    \n",
    "    def apply_transform(self, calcium_data):\n",
    "        \"\"\"Applies the transform to the calcium data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        calcium_data : np.ndarray\n",
    "            Calcium data to be transformed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        calcium_data : np.ndarray\n",
    "            Transformed calcium data.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.norm_dim == 'neurons':\n",
    "            calcium_data = self.transform.fit_transform(calcium_data)\n",
    "            calcium_data = torch.tensor(calcium_data, dtype=torch.float32)\n",
    "        elif self.norm_dim == 'time':\n",
    "            calcium_data = self.transform.fit_transform(calcium_data.T).T\n",
    "            calcium_data = torch.tensor(calcium_data, dtype=torch.float32)\n",
    "\n",
    "        return calcium_data\n",
    "    \n",
    "    def interpolate_data(self, time, data):\n",
    "        \"\"\"Interpolate data using np.interp, with support for torch.Tensor.\n",
    "\n",
    "        This function takes the given time points and corresponding data and\n",
    "        interpolates them to create new data points with the desired time \n",
    "        interval. The input tensors are first converted to NumPy arrays for \n",
    "        interpolation, and the interpolated data and time points are then \n",
    "        converted back to torch.Tensor objects before being returned.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        time : torch.Tensor\n",
    "            1D tensor containing the time points corresponding to the data.\n",
    "        data : torch.Tensor\n",
    "            A 2D tensor containing the data to be interpolated, with shape\n",
    "            (time, neurons).\n",
    "        target_dt : float\n",
    "            The desired time interval between the interpolated data points.\n",
    "            If None, no interpolation is performed.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor, torch.Tensor:\n",
    "            Two tensors containing the interpolated time points and data.\n",
    "        \"\"\"\n",
    "\n",
    "        # If target_dt is None, return the original data\n",
    "        if self.resample_dt is None:\n",
    "            return time, data\n",
    "\n",
    "        # Convert input tensors to NumPy arrays\n",
    "        time_np = time.squeeze().numpy()\n",
    "        data_np = data.numpy()\n",
    "\n",
    "        # Interpolate the data\n",
    "        target_time_np = np.arange(time_np.min(), time_np.max(), self.resample_dt)\n",
    "        num_neurons = data_np.shape[1]\n",
    "        interpolated_data_np = np.zeros((len(target_time_np), num_neurons))\n",
    "\n",
    "        for i in range(num_neurons):\n",
    "            interpolated_data_np[:, i] = np.interp(target_time_np, time_np, data_np[:, i])\n",
    "\n",
    "        # Convert the interpolated data and time back to torch.Tensor objects\n",
    "        target_time = torch.from_numpy(target_time_np).to(torch.float32).unsqueeze(-1)\n",
    "        interpolated_data = torch.from_numpy(interpolated_data_np).to(torch.float32)\n",
    "\n",
    "        return target_time, interpolated_data\n",
    "\n",
    "    def smooth_data_preprocess(self, calcium_data, smooth_method):\n",
    "        \"\"\"Smooth the calcium data. Returns the denoised signals calcium signals using FFT.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            calcium_data: tensor\n",
    "                Raw calcium imaging data to smooth\n",
    "            smooth_method: str\n",
    "                Method to use for smoothing.\n",
    "                Options are 'sg' for Savitzky-Golay, 'fft' for FFT, or 'tvr' for \n",
    "                Total Variation Denoising.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            smooth_ca_data: tensor\n",
    "                Smoothed calcium data\n",
    "            residual: tensor\n",
    "                Residual from the original data (calcium_data)\n",
    "            residual_smooth_ca_data: tensor\n",
    "                Residual from the smoothed data (smooth_ca_data)\n",
    "        \"\"\"\n",
    "\n",
    "        # Number of time steps\n",
    "        n = calcium_data.shape[0]\n",
    "\n",
    "        # Initialize the size for smooth_calcium_data\n",
    "        smooth_ca_data = torch.zeros_like(calcium_data)\n",
    "\n",
    "        # Calculate original residual\n",
    "        residual = torch.zeros_like(calcium_data)\n",
    "        residual[1:] = calcium_data[1:] - calcium_data[: n - 1]\n",
    "\n",
    "        # Savitzky-Golay method\n",
    "        if str(smooth_method).lower() == \"sg\" or smooth_method == None:\n",
    "            smooth_ca_data = savgol_filter(calcium_data, 5, 3, mode=\"nearest\", axis=-1)\n",
    "\n",
    "        # FFT method\n",
    "        elif str(smooth_method).lower() == \"fft\":\n",
    "            data_torch = calcium_data\n",
    "            smooth_ca_data = torch.zeros_like(calcium_data)\n",
    "            max_timesteps, num_neurons = data_torch.shape\n",
    "            frequencies = torch.fft.rfftfreq(max_timesteps, d=self.resample_dt)  # dt: sampling time\n",
    "            threshold = torch.abs(frequencies)[int(frequencies.shape[0] * 0.1)]\n",
    "            oneD_kernel = torch.abs(frequencies) < threshold\n",
    "            fft_input = torch.fft.rfftn(data_torch, dim=0)\n",
    "            oneD_kernel = oneD_kernel.repeat(calcium_data.shape[1], 1).T\n",
    "            fft_result = torch.fft.irfftn(fft_input * oneD_kernel, dim=0)\n",
    "            smooth_ca_data[0 : min(fft_result.shape[0], calcium_data.shape[0])] = fft_result\n",
    "\n",
    "        # TVR method\n",
    "        elif str(smooth_method).lower() == \"tvr\":\n",
    "            diff_tvr = DiffTVR(n, 1)\n",
    "            for i in range(0, calcium_data.shape[1]):\n",
    "                temp = np.array(calcium_data[:, i])\n",
    "                temp.reshape(len(temp), 1)\n",
    "                (item_denoise, _) = diff_tvr.get_deriv_tvr(\n",
    "                    data=temp,\n",
    "                    deriv_guess=np.full(n + 1, 0.0),\n",
    "                    alpha=0.005,\n",
    "                    no_opt_steps=100,\n",
    "                )\n",
    "                smooth_ca_data[:, i] = torch.tensor(item_denoise[: (len(item_denoise) - 1)])\n",
    "\n",
    "        m = smooth_ca_data.shape[0]\n",
    "        residual_smooth_ca_data = torch.zeros_like(residual)\n",
    "        residual_smooth_ca_data[1:] = smooth_ca_data[1:] - smooth_ca_data[: m - 1]\n",
    "\n",
    "        return smooth_ca_data, residual, residual_smooth_ca_data\n",
    "\n",
    "    def update_non_std_dict(self, data_dict, worm, calcium_data, smooth_calcium_data,\n",
    "                            residual, smooth_residual, neuron_to_idx,\n",
    "                            time_in_seconds, num_named):\n",
    "        data_dict.update(\n",
    "                    {\n",
    "                        worm: {\n",
    "                            \"dataset\": self.dataset,\n",
    "                            \"smooth_method\": self.smooth_method.upper(),\n",
    "                            # \"worm\": worm,\n",
    "                            \"calcium_data\": calcium_data,\n",
    "                            \"smooth_calcium_data\": smooth_calcium_data,\n",
    "                            \"residual_calcium\": residual,\n",
    "                            \"smooth_residual_calcium\": smooth_residual,\n",
    "                            \"neuron_to_idx\": neuron_to_idx,\n",
    "                            \"idx_to_neuron\": dict((v, k) for k, v in neuron_to_idx.items()),\n",
    "                            \"max_timesteps\": calcium_data.shape[0],\n",
    "                            \"time_in_seconds\": time_in_seconds,\n",
    "                            \"dt\": self.resample_dt,\n",
    "                            \"num_neurons\": calcium_data.shape[1],\n",
    "                            \"num_named_neurons\": num_named,\n",
    "                            \"num_unknown_neurons\": calcium_data.shape[1] - num_named,\n",
    "                        },\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    def reshape_calcium_data(self, single_worm_dataset):\n",
    "        \"\"\"Standardizes the calcium data to a (max_timesteps, 302) shape.\n",
    "        \n",
    "        Inserts neuron masks and mappings of neuron labels to indices in the data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        single_worm_dataset : dict\n",
    "            Dictionary containing the calcium data for a single worm.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        single_worm_dataset : dict\n",
    "            Dictionary containing the reshaped dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the calcium data for this worm\n",
    "        origin_calcium_data = single_worm_dataset[\"calcium_data\"]\n",
    "        smooth_calcium_data = single_worm_dataset[\"smooth_calcium_data\"]\n",
    "        residual_calcium = single_worm_dataset[\"residual_calcium\"]\n",
    "        smooth_residual_calcium = single_worm_dataset[\"smooth_residual_calcium\"]\n",
    "\n",
    "        # Get the number of unidentified tracked neurons\n",
    "        num_unknown_neurons = single_worm_dataset[\"num_unknown_neurons\"]\n",
    "\n",
    "        # Get the neuron to idx map of this worm\n",
    "        neuron_to_idx = single_worm_dataset[\"neuron_to_idx\"]\n",
    "        idx_to_neuron = single_worm_dataset[\"idx_to_neuron\"]\n",
    "\n",
    "        # Get the length of the time series\n",
    "        max_timesteps = single_worm_dataset[\"max_timesteps\"]\n",
    "\n",
    "        # Load names of all 302 neurons\n",
    "        neurons_302 = NEURONS_302\n",
    "\n",
    "        # Check the calcium data\n",
    "        assert len(idx_to_neuron) == origin_calcium_data.size(\n",
    "            1\n",
    "        ), \"Number of neurons in calcium dataset does not match number of recorded neurons.\"\n",
    "\n",
    "        # Create new maps of neurons to indices\n",
    "        named_neuron_to_idx = dict()\n",
    "        unknown_neuron_to_idx = dict()\n",
    "\n",
    "        # Create masks of which neurons have data\n",
    "        named_neurons_mask = torch.zeros(302, dtype=torch.bool)\n",
    "        unknown_neurons_mask = torch.zeros(302, dtype=torch.bool)\n",
    "\n",
    "        # Create the new calcium data structure\n",
    "        # len(residual) = len(data) - 1\n",
    "        standard_calcium_data = torch.zeros(\n",
    "            max_timesteps, 302, dtype=origin_calcium_data.dtype\n",
    "        )\n",
    "        standard_residual_calcium = torch.zeros(\n",
    "            max_timesteps, 302, dtype=residual_calcium.dtype\n",
    "        )\n",
    "        standard_smooth_calcium_data = torch.zeros(\n",
    "            max_timesteps, 302, dtype=smooth_calcium_data.dtype\n",
    "        )\n",
    "        standard_residual_smooth_calcium = torch.zeros(\n",
    "            max_timesteps, 302, dtype=smooth_residual_calcium.dtype\n",
    "        )\n",
    "\n",
    "        # Fill the new calcium data structure with data from named neurons\n",
    "        slot_to_named_neuron = dict((k, v) for k, v in enumerate(neurons_302))\n",
    "\n",
    "        for slot, neuron in slot_to_named_neuron.items():\n",
    "            if neuron in neuron_to_idx:\n",
    "                # If named neuron is in the dataset\n",
    "                idx = neuron_to_idx[neuron] # Extract its position in the dataset\n",
    "                named_neuron_to_idx[neuron] = idx # Include it in the named neuron map\n",
    "\n",
    "                # Add its data in the neuron standard position\n",
    "                standard_calcium_data[:, slot] = origin_calcium_data[:, idx]\n",
    "                standard_residual_calcium[:, slot] = residual_calcium[:, idx] \n",
    "                standard_smooth_calcium_data[:, slot] = smooth_calcium_data[:, idx]\n",
    "                standard_residual_smooth_calcium[:, slot] = smooth_residual_calcium[:, idx]\n",
    "                named_neurons_mask[slot] = True # Mask the named neuron as having data\n",
    "\n",
    "        # Randomly distribute the remaining data from unknown neurons\n",
    "        for neuron in set(neuron_to_idx) - set(named_neuron_to_idx):\n",
    "            unknown_neuron_to_idx[neuron] = neuron_to_idx[neuron]\n",
    "        free_slots = list(np.where(~named_neurons_mask)[0])\n",
    "\n",
    "        slot_to_unknown_neuron = dict(\n",
    "            zip(\n",
    "                np.random.choice(free_slots, num_unknown_neurons, replace=False).tolist(),\n",
    "                list(unknown_neuron_to_idx.keys()),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        for slot, neuron in slot_to_unknown_neuron.items():\n",
    "            idx = unknown_neuron_to_idx[neuron]\n",
    "            standard_calcium_data[:, slot] = origin_calcium_data[:, idx]\n",
    "            standard_residual_calcium[:, slot] = residual_calcium[:, idx]\n",
    "            standard_smooth_calcium_data[:, slot] = smooth_calcium_data[:, idx]\n",
    "            standard_residual_smooth_calcium[:, slot] = smooth_residual_calcium[:, idx]\n",
    "            unknown_neurons_mask[slot] = True\n",
    "\n",
    "        # Combined slot to neuron mapping\n",
    "        slot_to_neuron = dict()\n",
    "        slot_to_neuron.update(slot_to_named_neuron)\n",
    "        slot_to_neuron.update(slot_to_unknown_neuron)\n",
    "\n",
    "        # Modify the worm dataset to with new attributes\n",
    "        single_worm_dataset.update(\n",
    "            {\n",
    "                \"calcium_data\": standard_calcium_data,\n",
    "                \"smooth_calcium_data\": standard_smooth_calcium_data,\n",
    "                \"residual_calcium\": standard_residual_calcium,\n",
    "                \"smooth_residual_calcium\": standard_residual_smooth_calcium,\n",
    "                \"named_neurons_mask\": named_neurons_mask,\n",
    "                \"unknown_neurons_mask\": unknown_neurons_mask,\n",
    "                \"neurons_mask\": named_neurons_mask | unknown_neurons_mask,\n",
    "                \"named_neuron_to_idx\": named_neuron_to_idx,\n",
    "                \"idx_to_named_neuron\": dict((v, k) for k, v in named_neuron_to_idx.items()),\n",
    "                \"unknown_neuron_to_idx\": unknown_neuron_to_idx,\n",
    "                \"idx_to_unknown_neuron\": dict(\n",
    "                    (v, k) for k, v in unknown_neuron_to_idx.items()\n",
    "                ),\n",
    "                \"slot_to_named_neuron\": slot_to_named_neuron,\n",
    "                \"named_neuron_to_slot\": dict(\n",
    "                    (v, k) for k, v in slot_to_named_neuron.items()\n",
    "                ),\n",
    "                \"slot_to_unknown_neuron\": slot_to_unknown_neuron,\n",
    "                \"unknown_neuron_to_slot\": dict(\n",
    "                    (v, k) for k, v in slot_to_unknown_neuron.items()\n",
    "                ),\n",
    "                \"slot_to_neuron\": slot_to_neuron,\n",
    "                \"neuron_to_slot\": dict((v, k) for k, v in slot_to_neuron.items()),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Delete all original index mappings\n",
    "        keys_to_delete = [key for key in single_worm_dataset if \"idx\" in key]\n",
    "        for key in keys_to_delete:\n",
    "            single_worm_dataset.pop(key, None)\n",
    "\n",
    "        # Return the dataset for this worm\n",
    "        return single_worm_dataset\n",
    "\n",
    "    def preprocess_pipeline(self):\n",
    "        \"\"\"Preprocesses the data for each worm in the all_raw_data.\n",
    "        \"\"\"\n",
    "\n",
    "        # Load the data\n",
    "        self.load_mat()\n",
    "\n",
    "        # Auxiliar variables\n",
    "        worm_counter = -1\n",
    "        data_dict = dict()\n",
    "\n",
    "        # Iterate over the .mat files\n",
    "        for matf, data in self.all_raw_data.items():\n",
    "            \n",
    "            # Iterate over worms\n",
    "            for i, calcium_data in enumerate(data['traces']):\n",
    "\n",
    "                worm_counter += 1\n",
    "                worm = \"worm\" + str(worm_counter) # Worm name\n",
    "\n",
    "                # Get the IDs of the i-th worm in the file\n",
    "                ids = [(self._pick_non_none(j) if isinstance(j, list) else j) for j in data['ids'][i]]\n",
    "\n",
    "                # idx = unique neurons indices, neuron_to_idx = mapping from neuron to index\n",
    "                ids, calcium_data, neuron_to_idx = self.find_unique(ids, calcium_data)\n",
    "\n",
    "                # Retrieve the number of neurons that were labeled\n",
    "                num_named = len(\n",
    "                    [k for k in neuron_to_idx.keys() if not k.isnumeric()]\n",
    "                )\n",
    "\n",
    "                # Reshape time into a column vector and convert to tensor\n",
    "                time_in_seconds = data['tvs'][i].reshape(data['tvs'][i].shape[0], 1)\n",
    "                time_in_seconds = torch.tensor(time_in_seconds).to(torch.float32)\n",
    "\n",
    "                # Apply the transformation to the data\n",
    "                calcium_data = self.apply_transform(calcium_data)\n",
    "\n",
    "                # Resample the data to a fixed time step\n",
    "                time_in_seconds, calcium_data = self.interpolate_data(time_in_seconds, calcium_data)\n",
    "\n",
    "                # Calculate the time step\n",
    "                dt = torch.zeros_like(time_in_seconds).to(torch.float32)\n",
    "                dt[1:] = time_in_seconds[1:] - time_in_seconds[:-1]\n",
    "\n",
    "                # Smooth the data\n",
    "                smooth_calcium_data, residual, smooth_residual = self.smooth_data_preprocess(\n",
    "                    calcium_data, smooth_method\n",
    "                )\n",
    "\n",
    "                # Update the data\n",
    "                self.update_non_std_dict(data_dict, worm, calcium_data, smooth_calcium_data,\n",
    "                                            residual, smooth_residual, neuron_to_idx,\n",
    "                                            time_in_seconds, num_named)\n",
    "                \n",
    "                # Standardize the shape of calcium data to (max_timesteps, num_neurons=302)\n",
    "                data_dict[worm] = self.reshape_calcium_data(data_dict[worm])\n",
    "\n",
    "                logging.info('{}/{} - {} done. \\tLabeled {},\\tUnlabeled {},\\tCa shape ({},{})'.format(\n",
    "                    self.dataset, matf, worm, num_named, len(data_dict[worm]['slot_to_unknown_neuron']),\n",
    "                    data_dict[worm]['calcium_data'].shape[0], data_dict[worm]['calcium_data'].shape[1]))\n",
    "\n",
    "        # Pickle the data\n",
    "        file = os.path.join(processed_path, self.dataset+'.pickle')\n",
    "        pickle_out = open(file, \"wb\")\n",
    "        pickle.dump(data_dict, pickle_out)\n",
    "        pickle_out.close()\n",
    "        logging.info('{} saved into /data/processed/neural/{}.pickle'.format(\n",
    "                    self.dataset, self.dataset))\n",
    "        return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['Uzel2022', 'Skora2018', 'Nichols2017', 'Kato2015', 'Kaplan2020']\n",
    "\n",
    "for ds in datasets:\n",
    "    test = PreprocessDataset(ds, transform, smooth_method, resample_dt, norm_dim)\n",
    "    data = test.preprocess_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
