# @package _global_
defaults:
  - override /submodule: [dataset, model, train, predict, visualize]
  - _self_

hydra:
  mode: MULTIRUN
  sweeper:
  # These parameters will be tested just when MULTIRUN mode is used.
  # Use the submodule parameters if RUN.
      params:
        submodule.train.batch_size: 8, 16, 32, 64, 128

submodule:

  dataset:
    # Combined and validation datasets provided
    #  - Train: all worms (245) with all named neurons (num_train_samples=16, seq_len=60)
    #  - Validation: all worms (245) with all named neurons (num_val_samples=16, seq_len=60)
    use_these_datasets: /om2/user/lrvenan/worm-graph/data/standard_datasets/batch_size_old_exp

    # Won't be used, because Combined dataset is provided
    experimental_datasets: [Kato2015, Nichols2017, Skora2018, Uzel2022, Kaplan2020, Flavell2023, Leifer2023] 
    num_named_neurons: all
    num_worms: all
    k_splits: 2
    num_train_samples: 16
    num_val_samples: 16
    seq_len: 60
    tau: 1
    smooth_data: true
    reverse: false
    use_residual: false

  model:
    type: NetworkLSTM
    input_size: 302
    hidden_size: 256
    num_layers: 1
    loss: Huber
    fft_reg_param: 0.0
    l1_reg_param: 0.0
    use_this_pretrained_model: null # create fresh model

  train:
    optimizer: Adam
    lr: 0.001
    epochs: 900
    save_freq: 100
    # batch_size: 16 # PARAMETER OF STUDY
    shuffle: true
    early_stopping:
      delta: 0 # minimum change in validation loss to be considered an improvement
      patience: 50 # number of epochs to wait for improvement before stopping

  predict:
    worms_to_predict: [worm0]
    nb_ts_to_generate: null # time steps to generate = seq_len - context_window
    context_window: 30

  visualize:
    plot_figures_from_this_log_dir: null # plot figures of current experiment
    predict:
      worms_to_plot: null # plot all predicted worms (worm0)
      neurons_to_plot: 10 # plot all the neurons


experiment:
  name: batch_size
  mode: MULTIRUN
  seed: 42