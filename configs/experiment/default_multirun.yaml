# @package _global_
defaults:
  - override /submodule: [preprocess, dataset, model, train, predict, analysis, visualize]
  - _self_

hydra:
  # The sweeper params will be used only when MULTIRUN mode is used.
  # Uses the submodule parameters if in RUN mode.
  mode: MULTIRUN
  sweeper:
      params:
        experiment.seed: range(1) # assign each repetition of the experiment a distinct random seed
        submodule.model.type: FeatureFFNN, NetworkLSTM, NeuralTransformer # NeuralCFC, NetworkRNN

# The submodule parameters set below will be used only if RUN mode is used. 
# Otherwise, it uses the default parameters imported from the other config files in the submodule directory.
submodule:

  # Make the train and validation dataset from scratch
  dataset:
    # null = don't use on this dataset
    # all = use all the worms in the dataset
    # <int> = use this number of (randomly picked) worms from the dataset
    # <str> = use this wormID particular worm in the dataset
    # <list> = use the worms with wormIDs in the list
    experimental_datasets:
      Sines0000: null
      Lorenz0000: null
      VanDerPol0000: null
      RandWalk0000: null
      Kato2015: null
      Nichols2017: null
      Skora2018: null
      Uzel2022: null
      Yemini2021: null
      Kaplan2020: null
      Flavell2023: null
      Leifer2023: all

    use_these_datasets:
      # Dataset directory should contain a validation dataset
      path: null # options: null, data/datasets/<DatasetFolder>
      num_worms: null # options: null,  <int>

    save_datasets: false

    num_named_neurons: null
    num_train_samples: 32
    num_val_samples: 16
    seq_len: 100
    reverse: false
    use_residual: false
    smooth_data: true

  # Build model from scratch
  model:
    input_size: 302
    hidden_size: 512
    loss: MSE
    fft_reg_param: 0.0
    l1_reg_param: 0.0
    use_this_pretrained_model: null

  # Train model
  train:
    optimizer: AdamW
    lr: 0.001
    epochs: 500 
    save_freq: 100
    batch_size: 64
    shuffle: true
    reverse: false
    early_stopping:
      delta: 0
      patience: 50

  # Choose the worms that you want to predict 
  predict:
    # null = don't predict on this dataset
    # all = predict all the worms in the dataset
    # <int> = use this number of (randomly picked) worms from the dataset
    # <str> = predict the worm with this particular wormID 
    # <list> = predict the worms with wormIDs in the list
    experimental_datasets:
      Sines0000: null
      Lorenz0000: null
      VanDerPol0000: null
      Kato2015: null
      Nichols2017: null
      Skora2018: null
      Uzel2022: null
      Yemini2021: null
      Kaplan2020: null
      Flavell2023: null
      Leifer2023: worm0
    # Number of time steps to generate 
    # null = generate all remaining time steps (max_timesteps - context_window)
    nb_ts_to_generate: null 
    context_window: 100

  analysis:
    analyse_this_log_dir: null
    # Validate final model using some/all worms from each dataset
    validation:
      # null = don't analyze on this dataset
      # all = analyze all the worms in the dataset
      # <int> = use this number of (randomly picked) worms from the dataset
      # <str> = analyze the worm with this particular wormID 
      # <list> = analyze the worms with wormIDs in the list
      experimental_datasets:
        Sines0000: null
        Lorenz0000: null
        VanDerPol0000: null
        Kato2015: null
        Nichols2017: null
        Skora2018: null
        Uzel2022: null
        Yemini2021: null
        Kaplan2020: null
        Flavell2023: null
        Leifer2023: all

  visualize:
    plot_figures_from_this_log_dir: null
    predict:
      # null = plot all the neurons/worms in the dataset
      # <list> = plot the worms named in the list
      # <int> = plot this number of (randomly picked) worms
      worms_to_plot: null
      neurons_to_plot: 3

experiment:
  # What parameter you are experimenting with (key)
  # Options: num_time_steps, time_steps_per_neuron, num_named_neurons,
  #          num_train_samples, hidden_size, batch_size, seq_len, learn_rate,
  #          model_type, loss_type, optimizer_type, num_parameters,
  #          computation_time, computation_flops
  key: model_type
  mode: MULTIRUN
  seed: null # options: null (random seed), <int>