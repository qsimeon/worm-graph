# @package _global_
# nts = number of time steps
# We increase gradually the quantity of worms from all datasets.
defaults:
  - override /submodule: [preprocess, dataset, model, train, predict, analysis, visualize]
  - _self_

hydra:
  mode: MULTIRUN
  sweeper:
    params:
      submodule.dataset.experimental_datasets: >
        choice([
          "{'Flavell2023': 1}",
          "{'Leifer2023': 1, 'Skora2018': 1}",
          "{'Nichols2017': 1, 'Flavell2023': 2}",
          "{'Kaplan2020': 1, 'Flavell2023': 1, 'Nichols2017': 1, 'Leifer2023': 1}",
          "{'Kato2015': 1, 'Yemini2021': 1, 'Nichols2017': 2, 'Leifer2023': 1}",
          "{'Nichols2017': 2, 'Leifer2023': 4}",
          "{'Leifer2023': 2, 'Yemini2021': 3, 'Kato2015': 1, 'Nichols2017': 1}",
          "{'Leifer2023': 3, 'Kaplan2020': 1, 'Nichols2017': 1, 'Yemini2021': 2, 'Skora2018': 1}",
          "{'Flavell2023': 4, 'Kaplan2020': 1, 'Leifer2023': 3, 'Yemini2021': 1}",
          "{'Flavell2023': 2, 'Leifer2023': 2, 'Kaplan2020': 1, 'Uzel2022': 1, 'Kato2015': 1, 'Yemini2021': 2, 'Nichols2017': 1}",
          "{'Yemini2021': 2, 'Leifer2023': 6, 'Nichols2017': 2, 'Kaplan2020': 1}",
          "{'Leifer2023': 4, 'Nichols2017': 4, 'Yemini2021': 3, 'Flavell2023': 1}"
        ])

submodule:

  dataset:
    # Dataset directory should contain a validation dataset
    use_these_datasets:
      path: null #data/datasets/<DatasetFolder>
      num_worms: null

    save_datasets: false

    experimental_datasets:
      # Sines0000: all
      # Lorenz0000: all
      VanDerPol0000: all
      # Kato2015: all
      # Nichols2017: all
      # Skora2018: all
      # Uzel2022: all
      # Yemini2021: all
      # Kaplan2020: all
      # Flavell2023: all
      # Leifer2023: all

    num_named_neurons: null
    num_train_samples: 32
    num_val_samples: 16
    seq_len: 200
    reverse: false
    use_residual: false
    smooth_data: true

  model:
    # Train model from scratch
    type: LinearNN
    input_size: 302
    hidden_size: 512
    loss: MSE
    fft_reg_param: 0.0
    l1_reg_param: 0.0
    use_this_pretrained_model: null

  train:
    optimizer: AdamW
    lr: 0.001
    epochs: 1 #100
    save_freq: 100
    batch_size: 64
    shuffle: true
    early_stopping:
      # Minimum change in validation loss to be considered an improvement
      delta: 0
      # Number of epochs to wait for improvement before stopping
      patience: 50

  predict:
    # Choose the worms that you want to predict
    experimental_datasets:
      # Sines0000: worm0
      # Lorenz0000: worm0
      VanDerPol0000: worm0
      # Kato2015: worm0
      # Nichols2017: worm0
      # Skora2018: worm0
      # Uzel2022: worm0
      # Yemini2021: worm0
      # Kaplan2020: worm0
      # Flavell2023: worm0
      # Leifer2023: worm0
    # Number of time steps to generate
    nb_ts_to_generate: null
    context_window: 200

  analysis:
    analyse_this_log_dir: null
    # Validate using all worms of each experimental datasets
    validation:
      experimental_datasets:
        # Sines0000: 5
        # Lorenz0000: 5
        VanDerPol0000: 5
        # Kato2015: 5
        # Nichols2017: 5
        # Skora2018: 5
        # Uzel2022: 5
        # Yemini2021: 5
        # Kaplan2020: 5
        # Flavell2023: 5
        # Leifer2023: 5

  visualize:
    plot_figures_from_this_log_dir: null
    predict:
      worms_to_plot: null # number of worms to plot
      neurons_to_plot: 3 # number of neurons to plot

experiment:
  name: nts_linear
  mode: MULTIRUN
  seed: null