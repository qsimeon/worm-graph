preprocess:
  opensource_url: https://www.dropbox.com/scl/fi/vfygz1twi1jg62cfssc0w/opensource_data.zip?rlkey=qa4vpwcoza3k9v5o2watwblth&st=gabi4yqk&dl=1
  opensource_zipfile: opensource_data.zip
  presaved_url: https://www.dropbox.com/scl/fi/baikxamldjyrf5maephk3/presaved_datasets.zip?rlkey=4qrso6forjpvfdbm9mll3ndxf&dl=1
  presaved_file: presaved_datasets.zip
  connectome_pub: all # null or all; otherwise a string indicating which connectome raw data file to use; if null, the default connectome is used
                       # [witvliet_7, witvliet_8, cook_2019, chklovskii, openworm, white_1986_n2u, white_1986_jsh, white_1986_jse, white_1986_whole]
  cleanup: false # Whether to delete the downloaded and unzipped opensource data folder
  source_dataset: all # all; otherwise a string (or list) of dataset(s) in utils.EXPERIMENT_DATASETS
                      # [Kato2015, Nichols2017, Skora2018, Nejatbakhsh2020, Kaplan2020, Yemini2021, Uzel2022, Dag2023, Flavell2023, Leifer2023, Lin2023, Venkatachalam2024]
  resample_dt: 0.333 # The time interval (in seconds) to resample the neural activity at; if null, no resampling is performed
  interpolate: linear # The method to use for interpolation; options: null, linear, quadratic, cubic
  smooth: 
    # Smoothing is done using only causal filters/kernels and is applied prior to resampling.
    method: none # none: No smoothing, # gaussian: Gaussian convolution filter, # exponential: Exponential kernel filter, # moving: Moving average filter
    # Hyperparameters of the different smoothing methods/kernels.
    alpha: 0.5 # exponential; smaller alpha -> smoother; 1 = no smoothing
    sigma: 5 # gaussian; larger sigma -> smoother; 0 = no smoothing
    window_size: 15 # moving; larger window_size -> smoother; 1 = no smoothing