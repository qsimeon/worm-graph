dataset:
  # Path to a directory containing the datasets to be used.
  # If null, create a new dataset in the logs/dataset directory using the experimental_datasets.
  # If not null, and the directory contains train and validation datasets, use them directly.
  # If not null, and the directory contains only the combined dataset, create both train and validation dataset from it.
  # If not null, and the directory contains a combined dataset + train or val. dataset, create the missing dataset using the combined dataset.
  # Specify num_worms to random pick a subset worms from the combined dataset (when a combined dataset is provided).
  use_these_datasets:
    path: null # options: null, data/datasets/<DatasetFolder>
    num_worms: all

  # Whether to save the datasets in the logs/dataset directory.
  save_datasets: false

  experimental_datasets:
    # null = don't use this dataset
    # all = use all the worms in the dataset
    # positive integer = use this number of worms from the dataset (random pick)
    Kato2015: all
    Nichols2017: all
    Skora2018: all
    Uzel2022: all
    Kaplan2020: all
    Flavell2023: all
    Leifer2023: all
    
  num_named_neurons: all # number of neurons to train the model with (positive integer or 'all')
  k_splits: 2 # split the data into k_splits and alternate in assigning them to the train and validation set
  
  seq_len: 200
  num_train_samples: 128 # number of length seq_len samples to sample from the train set
  num_val_samples: 128 # number of length seq_len samples to sample from the validation set
  reverse: false
  use_residual: false
  smooth_data: true
  