# Train model 
train:
  optimizer: AdamW # options: Adam, AdamW, Adadelta, Adagrad, RMSprop, SGD
  lr: 0.0001
  epochs: 3 #100
  save_freq: 100
  batch_size: 64
  shuffle: true

  early_stopping:
    # Minimum change in validation loss to be considered an improvement
    delta: 0
    # Number of epochs to wait for improvement before stopping
    patience: 50