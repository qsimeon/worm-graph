# Train model 
train:
  optimizer: AdamW # options: Adam, AdamW, Adadelta, Adagrad, RMSprop, SGD
  lr: 0.001
  epochs: 500
  save_freq: 500
  batch_size: 64
  shuffle: true

  early_stopping:
    # Minimum change in validation loss to be considered an improvement
    delta: 0
    # Number of epochs to wait for improvement before stopping
    patience: 50
