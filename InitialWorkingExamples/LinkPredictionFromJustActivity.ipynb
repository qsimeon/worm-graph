{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20b98a53870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "#from models import GNN\n",
    "from dataset import MineDataset\n",
    "#from pytorch_net.util import Batch\n",
    "import sys\n",
    "import dgl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from matplotlib import style\n",
    "style.use('dark_background')\n",
    "\n",
    "data_dir = \"data\"\n",
    "#set seed\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = MineDataset(\n",
    "    data_dir=data_dir,\n",
    "    input_steps=3,\n",
    "    output_steps=3,\n",
    ")\n",
    "bhg = dgl.batch([g for g in dataset[:20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOW TO HAVE BOTH\n",
    "g = dgl.edge_type_subgraph(bhg, [('neuron_basic', 'electric', 'neuron_basic'),])\n",
    "\n",
    "#g = dataset[0]\n",
    "# Split edge set for training and testing\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())), shape=(g.nodes().shape[0], g.nodes().shape[0])) #am I removing something here? due to lack of edge possibly?\n",
    "#print(adj.todense().shape)\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges()) #sampling\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "\n",
    "#remove edges in test set from original graph\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])\n",
    "\n",
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "from dgl.nn import SAGEConv\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, layers=2):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layers = layers\n",
    "        for i in range(self.layers):\n",
    "            setattr(self,\"conv{}\".format(i),SAGEConv(in_feats if i == 0 else h_feats, h_feats, 'mean'))\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        for i in range(self.layers):\n",
    "            h = getattr(self,\"conv{}\".format(i))(g, h if i > 0 else in_feat)\n",
    "            if i != self.layers-1:\n",
    "                h = F.relu(h)\n",
    "        return h\n",
    "    \n",
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            #print(g.edata['score']) #only works with input/output = 1???\n",
    "            return g.edata['score'][:, 0]\n",
    "        \n",
    "model = GraphSAGE(train_g.ndata['feats'].shape[2]*train_g.ndata['feats'].shape[1], 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "#pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "def compute_acc(pos_score, neg_score):\n",
    "    \n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    probs = 1 / (1+np.exp(-scores))\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return (probs.round() == labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.567095160484314\n",
      "AUC 0.7211243998628258\n",
      "ACC 0.6425925925925926\n",
      "In epoch 100, loss: 0.5665022134780884\n",
      "AUC 0.7210515260631002\n",
      "ACC 0.6412037037037037\n",
      "In epoch 200, loss: 0.5662574768066406\n",
      "AUC 0.7214681927297667\n",
      "ACC 0.6435185185185185\n",
      "In epoch 300, loss: 0.5660574436187744\n",
      "AUC 0.7215685013717421\n",
      "ACC 0.6425925925925926\n",
      "In epoch 400, loss: 0.5658435225486755\n",
      "AUC 0.7216756687242799\n",
      "ACC 0.6453703703703704\n",
      "In epoch 500, loss: 0.5656073093414307\n",
      "AUC 0.7217245370370371\n",
      "ACC 0.6449074074074074\n",
      "In epoch 600, loss: 0.5657152533531189\n",
      "AUC 0.7221317729766804\n",
      "ACC 0.6439814814814815\n",
      "In epoch 700, loss: 0.5654144287109375\n",
      "AUC 0.7231605795610425\n",
      "ACC 0.6430555555555556\n",
      "In epoch 800, loss: 0.5648577213287354\n",
      "AUC 0.7219834533607681\n",
      "ACC 0.6439814814814815\n",
      "In epoch 900, loss: 0.5661309361457825\n",
      "AUC 0.7202276234567901\n",
      "ACC 0.6407407407407407\n",
      "In epoch 1000, loss: 0.5658532381057739\n",
      "AUC 0.7246369170096022\n",
      "ACC 0.6439814814814815\n",
      "In epoch 1100, loss: 0.5659124851226807\n",
      "AUC 0.725807184499314\n",
      "ACC 0.6430555555555556\n",
      "In epoch 1200, loss: 0.565481960773468\n",
      "AUC 0.7254573902606309\n",
      "ACC 0.6462962962962963\n",
      "In epoch 1300, loss: 1.511086344718933\n",
      "AUC 0.6265745027434843\n",
      "ACC 0.5925925925925926\n",
      "In epoch 1400, loss: 0.5632230043411255\n",
      "AUC 0.7263996056241426\n",
      "ACC 0.6476851851851851\n",
      "In epoch 1500, loss: 0.5627619028091431\n",
      "AUC 0.7260026577503429\n",
      "ACC 0.6462962962962963\n",
      "In epoch 1600, loss: 0.5625529885292053\n",
      "AUC 0.7260086591220851\n",
      "ACC 0.6472222222222223\n",
      "In epoch 1700, loss: 0.5623824000358582\n",
      "AUC 0.7260343792866941\n",
      "ACC 0.6467592592592593\n",
      "In epoch 1800, loss: 0.5622246265411377\n",
      "AUC 0.7261261145404663\n",
      "ACC 0.6476851851851851\n",
      "In epoch 1900, loss: 0.5620694756507874\n",
      "AUC 0.7261509773662551\n",
      "ACC 0.6476851851851851\n",
      "In epoch 2000, loss: 0.5619099140167236\n",
      "AUC 0.7263147290809329\n",
      "ACC 0.6486111111111111\n",
      "In epoch 2100, loss: 0.5617422461509705\n",
      "AUC 0.7265067729766803\n",
      "ACC 0.649074074074074\n",
      "In epoch 2200, loss: 0.5615714192390442\n",
      "AUC 0.7266362311385459\n",
      "ACC 0.65\n",
      "In epoch 2300, loss: 0.5613937377929688\n",
      "AUC 0.7267596879286694\n",
      "ACC 0.649537037037037\n",
      "In epoch 2400, loss: 0.5612084865570068\n",
      "AUC 0.7268874314128944\n",
      "ACC 0.65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-70a3781ee238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feats'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feats'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#squeezing out timesteps????\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mpos_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pos_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mneg_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_neg_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-80e226b6c10c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, h)\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Compute a new edge feature named 'score' by a dot-product between the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;31m# source node feature 'h' and destination node feature 'h'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mu_dot_v\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'h'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;31m# u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;31m#print(g.edata['score']) #only works with input/output = 1???\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36mapply_edges\u001b[1;34m(self, func, edges, etype, inplace)\u001b[0m\n\u001b[0;32m   4295\u001b[0m         \u001b[0metid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4296\u001b[0m         \u001b[0metype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanonical_etypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0metid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4297\u001b[1;33m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0metype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4298\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4299\u001b[0m             \u001b[0meid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dgl\\heterograph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2158\u001b[0m             \u001b[0metid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_etype_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrctype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsttype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2159\u001b[0m             \u001b[0mdtid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ntype_id_from_dst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsttype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2160\u001b[1;33m             \u001b[0mnew_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_relation_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtid\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36mget_relation_graph\u001b[1;34m(self, etype)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0munitgraph\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroGetRelationGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflatten_relations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mret_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDGLValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mret_tcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         check_call(_LIB.DGLFuncCall(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "epochs = 10000\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.001)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(epochs):\n",
    "    # forward\n",
    "    h = model(train_g, train_g.ndata['feats'].reshape(train_g.ndata['feats'].shape[0],-1)) #squeezing out timesteps????\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "    if e % 100 == 0:\n",
    "        \n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "    if e % 100 == 0:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        with torch.no_grad():\n",
    "            pos_score = pred(test_pos_g, h)\n",
    "            neg_score = pred(test_neg_g, h)\n",
    "            print('AUC', compute_auc(pos_score, neg_score))\n",
    "            print('ACC', compute_acc(pos_score, neg_score))\n",
    "# ----------- 5. check results ------------------------ #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n",
    "\n",
    "\n",
    "# Thumbnail Courtesy: Link Prediction with Neo4j, Mark Needham\n",
    "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0728, 1.0000, 0.0046,  ..., 1.0000, 1.0000, 0.9998],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(1 / (1+torch.exp(-1 * pos_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
