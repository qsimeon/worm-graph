{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from scipy import stats\n",
    "from omegaconf import OmegaConf\n",
    "from pprint import PrettyPrinter\n",
    "from models._main import get_model\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from models._utils import print_parameters\n",
    "from visualize._utils import experiment_parameter\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pp = PrettyPrinter(indent=4, width=100, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color and Marker Legend\n",
    "Returns the common legend code used for all plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_and_number(s):\n",
    "    match = re.match(r\"([a-zA-Z]+)([0-9]+)\", s)\n",
    "    if match:\n",
    "        return match.groups()\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text, number = split_text_and_number(\"Kato2015\")\n",
    "print(\"Text:\", text)\n",
    "print(\"Number:\", number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Marker and Dataset color codes\n",
    "def legend_code():\n",
    "    markers = {\"o\": \"LSTM\", \"s\": \"Transformer\", \"^\": \"Feedforward\", \"*\": \"CTRNN\"}\n",
    "\n",
    "    model_labels = {\n",
    "        \"NetworkLSTM\": \"LSTM\",\n",
    "        \"NeuralTransformer\": \"Transformer\",\n",
    "        \"FeatureFFNN\": \"Feedforward\",\n",
    "        \"NetworkCTRNN\": \"CTRNN\",\n",
    "    }\n",
    "\n",
    "    dataset_labels = {\n",
    "        \"Kato2015\": \"Kato (2015)\",\n",
    "        \"Nichols2017\": \"Nichols (2017)\",\n",
    "        \"Skora2018\": \"Skora (2018)\",\n",
    "        \"Kaplan2020\": \"Kaplan (2020)\",\n",
    "        \"Yemini2021\": \"Yemini (2021)\",\n",
    "        \"Uzel2022\": \"Uzel (2022)\",\n",
    "        \"Flavell2023\": \"Flavell (2023)\",\n",
    "        \"Leifer2023\": \"Leifer (2023)\",\n",
    "    }\n",
    "\n",
    "    marker_colors = sns.color_palette(\"tab10\", n_colors=len(markers))\n",
    "\n",
    "    # Create custom markers for models\n",
    "    marker_legend = [\n",
    "        Line2D([0], [0], marker=m, color=marker_colors[i], label=l, linestyle=\"None\")\n",
    "        for i, (m, l) in enumerate(markers.items())\n",
    "    ]\n",
    "\n",
    "    # Plot the marker legends\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(4, 1))\n",
    "\n",
    "    # Plot marker legend on the left subplot\n",
    "    axs[0].legend(handles=marker_legend, loc=\"center\", title=\"Model\")\n",
    "    # Legend title italic\n",
    "    axs[0].get_legend().get_title().set_fontsize(\"large\")\n",
    "    axs[0].get_legend().get_title().set_fontstyle(\"italic\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    color_palette = sns.color_palette(\"tab10\", n_colors=len(dataset_labels))\n",
    "    # Add black color to the end of color palette\n",
    "    color_palette.append((0, 0, 0))\n",
    "\n",
    "    # Create rectangular color patches for datasets\n",
    "    color_legend = [\n",
    "        Patch(facecolor=c, edgecolor=c, label=l)\n",
    "        for c, l in zip(color_palette, dataset_labels)\n",
    "    ]\n",
    "\n",
    "    # Plot color legend on the right subplot\n",
    "    axs[1].legend(handles=color_legend, loc=\"center\", title=\"Experimental datasets\")\n",
    "    axs[1].get_legend().get_title().set_fontsize(\"large\")\n",
    "    axs[1].get_legend().get_title().set_fontstyle(\"italic\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    dataset_color_code = {\n",
    "        dataset: color for dataset, color in zip(dataset_labels.keys(), color_palette)\n",
    "    }\n",
    "    model_marker_code = {\n",
    "        model: marker for model, marker in zip(markers.values(), markers.keys())\n",
    "    }\n",
    "    model_color_code = {\n",
    "        model: color for model, color in zip(markers.values(), marker_colors)\n",
    "    }\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    leg_code = {\n",
    "        \"dataset_color_code\": dataset_color_code,\n",
    "        \"model_marker_code\": model_marker_code,\n",
    "        \"model_color_code\": model_color_code,\n",
    "        \"color_legend\": color_legend,\n",
    "        \"dataset_labels\": dataset_labels,\n",
    "        \"marker_colors\": marker_colors,\n",
    "        \"marker_legend\": marker_legend,\n",
    "        \"model_labels\": model_labels,\n",
    "    }\n",
    "\n",
    "    return leg_code\n",
    "\n",
    "\n",
    "# Usage example\n",
    "leg_code = legend_code()\n",
    "pp.pprint(leg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "\n",
    "\n",
    "# 2. Plotting summary information about the datasets\n",
    "def dataset_information(path_dict, legend_code):\n",
    "    \"\"\"\n",
    "    path_dict: dictionary with the path to train_dataset_info,\n",
    "        validation_dataset_info and combined_dataset_info.\n",
    "    \"\"\"\n",
    "\n",
    "    # ### LOAD IN DATASET INFORMATION ###\n",
    "    train_dataset_info = pd.read_csv(\n",
    "        path_dict[\"train_dataset_info\"],\n",
    "        converters={\"neurons\": ast.literal_eval},\n",
    "    )\n",
    "    val_dataset_info = pd.read_csv(\n",
    "        path_dict[\"val_dataset_info\"],\n",
    "        converters={\"neurons\": ast.literal_eval},\n",
    "    )\n",
    "    combined_dataset_info = pd.read_csv(\n",
    "        path_dict[\"combined_dataset_info\"],\n",
    "        converters={\"neurons\": ast.literal_eval},\n",
    "    )\n",
    "\n",
    "    train_dataset_info[\"total_time_steps\"] = (\n",
    "        train_dataset_info[\"train_time_steps\"] + val_dataset_info[\"val_time_steps\"]\n",
    "    )\n",
    "    train_dataset_info[\"time_steps_per_neuron\"] = (\n",
    "        train_dataset_info[\"total_time_steps\"] / train_dataset_info[\"num_neurons\"]\n",
    "    )\n",
    "    amount_of_data_distribution = (\n",
    "        train_dataset_info[[\"dataset\", \"total_time_steps\"]]\n",
    "        .groupby(\"dataset\")\n",
    "        .sum()\n",
    "        .sort_values(by=\"total_time_steps\", ascending=False)\n",
    "    )\n",
    "    amount_of_data_distribution[\"percentage\"] = (\n",
    "        amount_of_data_distribution[\"total_time_steps\"]\n",
    "        / amount_of_data_distribution[\"total_time_steps\"].sum()\n",
    "    )\n",
    "\n",
    "    # ########### SET UP FOR FIGURES ###########\n",
    "    # Get color code and legend from legend_code\n",
    "    dataset_color_code = legend_code[\"dataset_color_code\"]\n",
    "    dataset_labels = legend_code[\"dataset_labels\"]\n",
    "    color_legend = legend_code[\"color_legend\"]\n",
    "\n",
    "    # Initialize figure\n",
    "    fig = plt.figure(figsize=(20, 7))\n",
    "    gs = gridspec.GridSpec(2, 4, height_ratios=[1, 1], width_ratios=[1, 1, 1, 0.25])\n",
    "\n",
    "    # Assigning the subplots to positions in the grid\n",
    "    ax1 = plt.subplot(gs[0, 0])  # Top left, 'Number of worms analyzed' pie chart\n",
    "    ax2 = plt.subplot(gs[0, 1])  # Top right, 'Number of neurons per worm' bar plot\n",
    "    ax3 = plt.subplot(\n",
    "        gs[1, 0]\n",
    "    )  # Bottom left, 'Total duration of recorded neural activity' pie chart\n",
    "    ax4 = plt.subplot(\n",
    "        gs[1, 1]\n",
    "    )  # Bottom middle, 'Duration of recorded neural activity per worm' bar plot\n",
    "    ax5 = plt.subplot(gs[0, 3])  # Bottom right, legend\n",
    "    ax6 = plt.subplot(gs[0, 2])\n",
    "    ax7 = plt.subplot(gs[1, 2:4])\n",
    "\n",
    "    # ########### FOR WORMS PIE CHART ###############\n",
    "    num_worms_per_dataset = combined_dataset_info[[\"dataset\", \"original_index\"]]\n",
    "    # Count the unique 'original_index' for each 'dataset'\n",
    "    num_worms_per_dataset = (\n",
    "        num_worms_per_dataset.groupby(\"dataset\")[\"original_index\"]\n",
    "        .nunique()\n",
    "        .reset_index(name=\"num_worms\")\n",
    "    )\n",
    "    # Calculate the percentage for each dataset\n",
    "    num_worms_per_dataset[\"percentage\"] = (\n",
    "        num_worms_per_dataset[\"num_worms\"] / num_worms_per_dataset[\"num_worms\"].sum()\n",
    "    )\n",
    "    # Sort the values by percentage in descending order\n",
    "    num_worms_per_dataset = num_worms_per_dataset.sort_values(\n",
    "        by=\"percentage\", ascending=False\n",
    "    )\n",
    "    worm_count_label = num_worms_per_dataset[\"num_worms\"][:7].tolist() + [\"\"]\n",
    "    # Plotting the worms per dataset pie chart\n",
    "    ax1.pie(\n",
    "        num_worms_per_dataset[\"num_worms\"],\n",
    "        labels=[\n",
    "            f\"{percentage:.1%}\" for percentage in num_worms_per_dataset[\"percentage\"]\n",
    "        ],\n",
    "        labeldistance=1.075,\n",
    "        startangle=45,\n",
    "        colors=[\n",
    "            dataset_color_code[dataset] for dataset in num_worms_per_dataset[\"dataset\"]\n",
    "        ],\n",
    "    )\n",
    "    ax1.pie(\n",
    "        num_worms_per_dataset[\"num_worms\"],\n",
    "        labels=[f\"{n}\" for n in worm_count_label],\n",
    "        labeldistance=0.70,\n",
    "        startangle=45,\n",
    "        colors=[\n",
    "            dataset_color_code[dataset] for dataset in num_worms_per_dataset[\"dataset\"]\n",
    "        ],\n",
    "    )\n",
    "    ax1.set_title(\"(A) Number of worms in dataset\", fontsize=14)\n",
    "\n",
    "    # ########### NEURON POPULATION DISTRIBUTION BAR PLOT ###############\n",
    "    ax2 = plt.subplot(gs[0, 1])  # Subplot for 'Number of neurons per worm' bar plot\n",
    "    # Compute data for the neuron population distribution bar plot\n",
    "    neuron_pop_stats = (\n",
    "        train_dataset_info.groupby(\"dataset\")[\"num_neurons\"]\n",
    "        .agg([\"mean\", \"sem\"])\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"mean\", ascending=False)\n",
    "    )\n",
    "    neuron_pop_colors = neuron_pop_stats[\"dataset\"].apply(\n",
    "        lambda x: dataset_color_code.get(x, \"grey\")\n",
    "    )\n",
    "    ax2.bar(\n",
    "        neuron_pop_stats[\"dataset\"],\n",
    "        neuron_pop_stats[\"mean\"],\n",
    "        yerr=2 * neuron_pop_stats[\"sem\"],\n",
    "        color=neuron_pop_colors,\n",
    "        capsize=5,\n",
    "    )\n",
    "    # Add a dashed horizontal line at y=302\n",
    "    ax2.axhline(y=302, color=\"black\", linestyle=\"dashed\", linewidth=1, alpha=0.5)\n",
    "    # Annotate the line\n",
    "    # Use the right edge of the subplot for text annotation to prevent overflow\n",
    "    right_edge = ax2.get_xlim()[1]\n",
    "    ax2.text(\n",
    "        right_edge,  # x position at the right edge\n",
    "        302,  # y position at the line\n",
    "        \"Number of neurons in C. elegans hermaphrodite\",\n",
    "        horizontalalignment=\"right\",  # Align text to the right\n",
    "        fontsize=10,\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    ax2.set_title(\"(B) Number of recorded neurons per worm\", fontsize=14)\n",
    "    ax2.set_ylabel(\"Neuron population size\")\n",
    "    ax2.set_xticklabels(neuron_pop_stats[\"dataset\"], rotation=45, ha=\"right\")\n",
    "    ax2.set_xticks([])  # Delete xticks\n",
    "\n",
    "    # ########### TOTAL DURATION OF RECORDED NEURAL ACTIVITY PIE CHART ###############\n",
    "    ax3 = plt.subplot(\n",
    "        gs[1, 0]\n",
    "    )  # Subplot for 'Total duration of recorded neural activity' pie chart\n",
    "    # Compute data for total duration pie chart\n",
    "    total_duration_stats = (\n",
    "        train_dataset_info.groupby(\"dataset\")[\"total_time_steps\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"total_time_steps\", ascending=False)\n",
    "    )\n",
    "    total_duration_stats[\"percentage\"] = (\n",
    "        total_duration_stats[\"total_time_steps\"]\n",
    "        / total_duration_stats[\"total_time_steps\"].sum()\n",
    "    )\n",
    "\n",
    "    # Determine the smallest slice\n",
    "    smallest_slice_index = total_duration_stats[\"percentage\"].idxmin()\n",
    "\n",
    "    # Generate labels, omitting the smallest slice\n",
    "    labels = [\n",
    "        f\"{percentage:.1%}\" if i != smallest_slice_index else \"\"\n",
    "        for i, percentage in enumerate(total_duration_stats[\"percentage\"])\n",
    "    ]\n",
    "\n",
    "    total_duration_colors = total_duration_stats[\"dataset\"].apply(\n",
    "        lambda x: dataset_color_code.get(x, \"grey\")\n",
    "    )\n",
    "    # Plotting the total duration pie chart\n",
    "    ax3.pie(\n",
    "        total_duration_stats[\"total_time_steps\"],\n",
    "        labels=labels,\n",
    "        labeldistance=1.075,\n",
    "        startangle=90,\n",
    "        colors=total_duration_colors,\n",
    "    )\n",
    "    ax3.set_title(\"(C) Total duration of recorded neural activity\", fontsize=14)\n",
    "\n",
    "    # ########### DURATION OF RECORDED NEURAL ACTIVITY PER WORM BAR PLOT ###############\n",
    "    ax4 = plt.subplot(\n",
    "        gs[1, 1]\n",
    "    )  # Subplot for 'Duration of recorded neural activity per worm' bar plot\n",
    "    # Compute data for recording duration bar plot\n",
    "    recording_duration_stats = (\n",
    "        train_dataset_info.groupby(\"dataset\")[\"total_time_steps\"]\n",
    "        .agg([\"mean\", \"sem\"])\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"mean\", ascending=False)\n",
    "    )\n",
    "    recording_duration_colors = recording_duration_stats[\"dataset\"].apply(\n",
    "        lambda x: dataset_color_code.get(x, \"grey\")\n",
    "    )\n",
    "    ax4.bar(\n",
    "        recording_duration_stats[\"dataset\"],\n",
    "        recording_duration_stats[\"mean\"],\n",
    "        yerr=2 * recording_duration_stats[\"sem\"],\n",
    "        color=recording_duration_colors,\n",
    "        capsize=5,\n",
    "    )\n",
    "    # Add a dashed horizontal line at y=3600\n",
    "    ax4.axhline(y=3600, color=\"black\", linestyle=\"dashed\", linewidth=1, alpha=0.5)\n",
    "    # Annotate the line\n",
    "    # Use the right edge of the subplot for text annotation to prevent overflow\n",
    "    right_edge = ax4.get_xlim()[1]\n",
    "    ax4.text(\n",
    "        right_edge,  # x position at the right edge\n",
    "        3600,  # y position at the line\n",
    "        \"3600 seconds = 1 hour of calcium imaging\",\n",
    "        horizontalalignment=\"right\",  # Align text to the right\n",
    "        fontsize=10,\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    ax4.set_title(\"(D) Duration of recorded neural activity per worm\", fontsize=14)\n",
    "    ax4.set_ylabel(\"Time (s)\")\n",
    "    ax4.set_xticklabels(recording_duration_stats[\"dataset\"], rotation=45, ha=\"right\")\n",
    "    ax4.set_xticks([])  # Delete xticks\n",
    "\n",
    "    # ########### TIME STEPS PER NEURON BAR PLOT ###############\n",
    "    ax6 = plt.subplot(\n",
    "        gs[0, 2]\n",
    "    )  # Subplot for 'Number of time steps per recorded neuron' bar plot\n",
    "    # Compute data for time steps per neuron bar plot\n",
    "    tsn_stats = (\n",
    "        train_dataset_info.groupby(\"dataset\")[\"time_steps_per_neuron\"]\n",
    "        .agg([\"mean\", \"sem\"])\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"mean\", ascending=False)\n",
    "    )\n",
    "    tsn_colors = tsn_stats[\"dataset\"].apply(lambda x: dataset_color_code.get(x, \"grey\"))\n",
    "    ax6.bar(\n",
    "        tsn_stats[\"dataset\"],\n",
    "        tsn_stats[\"mean\"],\n",
    "        yerr=2 * tsn_stats[\"sem\"],\n",
    "        color=tsn_colors,\n",
    "        capsize=5,\n",
    "    )\n",
    "    # Add a dashed horizontal line at y=100\n",
    "    ax6.axhline(y=100, color=\"black\", linestyle=\"dashed\", linewidth=1, alpha=0.5)\n",
    "    # Annotate the line\n",
    "    # Use the right edge of the subplot for text annotation to prevent overflow\n",
    "    right_edge = ax6.get_xlim()[1]\n",
    "    ax6.text(\n",
    "        right_edge,  # x position at the right edge\n",
    "        100,  # y position at the line\n",
    "        \"Sequence length $L=100$ was used in our experiments\",\n",
    "        horizontalalignment=\"right\",  # Align text to the right\n",
    "        fontsize=10,\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    ax6.set_title(\"(E) Number of time steps per recorded neuron\", fontsize=14)\n",
    "    ax6.set_ylabel(\"Time steps per neuron\")\n",
    "    ax6.set_xticklabels(tsn_stats[\"dataset\"], rotation=45, ha=\"right\")\n",
    "    ax6.set_xticks([])  # Delete xticks\n",
    "\n",
    "    # ########### SAMPLING INTERVAL BAR PLOT ###############\n",
    "    ax7 = plt.subplot(\n",
    "        gs[1, 2:4]\n",
    "    )  # Subplot for 'Sampling interval of recorded neural activity' bar plot\n",
    "    # Compute data for the sampling interval bar plot\n",
    "    dt_stats = (\n",
    "        train_dataset_info.groupby(\"dataset\")[\"original_median_dt\"]\n",
    "        .agg([\"mean\", \"sem\"])\n",
    "        .reset_index()\n",
    "        .sort_values(by=\"mean\", ascending=False)\n",
    "    )\n",
    "    dt_colors = dt_stats[\"dataset\"].apply(lambda x: dataset_color_code.get(x, \"grey\"))\n",
    "    ax7.bar(\n",
    "        dt_stats[\"dataset\"],\n",
    "        dt_stats[\"mean\"],\n",
    "        yerr=2 * dt_stats[\"sem\"],\n",
    "        color=dt_colors,\n",
    "        capsize=5,\n",
    "    )\n",
    "    # Add a dashed horizontal line at y=1.0\n",
    "    ax7.axhline(y=1.0, color=\"black\", linestyle=\"dashed\", linewidth=1, alpha=0.5)\n",
    "    # Annotate the line\n",
    "    # Use the right edge of the subplot for text annotation to prevent overflow\n",
    "    right_edge = ax7.get_xlim()[1]\n",
    "    ax7.text(\n",
    "        right_edge,  # x position at the right edge\n",
    "        1.0,  # y position at the line\n",
    "        \"We downsampled all data to $\\Delta s = 1.0s$ (1 Hz)\",\n",
    "        horizontalalignment=\"right\",  # Align text to the right\n",
    "        fontsize=10,\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    ax7.set_title(\"(F) Sampling interval of recorded neural activity\", fontsize=14)\n",
    "    ax7.set_ylabel(r\"Mean sampling interval ($\\Delta$s)\")\n",
    "    ax7.set_xticklabels(dt_stats[\"dataset\"], rotation=45, ha=\"right\")\n",
    "    ax7.set_xticks([])  # Delete xticks\n",
    "\n",
    "    # ########### LEGEND SUBPLOT ###############\n",
    "    ax5 = plt.subplot(gs[0, 3])  # Subplot for legend\n",
    "    ax5.legend(\n",
    "        handles=color_legend,\n",
    "        labels=dataset_labels.values(),  # DEBUG\n",
    "        loc=\"center\",\n",
    "        title=\"Experimental datasets\",\n",
    "        fontsize=11,\n",
    "        title_fontsize=12,\n",
    "    )\n",
    "    ax5.get_legend().get_title().set_fontstyle(\"italic\")\n",
    "    ax5.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Construct and return the dataset_info dictionary with all the computed stats\n",
    "    dataset_info = {\n",
    "        \"train_dataset_info\": train_dataset_info,\n",
    "        \"amount_of_data_distribution\": amount_of_data_distribution,\n",
    "        \"num_worms_per_dataset\": num_worms_per_dataset,\n",
    "        \"total_duration_stats\": total_duration_stats,\n",
    "        \"neuron_pop_stats\": neuron_pop_stats,\n",
    "        \"recording_duration_stats\": recording_duration_stats,\n",
    "        \"tsn_stats\": tsn_stats,\n",
    "        \"dt_stats\": dt_stats,\n",
    "    }\n",
    "\n",
    "    return dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "fig1_path_dict = {\n",
    "    \"train_dataset_info\": \"/om2/user/qsimeon/worm-graph/data/train_AllExperimental/train_dataset_info.csv\",  # Path to train dataset info => extract number of train time steps\n",
    "    \"val_dataset_info\": \"/om2/user/qsimeon/worm-graph/data/validation_AllExperimental/val_dataset_info.csv\",  # Path to val. dataset info => extract number of val. time steps\n",
    "    \"combined_dataset_info\": \"/om2/user/qsimeon/worm-graph/data/combined_AllExperimental/combined_dataset_info.csv\",  # Path to combined dataset info => extract total number of worms and time step interval\n",
    "}\n",
    "\n",
    "# NOTE: Error bars on bar plots show +/- 2 SEM\n",
    "dataset_info = dataset_information(path_dict=fig1_path_dict, legend_code=leg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Law Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "\n",
    "\n",
    "def get_results_df(results_root_dir):\n",
    "    \"\"\"\n",
    "    Recursively traverses the experiment directories, reads train_metrics.csv and\n",
    "    validation_loss_per_dataset.csv files, and combines the data into a comprehensive DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - results_root_dir: The root directory where the experiment directories are located.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame containing all the combined results from the experiments.\n",
    "    \"\"\"\n",
    "\n",
    "    def recursive_search(path, results):\n",
    "        \"\"\"\n",
    "        Helper function to perform a recursive search for csv files in the directory tree.\n",
    "        \"\"\"\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_dir() and any(os.scandir(entry.path)):\n",
    "                recursive_search(entry.path, results)\n",
    "            elif entry.is_file():\n",
    "                if entry.name == \"train_metrics.csv\":\n",
    "                    train_metrics_path = entry.path\n",
    "                    validation_loss_path = os.path.join(\n",
    "                        os.path.dirname(os.path.dirname(train_metrics_path)),\n",
    "                        \"analysis\",\n",
    "                        \"validation_loss_per_dataset.csv\",\n",
    "                    )\n",
    "\n",
    "                    if os.path.exists(validation_loss_path):\n",
    "                        # Read the csv files\n",
    "                        train_metrics_df = pd.read_csv(train_metrics_path)\n",
    "                        validation_loss_df = pd.read_csv(validation_loss_path)\n",
    "\n",
    "                        # Extract parameters using the provided experiment_parameter function\n",
    "                        exp_path = os.path.dirname(os.path.dirname(train_metrics_path))\n",
    "                        experiment_seed = experiment_parameter(\n",
    "                            exp_path, \"experiment_seed\"\n",
    "                        )[0]\n",
    "                        train_dataset = experiment_parameter(exp_path, \"train_dataset\")[\n",
    "                            0\n",
    "                        ]\n",
    "                        num_worms = experiment_parameter(exp_path, \"num_worms\")[0]\n",
    "                        num_time_steps = experiment_parameter(\n",
    "                            exp_path, \"num_time_steps\"\n",
    "                        )[0]\n",
    "                        num_named_neurons = experiment_parameter(\n",
    "                            exp_path, \"num_named_neurons\"\n",
    "                        )[0]\n",
    "                        time_steps_per_neuron = experiment_parameter(\n",
    "                            exp_path, \"time_steps_per_neuron\"\n",
    "                        )[0]\n",
    "                        train_split_first = experiment_parameter(\n",
    "                            exp_path, \"train_split_first\"\n",
    "                        )[0]\n",
    "                        hidden_size = experiment_parameter(exp_path, \"hidden_size\")[0]\n",
    "                        batch_size = experiment_parameter(exp_path, \"batch_size\")[0]\n",
    "                        seq_len = experiment_parameter(exp_path, \"seq_len\")[0]\n",
    "                        resample_dt = experiment_parameter(exp_path, \"resample_dt\")[0]\n",
    "                        time_last_epoch = experiment_parameter(\n",
    "                            exp_path, \"time_last_epoch\"\n",
    "                        )[0]\n",
    "                        computation_flops = experiment_parameter(\n",
    "                            exp_path, \"computation_flops\"\n",
    "                        )[0]\n",
    "                        num_parameters = experiment_parameter(\n",
    "                            exp_path, \"num_parameters\"\n",
    "                        )[0]\n",
    "                        model_type = experiment_parameter(exp_path, \"model\")[0]\n",
    "\n",
    "                        # Calculate the min_val_loss and val_baseline\n",
    "                        min_val_loss = train_metrics_df[\"val_loss\"].min()\n",
    "                        val_baseline = train_metrics_df[\"val_baseline\"].mean()\n",
    "\n",
    "                        # Append data to the results list\n",
    "                        for _, row in validation_loss_df.iterrows():\n",
    "                            results.append(\n",
    "                                {\n",
    "                                    \"experiment_ID\": os.path.basename(exp_path),\n",
    "                                    \"experiment_seed\": experiment_seed,\n",
    "                                    \"train_dataset\": train_dataset,\n",
    "                                    \"num_worms\": num_worms,\n",
    "                                    \"num_time_steps\": num_time_steps,\n",
    "                                    \"num_named_neurons\": num_named_neurons,\n",
    "                                    \"time_steps_per_neuron\": time_steps_per_neuron,\n",
    "                                    \"train_split_first\": train_split_first,\n",
    "                                    \"hidden_size\": hidden_size,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"seq_len\": seq_len,\n",
    "                                    \"resample_dt\": resample_dt,\n",
    "                                    \"time_last_epoch\": time_last_epoch,\n",
    "                                    \"computation_flops\": computation_flops,\n",
    "                                    \"num_parameters\": num_parameters,\n",
    "                                    \"model_type\": model_type,\n",
    "                                    \"min_val_loss\": min_val_loss,\n",
    "                                    \"val_baseline\": val_baseline,\n",
    "                                    \"validation_dataset\": row[\"dataset\"],\n",
    "                                    \"validation_loss\": row[\"validation_loss\"],\n",
    "                                    \"validation_baseline\": row[\"validation_baseline\"],\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "    # List to store result dictionaries\n",
    "    results = []\n",
    "    recursive_search(results_root_dir, results)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_ID</th>\n",
       "      <th>experiment_seed</th>\n",
       "      <th>train_dataset</th>\n",
       "      <th>num_worms</th>\n",
       "      <th>num_time_steps</th>\n",
       "      <th>num_named_neurons</th>\n",
       "      <th>time_steps_per_neuron</th>\n",
       "      <th>train_split_first</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>resample_dt</th>\n",
       "      <th>time_last_epoch</th>\n",
       "      <th>computation_flops</th>\n",
       "      <th>num_parameters</th>\n",
       "      <th>model_type</th>\n",
       "      <th>min_val_loss</th>\n",
       "      <th>val_baseline</th>\n",
       "      <th>validation_dataset</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exp0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>176189</td>\n",
       "      <td>247</td>\n",
       "      <td>11.682182</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.156839</td>\n",
       "      <td>62361600</td>\n",
       "      <td>5734</td>\n",
       "      <td>NetworkLSTM</td>\n",
       "      <td>0.394548</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>Kato2015</td>\n",
       "      <td>0.365148</td>\n",
       "      <td>0.013655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>exp0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>176189</td>\n",
       "      <td>247</td>\n",
       "      <td>11.682182</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.156839</td>\n",
       "      <td>62361600</td>\n",
       "      <td>5734</td>\n",
       "      <td>NetworkLSTM</td>\n",
       "      <td>0.394548</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>Nichols2017</td>\n",
       "      <td>0.303191</td>\n",
       "      <td>0.010337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exp0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>176189</td>\n",
       "      <td>247</td>\n",
       "      <td>11.682182</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.156839</td>\n",
       "      <td>62361600</td>\n",
       "      <td>5734</td>\n",
       "      <td>NetworkLSTM</td>\n",
       "      <td>0.394548</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>Skora2018</td>\n",
       "      <td>0.316107</td>\n",
       "      <td>0.007530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exp0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>176189</td>\n",
       "      <td>247</td>\n",
       "      <td>11.682182</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.156839</td>\n",
       "      <td>62361600</td>\n",
       "      <td>5734</td>\n",
       "      <td>NetworkLSTM</td>\n",
       "      <td>0.394548</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>Kaplan2020</td>\n",
       "      <td>0.307448</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exp0</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>176189</td>\n",
       "      <td>247</td>\n",
       "      <td>11.682182</td>\n",
       "      <td>False</td>\n",
       "      <td>8.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.156839</td>\n",
       "      <td>62361600</td>\n",
       "      <td>5734</td>\n",
       "      <td>NetworkLSTM</td>\n",
       "      <td>0.394548</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>Yemini2021</td>\n",
       "      <td>0.269851</td>\n",
       "      <td>0.010946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>exp9</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>171115</td>\n",
       "      <td>247</td>\n",
       "      <td>11.379269</td>\n",
       "      <td>False</td>\n",
       "      <td>68.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716088</td>\n",
       "      <td>584908800</td>\n",
       "      <td>46270</td>\n",
       "      <td>FeatureFFNN</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>Kaplan2020</td>\n",
       "      <td>0.074078</td>\n",
       "      <td>0.005937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>exp9</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>171115</td>\n",
       "      <td>247</td>\n",
       "      <td>11.379269</td>\n",
       "      <td>False</td>\n",
       "      <td>68.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716088</td>\n",
       "      <td>584908800</td>\n",
       "      <td>46270</td>\n",
       "      <td>FeatureFFNN</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>Yemini2021</td>\n",
       "      <td>0.245706</td>\n",
       "      <td>0.028008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>exp9</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>171115</td>\n",
       "      <td>247</td>\n",
       "      <td>11.379269</td>\n",
       "      <td>False</td>\n",
       "      <td>68.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716088</td>\n",
       "      <td>584908800</td>\n",
       "      <td>46270</td>\n",
       "      <td>FeatureFFNN</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>Uzel2022</td>\n",
       "      <td>0.118890</td>\n",
       "      <td>0.014890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>exp9</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>171115</td>\n",
       "      <td>247</td>\n",
       "      <td>11.379269</td>\n",
       "      <td>False</td>\n",
       "      <td>68.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716088</td>\n",
       "      <td>584908800</td>\n",
       "      <td>46270</td>\n",
       "      <td>FeatureFFNN</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>Flavell2023</td>\n",
       "      <td>0.155303</td>\n",
       "      <td>0.009692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>exp9</td>\n",
       "      <td>0</td>\n",
       "      <td>Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...</td>\n",
       "      <td>284</td>\n",
       "      <td>171115</td>\n",
       "      <td>247</td>\n",
       "      <td>11.379269</td>\n",
       "      <td>False</td>\n",
       "      <td>68.0</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.716088</td>\n",
       "      <td>584908800</td>\n",
       "      <td>46270</td>\n",
       "      <td>FeatureFFNN</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.014469</td>\n",
       "      <td>Leifer2023</td>\n",
       "      <td>0.162002</td>\n",
       "      <td>0.009215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>960 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experiment_ID  experiment_seed  \\\n",
       "0            exp0                0   \n",
       "1            exp0                0   \n",
       "2            exp0                0   \n",
       "3            exp0                0   \n",
       "4            exp0                0   \n",
       "..            ...              ...   \n",
       "955          exp9                0   \n",
       "956          exp9                0   \n",
       "957          exp9                0   \n",
       "958          exp9                0   \n",
       "959          exp9                0   \n",
       "\n",
       "                                         train_dataset  num_worms  \\\n",
       "0    Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "1    Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "2    Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "3    Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "4    Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "..                                                 ...        ...   \n",
       "955  Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "956  Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "957  Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "958  Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "959  Flavell2023_Kaplan2020_Kato2015_Leifer2023_Nic...        284   \n",
       "\n",
       "     num_time_steps  num_named_neurons  time_steps_per_neuron  \\\n",
       "0            176189                247              11.682182   \n",
       "1            176189                247              11.682182   \n",
       "2            176189                247              11.682182   \n",
       "3            176189                247              11.682182   \n",
       "4            176189                247              11.682182   \n",
       "..              ...                ...                    ...   \n",
       "955          171115                247              11.379269   \n",
       "956          171115                247              11.379269   \n",
       "957          171115                247              11.379269   \n",
       "958          171115                247              11.379269   \n",
       "959          171115                247              11.379269   \n",
       "\n",
       "     train_split_first  hidden_size  batch_size  ...  resample_dt  \\\n",
       "0                False          8.0         128  ...          NaN   \n",
       "1                False          8.0         128  ...          NaN   \n",
       "2                False          8.0         128  ...          NaN   \n",
       "3                False          8.0         128  ...          NaN   \n",
       "4                False          8.0         128  ...          NaN   \n",
       "..                 ...          ...         ...  ...          ...   \n",
       "955              False         68.0         128  ...          NaN   \n",
       "956              False         68.0         128  ...          NaN   \n",
       "957              False         68.0         128  ...          NaN   \n",
       "958              False         68.0         128  ...          NaN   \n",
       "959              False         68.0         128  ...          NaN   \n",
       "\n",
       "     time_last_epoch  computation_flops  num_parameters   model_type  \\\n",
       "0           4.156839           62361600            5734  NetworkLSTM   \n",
       "1           4.156839           62361600            5734  NetworkLSTM   \n",
       "2           4.156839           62361600            5734  NetworkLSTM   \n",
       "3           4.156839           62361600            5734  NetworkLSTM   \n",
       "4           4.156839           62361600            5734  NetworkLSTM   \n",
       "..               ...                ...             ...          ...   \n",
       "955         2.716088          584908800           46270  FeatureFFNN   \n",
       "956         2.716088          584908800           46270  FeatureFFNN   \n",
       "957         2.716088          584908800           46270  FeatureFFNN   \n",
       "958         2.716088          584908800           46270  FeatureFFNN   \n",
       "959         2.716088          584908800           46270  FeatureFFNN   \n",
       "\n",
       "    min_val_loss  val_baseline  validation_dataset validation_loss  \\\n",
       "0       0.394548      0.010523            Kato2015        0.365148   \n",
       "1       0.394548      0.010523         Nichols2017        0.303191   \n",
       "2       0.394548      0.010523           Skora2018        0.316107   \n",
       "3       0.394548      0.010523          Kaplan2020        0.307448   \n",
       "4       0.394548      0.010523          Yemini2021        0.269851   \n",
       "..           ...           ...                 ...             ...   \n",
       "955     0.153667      0.014469          Kaplan2020        0.074078   \n",
       "956     0.153667      0.014469          Yemini2021        0.245706   \n",
       "957     0.153667      0.014469            Uzel2022        0.118890   \n",
       "958     0.153667      0.014469         Flavell2023        0.155303   \n",
       "959     0.153667      0.014469          Leifer2023        0.162002   \n",
       "\n",
       "     validation_baseline  \n",
       "0               0.013655  \n",
       "1               0.010337  \n",
       "2               0.007530  \n",
       "3               0.003507  \n",
       "4               0.010946  \n",
       "..                   ...  \n",
       "955             0.005937  \n",
       "956             0.028008  \n",
       "957             0.014890  \n",
       "958             0.009692  \n",
       "959             0.009215  \n",
       "\n",
       "[960 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage example:\n",
    "results_root_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments\"\n",
    "combined_results_df = get_results_df(results_root_directory)\n",
    "combined_results_df  # .head()  # To display the first few rows of the resulting DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Number of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "\n",
    "\n",
    "# We varied the hidden size as a \"knob\" to vary the number of parameters.\n",
    "def parameters_scaling_plot(combined_results_df, legend_code, title=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title(title, fontsize=14)\n",
    "\n",
    "    # Group the DataFrame by 'model_type' and plot\n",
    "    for model_type, group in combined_results_df.groupby(\"model_type\"):\n",
    "        # Skip if unrecognized type of model\n",
    "        if model_type not in legend_code[\"model_labels\"]:\n",
    "            continue\n",
    "        # Plot settings from legend_code\n",
    "        model_label = legend_code[\"model_labels\"][model_type]\n",
    "        marker = legend_code[\"model_marker_code\"][model_label]\n",
    "        color = legend_code[\"model_color_code\"][model_label]\n",
    "\n",
    "        # Scatter plot of validation loss vs. number of parameters\n",
    "        ax.scatter(\n",
    "            group[\"num_parameters\"],\n",
    "            group[\"min_val_loss\"],\n",
    "            marker=marker,\n",
    "            s=10,\n",
    "            color=color,\n",
    "            label=model_label,\n",
    "            alpha=0.5,  # Adjust alpha to your preference\n",
    "        )\n",
    "\n",
    "    baseline = combined_results_df[\"val_baseline\"].unique()\n",
    "    ax.plot(\n",
    "        [\n",
    "            combined_results_df[\"num_parameters\"].min(),\n",
    "            combined_results_df[\"num_parameters\"].max(),\n",
    "        ],\n",
    "        [baseline.mean(), baseline.mean()],\n",
    "        label=\"Baseline\",\n",
    "        color=\"black\",\n",
    "        alpha=0.7,\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "\n",
    "    # Create legends\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel(\"Num. trainable parameters\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Minimum Validation Loss (MSE)\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/experimental\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve the relevant results\n",
    "results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/experimental\"  # real worms AllExperimental\n",
    "results_df = get_results_df(results_directory)\n",
    "results_df  # .head()\n",
    "\n",
    "# Example usage:\n",
    "parameters_scaling_plot(results_df, leg_code, title=\"All Experimental\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/synthetic\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve the relevant results\n",
    "# results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/synthetic/seed_0\"  # synthetic data Sines\n",
    "# results_df = get_results_df(results_directory)\n",
    "# results_df  # .head()\n",
    "\n",
    "# # Example usage:\n",
    "# parameters_scaling_plot(results_df, leg_code, title=\"Sines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve the relevant results\n",
    "# results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/synthetic/seed_1\"  # synthetic data Lorenz\n",
    "# results_df = get_results_df(results_directory)\n",
    "# results_df  # .head()\n",
    "\n",
    "# # Example usage:\n",
    "# parameters_scaling_plot(results_df, leg_code, title=\"Lorenz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve the relevant results\n",
    "# results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/synthetic/seed_2\"  # synthetic data White Noise\n",
    "# results_df = get_results_df(results_directory)\n",
    "# results_df  # .head()\n",
    "\n",
    "# # Example usage:\n",
    "# parameters_scaling_plot(results_df, leg_code, title=\"White Noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the relevant results\n",
    "results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_parameters/synthetic/seed_3\"  # synthetic data Random Walk\n",
    "results_df = get_results_df(results_directory)\n",
    "results_df  # .head()\n",
    "\n",
    "# Example usage:\n",
    "parameters_scaling_plot(results_df, leg_code, title=\"Random Walk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "\n",
    "\n",
    "def print_best_model_info(df):\n",
    "    \"\"\"\n",
    "    Prints the hidden size and number of parameters for the entry with the lowest min_val_loss\n",
    "    for each unique model type in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: A pandas DataFrame containing the model results.\n",
    "    \"\"\"\n",
    "    model_types = df[\"model_type\"].unique()\n",
    "    for model_type in model_types:\n",
    "        # Filter for the current model type\n",
    "        model_df = df[df[\"model_type\"] == model_type]\n",
    "\n",
    "        # Find the index of the minimum validation loss\n",
    "        idx_min_val_loss = model_df[\"min_val_loss\"].idxmin()\n",
    "\n",
    "        # Get the row for the minimum validation loss\n",
    "        min_val_loss_row = model_df.loc[idx_min_val_loss]\n",
    "\n",
    "        # Extract the hidden_size and num_parameters\n",
    "        hidden_size = min_val_loss_row[\"hidden_size\"]\n",
    "        num_parameters = min_val_loss_row[\"num_parameters\"]\n",
    "        min_val_loss = min_val_loss_row[\"min_val_loss\"]\n",
    "\n",
    "        print(\n",
    "            f\"The {model_type} model achieved its lowest min_val_loss of {min_val_loss:.6f} \"\n",
    "            f\"with a hidden_size of {hidden_size} and num_parameters of {num_parameters}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "print_best_model_info(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixed Dataset Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "\n",
    "\n",
    "def mixed_scaling_plot(combined_results_df, legend_code):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    for model_type, model_group in combined_results_df.groupby(\"model_type\"):\n",
    "        # Skip if unrecognized type of model\n",
    "        if model_type not in legend_code[\"model_labels\"]:\n",
    "            continue\n",
    "\n",
    "        # Obtain values for plotting\n",
    "        nts = model_group[\"num_time_steps\"]\n",
    "        val_loss = model_group[\"min_val_loss\"]\n",
    "        baseline_loss = model_group[\"val_baseline\"].iloc[0]  # Baseline is constant\n",
    "\n",
    "        # Plot settings from legend_code\n",
    "        model_label = legend_code[\"model_labels\"][model_type]\n",
    "        marker = legend_code[\"model_marker_code\"][model_label]\n",
    "        color = legend_code[\"model_color_code\"][model_label]\n",
    "\n",
    "        # Scatter plot\n",
    "        ax.scatter(\n",
    "            nts,\n",
    "            val_loss,\n",
    "            marker=marker,\n",
    "            color=color,  # TODO: is this preventing the alpha from kicking in?\n",
    "            s=7,\n",
    "            label=None,\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "        # Baseline plot\n",
    "        ax.axhline(\n",
    "            baseline_loss,\n",
    "            label=\"Baseline\"\n",
    "            if model_type == list(legend_code[\"model_labels\"].values())[0]\n",
    "            else \"_nolegend_\",\n",
    "            color=\"black\",\n",
    "            alpha=0.7,\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "\n",
    "        # Regression line\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            np.log(nts), np.log(val_loss)\n",
    "        )\n",
    "        fit_label = f\"y = {slope:.2f}x + {intercept:.1f}\\n\" f\"$R^2={r_value**2:.2f}$\"\n",
    "        x_fit = np.linspace(nts.min(), nts.max(), 10000)\n",
    "        y_fit = np.exp(intercept + slope * np.log(x_fit))\n",
    "\n",
    "        ax.plot(x_fit, y_fit, color=color, label=fit_label)\n",
    "\n",
    "    # Handles and labels for first legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    # Create the second legend\n",
    "    legend2 = ax.legend(\n",
    "        handles=legend_code[\"marker_legend\"],\n",
    "        loc=\"center right\",\n",
    "        bbox_to_anchor=(0.995, 0.85),\n",
    "        title=\"Model architecture\",\n",
    "    )\n",
    "    ax.get_legend().get_title().set_fontstyle(\"italic\")\n",
    "    ax.get_legend().get_title().set_fontsize(\"large\")\n",
    "    ax.add_artist(legend2)\n",
    "\n",
    "    # Display both legends\n",
    "    ax.legend(\n",
    "        handles, labels, loc=\"center left\", bbox_to_anchor=(0.01, 0.25), fontsize=12\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Num. train time steps\", fontsize=12)\n",
    "    ax.set_ylabel(\"Validation MSE Loss\", fontsize=12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_time_steps/experimental\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the relevant results\n",
    "results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_time_steps/experimental\"\n",
    "results_df = get_results_df(results_directory)\n",
    "results_df  # .head()\n",
    "\n",
    "# Example usage\n",
    "mixed_scaling_plot(results_df, leg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Dataset Scaling\n",
    "`results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_time_steps/experimental\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%cudf.pandas.profile\n",
    "\n",
    "\n",
    "def individual_scaling_plot(combined_results_df, legend_code):\n",
    "    fig, axs = plt.subplots(\n",
    "        1, len(combined_results_df[\"model_type\"].unique()), figsize=(15, 5)\n",
    "    )\n",
    "\n",
    "    if len(combined_results_df[\"model_type\"].unique()) > 1:\n",
    "        axs = axs.flatten()\n",
    "    else:\n",
    "        axs = [axs]\n",
    "\n",
    "    for idx, (model_type, model_group) in enumerate(\n",
    "        combined_results_df.groupby(\"model_type\")\n",
    "    ):\n",
    "        model_label = legend_code[\"model_labels\"][model_type]\n",
    "\n",
    "        ax = axs[idx]\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set_yscale(\"log\")\n",
    "\n",
    "        for dataset_name, dataset_group in model_group.groupby(\"validation_dataset\"):\n",
    "            color = legend_code[\"dataset_color_code\"][dataset_name]\n",
    "\n",
    "            # Scatter plot for individual dataset\n",
    "            ax.scatter(\n",
    "                dataset_group[\"num_time_steps\"],\n",
    "                dataset_group[\"validation_loss\"],\n",
    "                s=7,\n",
    "                color=color,\n",
    "                label=dataset_name,\n",
    "                alpha=0.3,\n",
    "            )\n",
    "\n",
    "            # Baseline horizontal line\n",
    "            baseline_loss = dataset_group[\"validation_baseline\"].iloc[0]\n",
    "            ax.axhline(\n",
    "                y=baseline_loss,\n",
    "                color=color,\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1,\n",
    "                alpha=0.7,\n",
    "                label=f\"{dataset_name} baseline\",\n",
    "            )\n",
    "\n",
    "            # Linear regression\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "                np.log(dataset_group[\"num_time_steps\"]),\n",
    "                np.log(dataset_group[\"validation_loss\"]),\n",
    "            )\n",
    "\n",
    "            # Plot regression line\n",
    "            x_reg = np.linspace(\n",
    "                dataset_group[\"num_time_steps\"].min(),\n",
    "                dataset_group[\"num_time_steps\"].max(),\n",
    "                100,\n",
    "            )\n",
    "            y_reg = np.exp(intercept + slope * np.log(x_reg))\n",
    "            ax.plot(x_reg, y_reg, color=color)\n",
    "\n",
    "        ax.set_title(model_label, fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Num. train time steps\")\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel(\"Validation Loss\")\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "    # Adjust the layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the relevant results\n",
    "results_directory = \"/om2/vast/yanglab/shared/qsimeon/worm-graph-experiments/num_time_steps/experimental\"\n",
    "results_df = get_results_df(results_directory)\n",
    "results_df.head()\n",
    "\n",
    "# Example usage:\n",
    "individual_scaling_plot(results_df, leg_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Cross Dataset Generalization\n",
    "A heatmap showing the validation loss on all of the experimental datasets after a model has been trained on just one of the experimental datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5. Cross-dataset Generalization plot\n",
    "# def cross_dataset(experiment_log_folders, model_names, legend_code):\n",
    "#     dataset_labels = legend_code[\"dataset_labels\"]\n",
    "\n",
    "#     analysis_df = pd.DataFrame(\n",
    "#         columns=[\n",
    "#             \"experiment_ID\",\n",
    "#             \"model_type\",\n",
    "#             \"train_dataset\",\n",
    "#             \"val_dataset\",\n",
    "#             \"val_loss\",\n",
    "#             \"val_baseline\",\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     for exp_log_dir, model in zip(experiment_log_folders, model_names):\n",
    "#         for experiment_ID in sorted(\n",
    "#             os.listdir(exp_log_dir), key=lambda x: x.strip(\"exp_\")\n",
    "#         ):\n",
    "#             # Skip if not starts with exp\n",
    "#             if not experiment_ID.startswith(\"exp\") or experiment_ID.startswith(\"exp_\"):\n",
    "#                 continue\n",
    "\n",
    "#             val_url = os.path.join(\n",
    "#                 exp_log_dir,\n",
    "#                 experiment_ID,\n",
    "#                 \"analysis\",\n",
    "#                 \"validation_loss_per_dataset.csv\",\n",
    "#             )\n",
    "#             train_ds_url = os.path.join(\n",
    "#                 exp_log_dir, experiment_ID, \"dataset\", \"train_dataset_info.csv\"\n",
    "#             )\n",
    "\n",
    "#             val_df = pd.read_csv(val_url)\n",
    "#             val_df[\"experiment_ID\"] = experiment_ID\n",
    "#             val_df[\"model_type\"] = model\n",
    "\n",
    "#             train_dataset_info = pd.read_csv(train_ds_url)\n",
    "#             val_df[\"train_dataset\"] = train_dataset_info[\"dataset\"].unique()[0]\n",
    "\n",
    "#             # Change 'dataset' column name to 'val_dataset'\n",
    "#             val_df = val_df.rename(columns={\"dataset\": \"val_dataset\"})\n",
    "\n",
    "#             # Swap uzel and kaplan\n",
    "#             val_df = val_df.iloc[[0, 1, 2, 4, 3, 5, 6], :]\n",
    "#             val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "#             analysis_df = pd.concat([analysis_df, val_df], axis=0)\n",
    "\n",
    "#     train_ds_names = [\n",
    "#         \"Leifer2023\",\n",
    "#         \"Flavell2023\",\n",
    "#         \"Uzel2022\",\n",
    "#         \"Yemini2021\",\n",
    "#         \"Kaplan2020\",\n",
    "#         \"Skora2018\",\n",
    "#         \"Nichols2017\",\n",
    "#         \"Kato2015\",\n",
    "#     ]\n",
    "#     val_ds_names = analysis_df[\"val_dataset\"].unique()\n",
    "#     models = analysis_df[\"model_type\"].unique()\n",
    "\n",
    "#     # Figure size\n",
    "#     fig, ax = plt.subplots(1, len(models), figsize=(12, 4), sharex=\"col\", sharey=\"row\")\n",
    "\n",
    "#     # Initialize vmin and vmax for the color scale\n",
    "#     vmin = analysis_df[\"val_loss\"].min()\n",
    "#     vmax = analysis_df[\"val_loss\"].max()\n",
    "\n",
    "#     for i, model_name in enumerate(models):\n",
    "#         # Filter data for the specific model\n",
    "#         df_model_subset = analysis_df[analysis_df[\"model_type\"] == model_name]\n",
    "\n",
    "#         # Create an empty matrix for the heatmap data\n",
    "#         heatmap_data = pd.DataFrame(columns=train_ds_names, index=val_ds_names)\n",
    "\n",
    "#         for train_ds in train_ds_names:\n",
    "#             for val_ds in val_ds_names:\n",
    "#                 value = df_model_subset[\n",
    "#                     (df_model_subset[\"train_dataset\"] == train_ds)\n",
    "#                     & (df_model_subset[\"val_dataset\"] == val_ds)\n",
    "#                 ][\"val_loss\"].values\n",
    "#                 if value:\n",
    "#                     heatmap_data.at[val_ds, train_ds] = value[0]\n",
    "\n",
    "#         # Plot the heatmap\n",
    "#         sns.heatmap(\n",
    "#             heatmap_data.astype(float),\n",
    "#             cmap=\"magma_r\",\n",
    "#             ax=ax[i],\n",
    "#             annot=True,\n",
    "#             square=True,\n",
    "#             cbar=False,\n",
    "#             vmin=vmin,\n",
    "#             vmax=vmax,\n",
    "#         )\n",
    "#         ax[i].set_title(\"{}\".format(model_name), fontsize=16)\n",
    "#         # Set xlabel\n",
    "#         ax[i].set_xlabel(\"Train dataset\", fontsize=14, fontweight=\"bold\")\n",
    "#         ax[i].set_xticklabels(dataset_labels, rotation=90, fontsize=10)\n",
    "#         # Set ylabel\n",
    "#         ax[0].set_ylabel(\"Validation dataset\", fontsize=14, fontweight=\"bold\")\n",
    "#         ax[i].set_yticklabels(dataset_labels, rotation=0, fontsize=10)\n",
    "\n",
    "#     # Add a single colorbar at the rightmost part\n",
    "#     cbar_ax = fig.add_axes(\n",
    "#         [0.92, 0.125, 0.02, 0.755]\n",
    "#     )  # [left, bottom, width, height] of the colorbar axes in figure coordinates.\n",
    "#     fig.colorbar(\n",
    "#         ax[-1].collections[0], cax=cbar_ax\n",
    "#     )  # ax[-1].collections[0] grabs the colormap of the last subplot\n",
    "\n",
    "#     # Add title to cmap\n",
    "#     cbar_ax.set_ylabel(\n",
    "#         \"Validation loss (MSE)\",\n",
    "#         fontsize=12,\n",
    "#         fontweight=\"bold\",\n",
    "#         rotation=90,\n",
    "#         labelpad=-57,\n",
    "#     )\n",
    "\n",
    "#     plt.tight_layout(pad=0.1)\n",
    "#     plt.subplots_adjust(\n",
    "#         right=0.9\n",
    "#     )  # adjust the rightmost part to make room for the colorbar\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_log_folders = [\n",
    "#     os.path.join(\"results\", \"CDS_LINEAR\"),  # Linear trial 1\n",
    "#     os.path.join(\"results\", \"CDS_LSTM\"),  # LSTM trial 1\n",
    "#     os.path.join(\"results\", \"CDS_TRANSFORMER\"),  # Transformer trial 1\n",
    "# ]\n",
    "\n",
    "# model_names = [\"Feedforward\", \"LSTM\", \"Transformer\"]\n",
    "\n",
    "# cross_dataset(\n",
    "#     experiment_log_folders=experiment_log_folders,\n",
    "#     model_names=model_names,\n",
    "#     legend_code=leg_code,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
