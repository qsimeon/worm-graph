{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate future prediction capacity of trained models\n",
    "Evaluate the ability of trained models optimized for next timestep (i.e. 1 step ahead) prediction to generalize to predicting longer horizons (i.e. an arbitrary number of future timesteps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from data._utils import load_Uzel2022, load_Skora2018\n",
    "from models._main import get_model\n",
    "from models._utils import *\n",
    "from omegaconf import OmegaConf\n",
    "from utils import DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model from the config file (simpler)\n",
    "\n",
    "# load config\n",
    "config_path = \"../logs/hydra/2023_06_11_02_22_23/5/config.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "print(\"config:\", OmegaConf.to_yaml(config), end=\"\\n\\n\")\n",
    "\n",
    "# training params\n",
    "epoch = config.train.epochs\n",
    "seq_len = config.train.seq_len\n",
    "tau = config.train.tau_in\n",
    "smooth_data = config.globals.smooth_data\n",
    "\n",
    "# names\n",
    "model_name = config.model.type\n",
    "train_dataset_name = config.dataset.name\n",
    "\n",
    "# print info\n",
    "print(\n",
    "    \"{} model was trained on dataset {} containing sequences of length \"\n",
    "    \"{} for {} epochs to predict {} timesteps into the future.\".format(\n",
    "        model_name,\n",
    "        train_dataset_name,\n",
    "        seq_len,\n",
    "        epoch,\n",
    "        tau,\n",
    "    ),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "\n",
    "# load the pretrained model\n",
    "model = get_model(config)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T18:27:15.451271Z",
     "start_time": "2023-04-11T18:27:15.437906Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load a trained model from the saved checkpoint (more complicated)\n",
    "\n",
    "# # load checkpoint\n",
    "# checkpoint_path = (\n",
    "#     \"../logs/hydra/2023_06_07_19_48_20/checkpoints/10_epochs_1030_worms.pt\"\n",
    "# )\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=torch.device(DEVICE))\n",
    "\n",
    "# # Get checkpoint variables\n",
    "# # state dictionaries\n",
    "# model_state_dict = checkpoint[\"model_state_dict\"]\n",
    "\n",
    "# # training params\n",
    "# epoch = checkpoint[\"epoch\"]\n",
    "# seq_len = checkpoint[\"seq_len\"]\n",
    "# tau = checkpoint[\"tau\"]\n",
    "# smooth_data = checkpoint[\"smooth_data\"]\n",
    "\n",
    "# # model instance params\n",
    "# input_size = checkpoint[\"input_size\"]\n",
    "# hidden_size = checkpoint[\"hidden_size\"]\n",
    "# num_layers = checkpoint[\"num_layers\"]\n",
    "# loss_name = checkpoint[\"loss_name\"]\n",
    "# fft_reg_param = checkpoint[\"fft_reg_param\"]\n",
    "# l1_reg_param = checkpoint[\"l1_reg_param\"]\n",
    "\n",
    "# # names\n",
    "# model_name = checkpoint[\"model_name\"]\n",
    "# train_dataset_name = checkpoint[\"dataset_name\"]\n",
    "\n",
    "# # print info\n",
    "# print(\n",
    "#     \"{} model was trained on dataset {} containing sequences of length \"\n",
    "#     \"{} for {} epochs to predict {} timesteps into the future.\".format(\n",
    "#         model_name,\n",
    "#         train_dataset_name,\n",
    "#         seq_len,\n",
    "#         epoch,\n",
    "#         tau,\n",
    "#     ),\n",
    "#     end=\"\\n\\n\",\n",
    "# )\n",
    "\n",
    "# # Load the model checkpoint\n",
    "# model = eval(model_name)(\n",
    "#     input_size,\n",
    "#     hidden_size,\n",
    "#     num_layers,\n",
    "#     loss=loss_name,\n",
    "#     fft_reg_param=fft_reg_param,\n",
    "#     l1_reg_param=l1_reg_param,\n",
    "# )\n",
    "# model.load_state_dict(model_state_dict)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally evaluate the model on a test dataset that it was not trained on\n",
    "\n",
    "# test_dataset = load_Uzel2022()  # dataset of multiple worms\n",
    "test_dataset = load_Skora2018()  # dataset of multiple worms\n",
    "\n",
    "# determine if the test dataset was seen during training\n",
    "test_dataset_name = test_dataset[\"worm0\"][\"dataset\"]\n",
    "in_distribution = test_dataset_name in train_dataset_name\n",
    "dataset_inclusion_str = int(not in_distribution) * \"un\" + \"familiar\"\n",
    "print(\n",
    "    \"The (train) dataset(s) the model was trained on:\", train_dataset_name, end=\"\\n\\n\"\n",
    ")\n",
    "print(\"The (test) dataset(s) to make predictions on:\", test_dataset_name, end=\"\\n\\n\")\n",
    "print(\"Was the test dataset seen during training?\", \"YES\" if in_distribution else \"NO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values from the test dataset to use for prediciton and plots\n",
    "\n",
    "named_neurons_mask = test_dataset[\"worm0\"][\"named_neurons_mask\"]\n",
    "if smooth_data:\n",
    "    calcium_data = test_dataset[\"worm0\"][\"smooth_calcium_data\"]\n",
    "else:\n",
    "    calcium_data = test_dataset[\"worm0\"][\"calcium_data\"]\n",
    "time_in_seconds = test_dataset[\"worm0\"][\"time_in_seconds\"]\n",
    "max_timesteps = test_dataset[\"worm0\"][\"max_timesteps\"]\n",
    "slot_to_named_neuron = test_dataset[\"worm0\"][\"slot_to_named_neuron\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the model's ability to complete a sequence\n",
    "\n",
    "context_len = 200  # max_timesteps // 2\n",
    "new_timesteps = 200\n",
    "start_time_slice = range(0, context_len)\n",
    "future_time_slice = range(context_len, context_len + new_timesteps)\n",
    "complete_time_slice = range(0, context_len + new_timesteps)\n",
    "\n",
    "input_ = calcium_data[start_time_slice, :] * named_neurons_mask\n",
    "target = calcium_data[future_time_slice, :] * named_neurons_mask\n",
    "\n",
    "# put on device\n",
    "model = model.to(DEVICE)\n",
    "input_ = input_.to(DEVICE)\n",
    "\n",
    "output = model.generate(input_, new_timesteps, mask=named_neurons_mask).cpu().squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of the labeled neurons in the test dataset to inspect\n",
    "\n",
    "named_neuron_inds = torch.where(named_neurons_mask)[0].numpy()\n",
    "nidx = np.random.choice(named_neuron_inds)  # pick a neuron to plot (random)\n",
    "# nidx = 53  # index for neuron AVAL (consistent)\n",
    "neuron_name = slot_to_named_neuron[nidx]\n",
    "\n",
    "print(\"picked neuron index:\", nidx)\n",
    "print(\"picked neuron name:\", neuron_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot what the generations versus real data look like\n",
    "\n",
    "plt.plot(\n",
    "    time_in_seconds[future_time_slice],\n",
    "    target[:, nidx],\n",
    "    color=\"magenta\",\n",
    "    label=\"desired sequence\",\n",
    "    alpha=0.8,\n",
    "    linewidth=3,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    time_in_seconds[complete_time_slice],\n",
    "    output[:, nidx],\n",
    "    color=\"green\",\n",
    "    label=\"completed sequence\",\n",
    "    alpha=0.6,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    time_in_seconds[start_time_slice],\n",
    "    input_[:, nidx],\n",
    "    color=\"black\",\n",
    "    label=\"starting sequence\",\n",
    "    alpha=1.0,\n",
    "    linewidth=2,\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "plt.ylabel(\"$\\Delta F / F$\")\n",
    "plt.ylim([-3.0, 3.0])\n",
    "plt.title(\n",
    "    \"Generated %s future timesteps ahead on %s dataset with pre-trained model\\nPretrained model: %s \\nTest dataset: %s \\nPredicted neuron: %s\"\n",
    "    % (\n",
    "        new_timesteps,\n",
    "        dataset_inclusion_str,\n",
    "        model_name,\n",
    "        test_dataset_name,\n",
    "        neuron_name,\n",
    "    )\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
