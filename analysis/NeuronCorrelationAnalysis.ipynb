{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform autocorrelation analysis of neurons across worms and datasets\n",
    "---\n",
    "@anshul Please provide a descriptive header title and then a short paragraph description of every notebook you write.\n",
    "\n",
    "---\n",
    "To study the auto-correlation and cross-correlation structure of different neurons. When do these fall to zero?\n",
    "\n",
    "Temporal Structure Analysis and Request for Guidance: While we acknowledge the potential insights that could be derived from studying the auto-correlation and cross-correlation structure of different neurons, we face certain challenges with our dataset that make the execution of this analysis complex.\n",
    "\n",
    "Variability Across Subjects: The measured neurons vary from worm to worm, which means standardizing a correlation analysis across multiple datasets is not straightforward. If in a particular worm there are $k$ measured/labelled neurons (out of the possible $300$), we would be conducting $k$ autocorrelations and $k(k-1)$ cross-correlations for that worm, but the comparison across different worms and datasets becomes less clear.\n",
    "\n",
    "Aggregation of Analysis: Aggregating this data meaningfully poses a significant challenge. We are considering focusing on common neurons measured across worms and applying statistical methods to manage missing data.\n",
    "\n",
    "The cross-correlation and auto-correlation need only be computed for a relatively short number of lags, since long lags become more independent as behavior is not typically periodic. While I agree that this would require some careful bookkeeping, it is straightforward to script. Estimates of the correlation functions themselves would be computed within a worm recording for all pairs (including self). Then when you are getting average across worm recording dataset you may not have all pairs, but simply average what is available. Of course the number will vary by neuron-to-neuron pair but that is fine.\n",
    "\n",
    "---\n",
    "\n",
    "*Last updated: 1 July 2024*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from utils import NEURON_LABELS\n",
    "from data._utils import pick_worm, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate_with_specific_lag(f, g, lag):\n",
    "    g = np.pad(g[lag:], (0, lag), 'constant')\n",
    "    if len(f) > len(g):\n",
    "        g = np.pad(g[lag:], (0, lag+(len(f)-len(g))), 'constant')\n",
    "    else:\n",
    "        f = np.pad(f, (0, len(g)-len(f)), 'constant')\n",
    "    return np.sum(np.multiply(f, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlate(X1, X2, lag_limit):\n",
    "    vals = []\n",
    "    for i in range(lag_limit):\n",
    "        vals += [correlate_with_specific_lag(X1, X2, i)]\n",
    "\n",
    "    arr = np.array(vals)\n",
    "    final_arr = arr / np.max(np.abs(arr))\n",
    "    \n",
    "    return final_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_crosscorrelation(X, worm_idx=0, lag_limit=100, dataset=\"\", mask=None):\n",
    "    \"\"\"\n",
    "    Plot the crosscorrelation for each neuron's trajectory.\n",
    "\n",
    "    Parameters:\n",
    "    - X: A 2D numpy array of shape (max_timesteps, num_neurons) containing the neural trajectory data.\n",
    "    - neurons: A list or array containing the neuron identifiers.\n",
    "\n",
    "    Returns:\n",
    "    - None: The function creates and displays a plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    worm_corr_data = np.zeros((len(mask), len(mask), lag_limit))\n",
    "\n",
    "    # Iterate over the number of neurons to create individual plots\n",
    "    for i in tqdm(range(len(mask))):\n",
    "        for j in range(len(mask)):\n",
    "            if mask[i] == True and mask[j] == True:\n",
    "                # 0 -> lag_limit\n",
    "                corr = cross_correlate(X[:, i], X[:, j], lag_limit)\n",
    "                \n",
    "                worm_corr_data[i, j] = corr\n",
    "            else:\n",
    "                worm_corr_data[i, j] = np.full((lag_limit,), np.NaN)\n",
    "    \n",
    "    if not os.path.exists(f\"../analysis/figures/corr_data\"):\n",
    "        os.makedirs(f\"../analysis/figures/corr_data\")\n",
    "                            \n",
    "    np.save('../analysis/figures/corr_data/worm_' + str(dataset) + \"_\" + str(worm_idx) + '.npy', worm_corr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Kato2015\"\n",
    "Kato2015 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Nichols2017\"\n",
    "Nichols2017 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Skora2018\"\n",
    "Skora2018 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Kaplan2020\"\n",
    "Kaplan2020 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Yemini2021\"\n",
    "Yemini2021 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Uzel2022\"\n",
    "Uzel2022 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Lin2023\"\n",
    "Lin2023 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Leifer2023\"\n",
    "Leifer2023 = load_dataset(dataset_name)\n",
    "\n",
    "dataset_name = \"Flavell2023\"\n",
    "Flavell2023 = load_dataset(dataset_name)\n",
    "\n",
    "datasets = [Kato2015, Nichols2017, Skora2018, Kaplan2020, Yemini2021, Uzel2022, Lin2023, Leifer2023, Flavell2023]\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "        if i >= -1:\n",
    "                worms = list(dataset.keys())   \n",
    "                for idx in tqdm(range(len(worms))):\n",
    "                        if i != 6 or (i == 6 and idx > 443):\n",
    "                                worm = worms[idx]\n",
    "\n",
    "                                single_worm_dataset = pick_worm(dataset, worm)\n",
    "\n",
    "                                data = single_worm_dataset[\"calcium_data\"]\n",
    "                                mask = single_worm_dataset[\"named_neurons_mask\"]\n",
    "                                neurons = sorted(single_worm_dataset[\"named_neuron_to_slot\"])\n",
    "\n",
    "                                # X = data[:, mask].numpy()\n",
    "                                X = data.numpy()\n",
    "\n",
    "                                # plot autocorrelation and partial autocorrelation\n",
    "                                save_crosscorrelation(X, idx, 100, i, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce figures from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all data\n",
    "print(\"Collecting data...\")\n",
    "\n",
    "worm_files = sorted(os.listdir(\"../analysis/figures/corr_data\"))\n",
    "print(worm_files)\n",
    "seperated_files = [[]]\n",
    "\n",
    "curr_set = 0\n",
    "\n",
    "datasets = [\"Kato2015\", \"Nichols2017\", \"Skora2018\", \"Kaplan2020\", \"Yemini2021\", \"Uzel2022\", \"Lin2023\", \"Leifer2023\", \"Flavell2023\"]\n",
    "\n",
    "if not os.path.exists(f\"../analysis/figures/analysis/figures/corr_figs\"):\n",
    "    os.makedirs(f\"../analysis/figures/corr_figs\")\n",
    "                            \n",
    "for file in worm_files:\n",
    "    file_set = int(file.split(\"_\")[1])\n",
    "    if file_set != curr_set:\n",
    "        curr_set = file_set\n",
    "        seperated_files += [[file]]\n",
    "    else:\n",
    "        seperated_files[-1] += [file]\n",
    "\n",
    "for set_idx, files in enumerate(seperated_files):\n",
    "    if set_idx != 6 and set_idx > 0:\n",
    "        all_data = np.empty((len(files), 300, 300, 100))\n",
    "        for i, file in tqdm(enumerate(files)):\n",
    "            all_data[i] = np.load(f'../analysis/figures/corr_data/{file}')\n",
    "\n",
    "        # filter data\n",
    "        # length of filtered data list is 300 neurons*300 neurons\n",
    "        print(\"Filtering data...\")\n",
    "\n",
    "        filtered_data = [None for i in range(300**2)]\n",
    "\n",
    "        for i in tqdm(range(all_data.shape[1])):\n",
    "            for j in range(all_data.shape[2]):\n",
    "                for worm_idx in range(all_data.shape[0]):\n",
    "                    if filtered_data[i*all_data.shape[1]+j] is None and not np.any(np.isnan(all_data[worm_idx, i, j])):\n",
    "                        filtered_data[i*all_data.shape[1]+j] = [all_data[worm_idx, i, j]]\n",
    "                    elif not np.any(np.isnan(all_data[worm_idx, i, j])):\n",
    "                        filtered_data[i*all_data.shape[1]+j] += [all_data[worm_idx, i, j]]\n",
    "\n",
    "        for i in range(len(filtered_data)):\n",
    "            if filtered_data[i] is not None:\n",
    "                filtered_data[i] = np.array(filtered_data[i])\n",
    "\n",
    "        # generate plots \n",
    "        print(\"Generating plots...\")\n",
    "            \n",
    "        for i, neuron1 in enumerate(NEURON_LABELS):\n",
    "            if i > -1:\n",
    "                for j, neuron2 in tqdm(enumerate(NEURON_LABELS)):\n",
    "                    if filtered_data[i*len(NEURON_LABELS)+j] is not None:\n",
    "                        plt.figure()\n",
    "                        plt.ylim(-1, 1)\n",
    "                        \n",
    "                        plt.title(f\"Dataset {datasets[set_idx]}: {neuron1}_{neuron2}\")\n",
    "                        plt.xlabel(\"Lag\")\n",
    "                        plt.ylabel(\"Correlation Score\")\n",
    "                        \n",
    "                        mean = np.mean(filtered_data[i*len(NEURON_LABELS)+j], axis=0)\n",
    "                        std = np.std(filtered_data[i*len(NEURON_LABELS)+j], axis=0)\n",
    "\n",
    "                        plt.plot(np.arange(0, 100, 1), mean, linewidth=5.0, alpha=1.0, color=\"cornflowerblue\")\n",
    "\n",
    "                        for k in filtered_data[i*len(NEURON_LABELS)+j]:\n",
    "                            plt.plot(np.arange(0, 100, 1), k, alpha=0.3, color=\"cornflowerblue\")\n",
    "\n",
    "                        z=1\n",
    "                        plt.fill_between(np.arange(0, 100, 1), mean-(std*z), mean+(std*z), alpha=0.4)  \n",
    "                        \n",
    "                        if not os.path.exists(f\"../analysis/figures/corr_figs/{set_idx}\"):\n",
    "                            os.makedirs(f\"../analysis/figures/corr_figs/{set_idx}\")\n",
    "                            \n",
    "                        if not os.path.exists(f\"../analysis/figures/corr_figs/{set_idx}/{neuron1}\"):\n",
    "                            os.makedirs(f\"../analysis/figures/corr_figs/{set_idx}/{neuron1}\")\n",
    "                            \n",
    "                        plt.savefig(f\"../analysis/figures/corr_figs/{set_idx}/{neuron1}/{neuron1}_{neuron2}.png\")\n",
    "                        plt.clf()\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Autocorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(\"../analysis/figures/corr_figs\")\n",
    "file_paths = []\n",
    "\n",
    "for directory in dirs:\n",
    "    subdirs = os.listdir(\"../analysis/figures/corr_figs/\" + directory)\n",
    "    for subdir in subdirs:\n",
    "        file_paths += [f\"../analysis/figures/corr_figs/{directory}/{subdir}/{subdir}_{subdir}.png\"]\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"../analysis/figures/autocorr_figs\"):\n",
    "    os.makedirs(f\"../analysis/figures/autocorr_figs\")\n",
    "                            \n",
    "for file in file_paths:\n",
    "    split_path = file.split(\"/\")\n",
    "    dataset = split_path[2]\n",
    "    if not os.path.exists(f\"../analysis/figures/autocorr_figs/{dataset}\"):\n",
    "        os.makedirs(f\"../analysis/figures/autocorr_figs/{dataset}\")\n",
    "    shutil.copyfile(file, f\"{split_path[0]}/autocorr_figs/{split_path[2]}/{split_path[-1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
