{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found.\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from utils import DEVICE, BLOCK_SIZE, NUM_TOKENS, init_random_seeds\n",
    "from CreateSyntheticDataset import tokenize_and_chunk  # works because of nbimporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `tokenizer.encode(text)`:\n",
      "\ttext: Welcome to the ðŸ¤— Tokenizers library.\n",
      "\ttokenized: [90, 104, 111, 102, 114, 112, 104, 35, 119, 114, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 114, 110, 104, 113, 108, 125, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: Welcome to the ðŸ¤— Tokenizers library.</s>\n",
      "\n",
      "Calling `tokenizer(text)`:\n",
      "\tobject.keys(): dict_keys(['input_ids', 'attention_mask'])\n",
      "\ttext: We are very happy to show you the ðŸ¤— Transformers library.\n",
      "\ttokenized: [90, 104, 35, 100, 117, 104, 35, 121, 104, 117, 124, 35, 107, 100, 115, 115, 124, 35, 119, 114, 35, 118, 107, 114, 122, 35, 124, 114, 120, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 117, 100, 113, 118, 105, 114, 117, 112, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: We are very happy to show you the ðŸ¤— Transformers library.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-large\")\n",
    "\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "train: <class 'list'> 1 <class 'str'> 1003854\n",
      "\n",
      "validation: <class 'list'> 1 <class 'str'> 55770\n",
      "\n",
      "test: <class 'list'> 1 <class 'str'> 55770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1963\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "text_dataset['train']['input_ids']:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 1963\n",
      "\n",
      "text_dataset['train']['input_ids'][0]:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 506\n",
      "\n",
      "text_dataset['train']['input_ids'][0][0]:\n",
      " \ttype: <class 'int'> \n",
      "\tvalue: 73\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Original sequence (text):\n",
      "\tFirst Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the\n",
      "\n",
      "Encoded sequence (tokens):\n",
      "\t [73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 69, 104, 105, 114, 117, 104, 35, 122, 104, 35, 115, 117, 114, 102, 104, 104, 103, 35, 100, 113, 124, 35, 105, 120, 117, 119, 107, 104, 117, 47, 35, 107, 104, 100, 117, 35, 112, 104, 35, 118, 115, 104, 100, 110, 49, 35, 68, 111, 111, 61, 35, 86, 115, 104, 100, 110, 47, 35, 118, 115, 104, 100, 110, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 92, 114, 120, 35, 100, 117, 104, 35, 100, 111, 111, 35, 117, 104, 118, 114, 111, 121, 104, 103, 35, 117, 100, 119, 107, 104, 117, 35, 119, 114, 35, 103, 108, 104, 35, 119, 107, 100, 113, 35, 119, 114, 35, 105, 100, 112, 108, 118, 107, 66, 35, 68, 111, 111, 61, 35, 85, 104, 118, 114, 111, 121, 104, 103, 49, 35, 117, 104, 118, 114, 111, 121, 104, 103, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 73, 108, 117, 118, 119, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 35, 70, 100, 108, 120, 118, 35, 80, 100, 117, 102, 108, 120, 118, 35, 108, 118, 35, 102, 107, 108, 104, 105, 35, 104, 113, 104, 112, 124, 35, 119, 114, 35, 119, 107, 104, 35, 115, 104, 114, 115, 111, 104, 49, 35, 68, 111, 111, 61, 35, 90, 104, 35, 110, 113, 114, 122, 42, 119, 47, 35, 122, 104, 35, 110, 113, 114, 122, 42, 119, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 79, 104, 119, 35, 120, 118, 35, 110, 108, 111, 111, 35, 107, 108, 112, 47, 35, 100, 113, 103, 35, 122, 104, 42, 111, 111, 35, 107, 100, 121, 104, 35, 102, 114, 117, 113, 35, 100, 119, 35, 114, 120, 117, 35, 114, 122, 113, 35, 115, 117, 108, 102, 104, 49, 35, 76, 118, 42, 119, 35, 100, 35, 121, 104, 117, 103, 108, 102, 119, 66, 35, 68, 111, 111, 61, 35, 81, 114, 35, 112, 114, 117, 104, 35, 119, 100, 111, 110, 108, 113, 106, 35, 114, 113, 42, 119, 62, 35, 111, 104, 119, 35, 108, 119, 35, 101, 104, 35, 103, 114, 113, 104, 61, 35, 100, 122, 100, 124, 47, 35, 100, 122, 100, 124, 36, 35, 86, 104, 102, 114, 113, 103, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 82, 113, 104, 35, 122, 114, 117, 103, 47, 35, 106, 114, 114, 103, 35, 102, 108, 119, 108, 125, 104, 113, 118, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 90, 104, 35, 100, 117, 104, 35, 100, 102, 102, 114, 120, 113, 119, 104, 103, 35, 115, 114, 114, 117, 35, 102, 108, 119, 108, 125, 104, 113, 118, 47, 35, 119, 107, 104, 1]\n",
      "\n",
      "Decoded sequence (tokens):\n",
      "\t First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 510]) torch.int64 False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create token datasets\n",
    "\n",
    "# train_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"train\"][\"input_ids\"]]\n",
    "train_dataset = [\n",
    "    torch.LongTensor(sequence[:-1])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"test\"][\"input_ids\"]]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Number of attn heads = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a TransformerModel\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Number of attn heads = {nhead}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler, criterion\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        tokens = train_dataset[batch].unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        input = tokens[:, :-1].to(DEVICE)  # ``[batch_size=1, seq_len]``\n",
    "        target = tokens[:, 1:].reshape(-1).to(DEVICE)  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            tokens = test_dataset[batch].unsqueeze(0)\n",
    "            input = tokens[:, :-1].to(DEVICE)\n",
    "            target = tokens[:, 1:].reshape(-1).to(DEVICE)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 2072 batches | lr 5.00 | ms/batch  7.48 | loss  3.38 | ppl    29.52\n",
      "| epoch   1 |   600/ 2072 batches | lr 5.00 | ms/batch  5.32 | loss  2.63 | ppl    13.91\n",
      "| epoch   1 |   900/ 2072 batches | lr 5.00 | ms/batch  5.31 | loss  2.59 | ppl    13.39\n",
      "| epoch   1 |  1200/ 2072 batches | lr 5.00 | ms/batch  5.32 | loss  2.55 | ppl    12.83\n",
      "| epoch   1 |  1500/ 2072 batches | lr 5.00 | ms/batch  5.32 | loss  2.53 | ppl    12.59\n",
      "| epoch   1 |  1800/ 2072 batches | lr 5.00 | ms/batch  5.31 | loss  2.50 | ppl    12.24\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 11.84s | valid loss  2.59 | valid ppl    13.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   2 |   300/ 2072 batches | lr 4.95 | ms/batch  5.33 | loss  2.50 | ppl    12.18\n",
      "| epoch   2 |   600/ 2072 batches | lr 4.95 | ms/batch  5.31 | loss  2.53 | ppl    12.55\n",
      "| epoch   2 |   900/ 2072 batches | lr 4.95 | ms/batch  5.30 | loss  2.54 | ppl    12.73\n",
      "| epoch   2 |  1200/ 2072 batches | lr 4.95 | ms/batch  5.29 | loss  2.52 | ppl    12.41\n",
      "| epoch   2 |  1500/ 2072 batches | lr 4.95 | ms/batch  5.31 | loss  2.54 | ppl    12.62\n",
      "| epoch   2 |  1800/ 2072 batches | lr 4.95 | ms/batch  5.30 | loss  2.49 | ppl    12.07\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 11.18s | valid loss  2.58 | valid ppl    13.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   3 |   300/ 2072 batches | lr 4.90 | ms/batch  5.32 | loss  2.49 | ppl    12.01\n",
      "| epoch   3 |   600/ 2072 batches | lr 4.90 | ms/batch  5.31 | loss  2.52 | ppl    12.41\n",
      "| epoch   3 |   900/ 2072 batches | lr 4.90 | ms/batch  5.31 | loss  2.54 | ppl    12.68\n",
      "| epoch   3 |  1200/ 2072 batches | lr 4.90 | ms/batch  5.31 | loss  2.51 | ppl    12.29\n",
      "| epoch   3 |  1500/ 2072 batches | lr 4.90 | ms/batch  5.31 | loss  2.50 | ppl    12.16\n",
      "| epoch   3 |  1800/ 2072 batches | lr 4.90 | ms/batch  5.30 | loss  2.48 | ppl    11.97\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 11.18s | valid loss  2.57 | valid ppl    13.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   4 |   300/ 2072 batches | lr 4.85 | ms/batch  5.31 | loss  2.48 | ppl    11.93\n",
      "| epoch   4 |   600/ 2072 batches | lr 4.85 | ms/batch  5.30 | loss  2.50 | ppl    12.15\n",
      "| epoch   4 |   900/ 2072 batches | lr 4.85 | ms/batch  5.31 | loss  2.52 | ppl    12.49\n",
      "| epoch   4 |  1200/ 2072 batches | lr 4.85 | ms/batch  5.31 | loss  2.50 | ppl    12.21\n",
      "| epoch   4 |  1500/ 2072 batches | lr 4.85 | ms/batch  8.49 | loss  2.49 | ppl    12.12\n",
      "| epoch   4 |  1800/ 2072 batches | lr 4.85 | ms/batch 14.17 | loss  2.47 | ppl    11.84\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 14.79s | valid loss  2.69 | valid ppl    14.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   300/ 2072 batches | lr 4.80 | ms/batch  5.33 | loss  2.47 | ppl    11.86\n",
      "| epoch   5 |   600/ 2072 batches | lr 4.80 | ms/batch  5.31 | loss  2.49 | ppl    12.10\n",
      "| epoch   5 |   900/ 2072 batches | lr 4.80 | ms/batch  5.30 | loss  2.52 | ppl    12.42\n",
      "| epoch   5 |  1200/ 2072 batches | lr 4.80 | ms/batch  5.31 | loss  2.50 | ppl    12.17\n",
      "| epoch   5 |  1500/ 2072 batches | lr 4.80 | ms/batch  5.31 | loss  2.49 | ppl    12.07\n",
      "| epoch   5 |  1800/ 2072 batches | lr 4.80 | ms/batch  5.31 | loss  2.47 | ppl    11.81\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 11.19s | valid loss  2.56 | valid ppl    12.93\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   6 |   300/ 2072 batches | lr 4.75 | ms/batch  5.32 | loss  2.47 | ppl    11.84\n",
      "| epoch   6 |   600/ 2072 batches | lr 4.75 | ms/batch  5.31 | loss  2.49 | ppl    12.02\n",
      "| epoch   6 |   900/ 2072 batches | lr 4.75 | ms/batch  5.31 | loss  2.53 | ppl    12.51\n",
      "| epoch   6 |  1200/ 2072 batches | lr 4.75 | ms/batch  5.31 | loss  2.49 | ppl    12.12\n",
      "| epoch   6 |  1500/ 2072 batches | lr 4.75 | ms/batch  5.32 | loss  2.49 | ppl    12.03\n",
      "| epoch   6 |  1800/ 2072 batches | lr 4.75 | ms/batch  5.32 | loss  2.47 | ppl    11.78\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 11.20s | valid loss  2.58 | valid ppl    13.22\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   300/ 2072 batches | lr 4.71 | ms/batch  5.33 | loss  2.48 | ppl    11.90\n",
      "| epoch   7 |   600/ 2072 batches | lr 4.71 | ms/batch  5.29 | loss  2.51 | ppl    12.34\n",
      "| epoch   7 |   900/ 2072 batches | lr 4.71 | ms/batch  5.30 | loss  2.51 | ppl    12.36\n",
      "| epoch   7 |  1200/ 2072 batches | lr 4.71 | ms/batch  5.29 | loss  2.49 | ppl    12.09\n",
      "| epoch   7 |  1500/ 2072 batches | lr 4.71 | ms/batch  5.31 | loss  2.49 | ppl    12.01\n",
      "| epoch   7 |  1800/ 2072 batches | lr 4.71 | ms/batch  5.29 | loss  2.46 | ppl    11.73\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 11.17s | valid loss  2.59 | valid ppl    13.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   300/ 2072 batches | lr 4.66 | ms/batch  5.31 | loss  2.47 | ppl    11.78\n",
      "| epoch   8 |   600/ 2072 batches | lr 4.66 | ms/batch  5.29 | loss  2.52 | ppl    12.45\n",
      "| epoch   8 |   900/ 2072 batches | lr 4.66 | ms/batch  5.31 | loss  2.52 | ppl    12.37\n",
      "| epoch   8 |  1200/ 2072 batches | lr 4.66 | ms/batch  5.28 | loss  2.50 | ppl    12.16\n",
      "| epoch   8 |  1500/ 2072 batches | lr 4.66 | ms/batch  5.28 | loss  2.48 | ppl    11.96\n",
      "| epoch   8 |  1800/ 2072 batches | lr 4.66 | ms/batch  5.31 | loss  2.46 | ppl    11.72\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 11.16s | valid loss  2.63 | valid ppl    13.84\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   300/ 2072 batches | lr 4.61 | ms/batch  5.32 | loss  2.46 | ppl    11.75\n",
      "| epoch   9 |   600/ 2072 batches | lr 4.61 | ms/batch  5.30 | loss  2.48 | ppl    11.93\n",
      "| epoch   9 |   900/ 2072 batches | lr 4.61 | ms/batch  5.28 | loss  2.51 | ppl    12.32\n",
      "| epoch   9 |  1200/ 2072 batches | lr 4.61 | ms/batch  5.30 | loss  2.49 | ppl    12.04\n",
      "| epoch   9 |  1500/ 2072 batches | lr 4.61 | ms/batch  5.30 | loss  2.48 | ppl    11.97\n",
      "| epoch   9 |  1800/ 2072 batches | lr 4.61 | ms/batch  5.31 | loss  2.46 | ppl    11.70\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 11.17s | valid loss  2.56 | valid ppl    12.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   300/ 2072 batches | lr 4.57 | ms/batch  5.33 | loss  2.46 | ppl    11.73\n",
      "| epoch  10 |   600/ 2072 batches | lr 4.57 | ms/batch  5.32 | loss  2.48 | ppl    11.94\n",
      "| epoch  10 |   900/ 2072 batches | lr 4.57 | ms/batch  5.30 | loss  2.51 | ppl    12.27\n",
      "| epoch  10 |  1200/ 2072 batches | lr 4.57 | ms/batch  5.74 | loss  2.49 | ppl    12.02\n",
      "| epoch  10 |  1500/ 2072 batches | lr 4.57 | ms/batch  6.11 | loss  2.48 | ppl    11.94\n",
      "| epoch  10 |  1800/ 2072 batches | lr 4.57 | ms/batch  5.40 | loss  2.46 | ppl    11.70\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 11.67s | valid loss  2.57 | valid ppl    13.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   300/ 2072 batches | lr 4.52 | ms/batch  5.79 | loss  2.46 | ppl    11.69\n",
      "| epoch  11 |   600/ 2072 batches | lr 4.52 | ms/batch  5.53 | loss  2.48 | ppl    11.94\n",
      "| epoch  11 |   900/ 2072 batches | lr 4.52 | ms/batch  5.65 | loss  2.51 | ppl    12.27\n",
      "| epoch  11 |  1200/ 2072 batches | lr 4.52 | ms/batch  5.31 | loss  2.48 | ppl    11.99\n",
      "| epoch  11 |  1500/ 2072 batches | lr 4.52 | ms/batch  5.30 | loss  2.48 | ppl    11.90\n",
      "| epoch  11 |  1800/ 2072 batches | lr 4.52 | ms/batch  5.34 | loss  2.45 | ppl    11.65\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 11.65s | valid loss  2.61 | valid ppl    13.55\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   300/ 2072 batches | lr 4.48 | ms/batch  7.58 | loss  2.46 | ppl    11.68\n",
      "| epoch  12 |   600/ 2072 batches | lr 4.48 | ms/batch  5.45 | loss  2.47 | ppl    11.85\n",
      "| epoch  12 |   900/ 2072 batches | lr 4.48 | ms/batch  6.97 | loss  2.51 | ppl    12.26\n",
      "| epoch  12 |  1200/ 2072 batches | lr 4.48 | ms/batch  5.33 | loss  2.48 | ppl    11.96\n",
      "| epoch  12 |  1500/ 2072 batches | lr 4.48 | ms/batch  5.40 | loss  2.47 | ppl    11.87\n",
      "| epoch  12 |  1800/ 2072 batches | lr 4.48 | ms/batch  5.76 | loss  2.46 | ppl    11.73\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 12.57s | valid loss  2.57 | valid ppl    13.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   300/ 2072 batches | lr 4.43 | ms/batch  5.32 | loss  2.50 | ppl    12.13\n",
      "| epoch  13 |   600/ 2072 batches | lr 4.43 | ms/batch  5.29 | loss  2.48 | ppl    11.89\n",
      "| epoch  13 |   900/ 2072 batches | lr 4.43 | ms/batch  5.29 | loss  2.50 | ppl    12.22\n",
      "| epoch  13 |  1200/ 2072 batches | lr 4.43 | ms/batch  5.30 | loss  2.48 | ppl    11.97\n",
      "| epoch  13 |  1500/ 2072 batches | lr 4.43 | ms/batch  5.30 | loss  2.47 | ppl    11.86\n",
      "| epoch  13 |  1800/ 2072 batches | lr 4.43 | ms/batch  5.30 | loss  2.45 | ppl    11.62\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 11.16s | valid loss  2.55 | valid ppl    12.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  14 |   300/ 2072 batches | lr 4.39 | ms/batch  5.31 | loss  2.45 | ppl    11.64\n",
      "| epoch  14 |   600/ 2072 batches | lr 4.39 | ms/batch  5.29 | loss  2.48 | ppl    11.98\n",
      "| epoch  14 |   900/ 2072 batches | lr 4.39 | ms/batch  5.30 | loss  2.51 | ppl    12.27\n",
      "| epoch  14 |  1200/ 2072 batches | lr 4.39 | ms/batch  5.31 | loss  2.48 | ppl    11.93\n",
      "| epoch  14 |  1500/ 2072 batches | lr 4.39 | ms/batch  5.30 | loss  2.47 | ppl    11.85\n",
      "| epoch  14 |  1800/ 2072 batches | lr 4.39 | ms/batch  5.31 | loss  2.45 | ppl    11.60\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 11.18s | valid loss  2.59 | valid ppl    13.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |   300/ 2072 batches | lr 4.34 | ms/batch  5.31 | loss  2.45 | ppl    11.62\n",
      "| epoch  15 |   600/ 2072 batches | lr 4.34 | ms/batch  5.30 | loss  2.47 | ppl    11.81\n",
      "| epoch  15 |   900/ 2072 batches | lr 4.34 | ms/batch  5.32 | loss  2.50 | ppl    12.16\n",
      "| epoch  15 |  1200/ 2072 batches | lr 4.34 | ms/batch  5.31 | loss  2.48 | ppl    11.94\n",
      "| epoch  15 |  1500/ 2072 batches | lr 4.34 | ms/batch  5.30 | loss  2.47 | ppl    11.83\n",
      "| epoch  15 |  1800/ 2072 batches | lr 4.34 | ms/batch  5.31 | loss  2.45 | ppl    11.60\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 11.19s | valid loss  2.59 | valid ppl    13.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   300/ 2072 batches | lr 4.30 | ms/batch  5.33 | loss  2.45 | ppl    11.60\n",
      "| epoch  16 |   600/ 2072 batches | lr 4.30 | ms/batch  5.31 | loss  2.47 | ppl    11.80\n",
      "| epoch  16 |   900/ 2072 batches | lr 4.30 | ms/batch  5.30 | loss  2.50 | ppl    12.16\n",
      "| epoch  16 |  1200/ 2072 batches | lr 4.30 | ms/batch  5.30 | loss  2.48 | ppl    11.91\n",
      "| epoch  16 |  1500/ 2072 batches | lr 4.30 | ms/batch  5.29 | loss  2.47 | ppl    11.81\n",
      "| epoch  16 |  1800/ 2072 batches | lr 4.30 | ms/batch  5.29 | loss  2.45 | ppl    11.58\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 11.17s | valid loss  2.56 | valid ppl    12.98\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |   300/ 2072 batches | lr 4.26 | ms/batch  5.32 | loss  2.45 | ppl    11.59\n",
      "| epoch  17 |   600/ 2072 batches | lr 4.26 | ms/batch  5.31 | loss  2.47 | ppl    11.77\n",
      "| epoch  17 |   900/ 2072 batches | lr 4.26 | ms/batch  5.29 | loss  2.50 | ppl    12.15\n",
      "| epoch  17 |  1200/ 2072 batches | lr 4.26 | ms/batch  5.28 | loss  2.48 | ppl    11.90\n",
      "| epoch  17 |  1500/ 2072 batches | lr 4.26 | ms/batch  5.30 | loss  2.47 | ppl    11.80\n",
      "| epoch  17 |  1800/ 2072 batches | lr 4.26 | ms/batch  5.30 | loss  2.45 | ppl    11.56\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 11.17s | valid loss  2.56 | valid ppl    12.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   300/ 2072 batches | lr 4.21 | ms/batch  5.32 | loss  2.45 | ppl    11.58\n",
      "| epoch  18 |   600/ 2072 batches | lr 4.21 | ms/batch  5.30 | loss  2.47 | ppl    11.79\n",
      "| epoch  18 |   900/ 2072 batches | lr 4.21 | ms/batch  5.30 | loss  2.50 | ppl    12.16\n",
      "| epoch  18 |  1200/ 2072 batches | lr 4.21 | ms/batch  5.29 | loss  2.48 | ppl    11.90\n",
      "| epoch  18 |  1500/ 2072 batches | lr 4.21 | ms/batch  5.35 | loss  2.47 | ppl    11.78\n",
      "| epoch  18 |  1800/ 2072 batches | lr 4.21 | ms/batch  5.34 | loss  2.45 | ppl    11.55\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 11.24s | valid loss  2.55 | valid ppl    12.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  19 |   300/ 2072 batches | lr 4.17 | ms/batch  5.53 | loss  2.45 | ppl    11.57\n",
      "| epoch  19 |   600/ 2072 batches | lr 4.17 | ms/batch  5.29 | loss  2.46 | ppl    11.73\n",
      "| epoch  19 |   900/ 2072 batches | lr 4.17 | ms/batch  5.33 | loss  2.50 | ppl    12.13\n",
      "| epoch  19 |  1200/ 2072 batches | lr 4.17 | ms/batch  5.31 | loss  2.47 | ppl    11.87\n",
      "| epoch  19 |  1500/ 2072 batches | lr 4.17 | ms/batch 12.23 | loss  2.46 | ppl    11.76\n",
      "| epoch  19 |  1800/ 2072 batches | lr 4.17 | ms/batch  5.51 | loss  2.45 | ppl    11.54\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 14.15s | valid loss  2.54 | valid ppl    12.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  20 |   300/ 2072 batches | lr 4.13 | ms/batch  5.46 | loss  2.45 | ppl    11.56\n",
      "| epoch  20 |   600/ 2072 batches | lr 4.13 | ms/batch  5.31 | loss  2.46 | ppl    11.73\n",
      "| epoch  20 |   900/ 2072 batches | lr 4.13 | ms/batch  5.31 | loss  2.50 | ppl    12.23\n",
      "| epoch  20 |  1200/ 2072 batches | lr 4.13 | ms/batch  5.32 | loss  2.48 | ppl    11.90\n",
      "| epoch  20 |  1500/ 2072 batches | lr 4.13 | ms/batch  5.32 | loss  2.46 | ppl    11.76\n",
      "| epoch  20 |  1800/ 2072 batches | lr 4.13 | ms/batch  5.31 | loss  2.44 | ppl    11.51\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 11.24s | valid loss  2.56 | valid ppl    12.92\n",
      "-----------------------------------------------------------------------------------------\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 20\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            val_ppl = math.exp(val_loss)\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 509]) torch.Size([1, 609])\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, Yo\n",
      "\n",
      "n. igay brd ny, y Tond at thy Wherendou mar thound Peathethe gonghece cs athis hyo d I haimy l ksaht\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new text\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=None)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 510, 302]) torch.float32 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create neural datasets\n",
    "# @markdown A synthetic dataset where the neural activity is the embeddings of tokens from tiny Shakespeare.\n",
    "\n",
    "init_random_seeds()  # set random seeds\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding = torch.nn.Embedding(ntokens, emsize, _freeze=True)  # fixed embedding map\n",
    "\n",
    "# Create datasets\n",
    "# train_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "# ]\n",
    "train_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "    for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 \t {35, 36, 39, 41, 42, 47, 48, 49, 54, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "\n",
      "59 \t {35, 36, 42, 47, 48, 49, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !',-.:;?ABCDEFGHIJKLMNOPRSTUVWYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# What tokens and their corresponding characters are in the train and test set\n",
    "real_train_tokens = set()\n",
    "for sequence in text_dataset[\"train\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_train_tokens.update(tokens)\n",
    "print(len(real_train_tokens), \"\\t\", real_train_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_train_tokens)))\n",
    "print(\"\\n\", \"~\" * 333, \"\\n\")\n",
    "\n",
    "real_test_tokens = set()\n",
    "for sequence in text_dataset[\"test\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_test_tokens.update(tokens)\n",
    "print(len(real_test_tokens), \"\\t\", real_test_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_test_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Model internal tokens = 2048\n",
      "Number of attn heads = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(\n",
    "    input_size=emsize,\n",
    "    hidden_size=d_hid,\n",
    "    version_2=True,\n",
    "    # num_tokens=ntokens,\n",
    "    num_tokens=NUM_TOKENS,\n",
    ").to(DEVICE)\n",
    "# NOTE: In reality we don't actually know the underlying vocabulary size (i.e. num_tokens) of the embedding table used to generated the neural data.\n",
    "\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Model internal tokens = {model.num_tokens}\")\n",
    "print(f\"Number of attn heads = {model.num_heads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 509, 302]) torch.float32 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 509, 302]) torch.float32 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 509, 2048]) torch.float16 False cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's input-output functionality\n",
    "\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(input, mask)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([117, 100, 113, 102, 104])\n",
      "\n",
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([0, 0, 0, 0, 0])\n",
      "\n",
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([0, 0, 0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's internal tokenizer\n",
    "\n",
    "# The code below should only work when we cheat and set the neural_embedding to be exactky the embedding table that was used to generate the neural data.\n",
    "# This is because the neural_embedding is initialized randomly. If the model has not been trained then there is no reason for its internal tokenizer to\n",
    "# correctly invert the ground-truth embedding, which should be unknown to us. Thereforem the goal of our optimization is ultimately to learn the\n",
    "# a neural_embedding that is as close as possible to the ground-truth but unknown embedding map.\n",
    "\n",
    "if embedding.weight.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(\n",
    "        embedding.weight, model.neural_embedding.cpu()\n",
    "    ), \"The neural_embedding should be different from the embedding map!\"\n",
    "\n",
    "# Replace model neural_embedding with the embedding map use to generate the dataset\n",
    "tmp = model.neural_embedding  # save for later restoration\n",
    "model.neural_embedding = embedding.weight.to(DEVICE)  # let's cheat\n",
    "\n",
    "if tmp.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(\n",
    "        tmp, model.neural_embedding\n",
    "    ), \"Unexpected aliasing of tmp to model.neural_embedding!\"\n",
    "\n",
    "    assert torch.allclose(\n",
    "        embedding.weight, model.neural_embedding.cpu()\n",
    "    ), \"The neural_embedding should be the same as the embedding map!\"\n",
    "\n",
    "# Get some ground-truth test data\n",
    "token_list = text_dataset[\"test\"][\"input_ids\"][0]\n",
    "token_target = torch.LongTensor(token_list)\n",
    "neural_target = torch.vstack([embedding(t) for t in token_target])\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the neural_embedding is the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should be the same\n",
    "assert torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should be the same!\"\n",
    "\n",
    "# Restore the model neural_embedding to its original random initialization\n",
    "model.neural_embedding = tmp\n",
    "\n",
    "if embedding.weight.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(embedding.weight, model.neural_embedding.cpu())\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the neural_embedding is NOT the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should NOT be the same\n",
    "assert not torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should NOT be the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        data = train_dataset[batch].unsqueeze(0)\n",
    "        mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = data[:, :-1, :].to(DEVICE)\n",
    "        target = data[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target, mask\n",
    "        )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            try:\n",
    "                ppl = math.exp(cur_loss)\n",
    "            except OverflowError:\n",
    "                ppl = float(\"inf\")\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            data = test_dataset[batch].unsqueeze(0)\n",
    "            mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = data[:, :-1, :].to(DEVICE)\n",
    "            target = data[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (2048, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 20 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 2072 batches | lr 5.00 | ms/batch  7.14 | loss 76.97 | ppl 2678102704860588964087438979891200.00\n",
      "| epoch   1 |   600/ 2072 batches | lr 5.00 | ms/batch  5.56 | loss 27.33 | ppl 736984968446.91\n",
      "| epoch   1 |   900/ 2072 batches | lr 5.00 | ms/batch  5.46 | loss 19.66 | ppl 344096359.75\n",
      "| epoch   1 |  1200/ 2072 batches | lr 5.00 | ms/batch  5.45 | loss 15.81 | ppl 7317895.42\n",
      "| epoch   1 |  1500/ 2072 batches | lr 5.00 | ms/batch  5.45 | loss 13.84 | ppl 1021088.94\n",
      "| epoch   1 |  1800/ 2072 batches | lr 5.00 | ms/batch  5.45 | loss 11.59 | ppl 108336.22\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 12.08s | valid loss  8.42 | valid ppl  4538.58\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   2 |   300/ 2072 batches | lr 4.95 | ms/batch  5.46 | loss  9.60 | ppl 14832.42\n",
      "| epoch   2 |   600/ 2072 batches | lr 4.95 | ms/batch  5.43 | loss  8.58 | ppl  5345.64\n",
      "| epoch   2 |   900/ 2072 batches | lr 4.95 | ms/batch  5.44 | loss  8.04 | ppl  3096.20\n",
      "| epoch   2 |  1200/ 2072 batches | lr 4.95 | ms/batch  5.44 | loss  7.88 | ppl  2640.74\n",
      "| epoch   2 |  1500/ 2072 batches | lr 4.95 | ms/batch  5.45 | loss  7.32 | ppl  1512.78\n",
      "| epoch   2 |  1800/ 2072 batches | lr 4.95 | ms/batch  5.50 | loss  7.30 | ppl  1484.76\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 11.54s | valid loss  7.31 | valid ppl  1489.87\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   3 |   300/ 2072 batches | lr 4.90 | ms/batch  5.50 | loss  6.91 | ppl  1000.50\n",
      "| epoch   3 |   600/ 2072 batches | lr 4.90 | ms/batch  5.45 | loss  6.85 | ppl   939.44\n",
      "| epoch   3 |   900/ 2072 batches | lr 4.90 | ms/batch  5.52 | loss  6.92 | ppl  1014.79\n",
      "| epoch   3 |  1200/ 2072 batches | lr 4.90 | ms/batch  5.45 | loss  6.62 | ppl   748.76\n",
      "| epoch   3 |  1500/ 2072 batches | lr 4.90 | ms/batch  5.44 | loss  6.26 | ppl   524.75\n",
      "| epoch   3 |  1800/ 2072 batches | lr 4.90 | ms/batch  5.43 | loss  6.56 | ppl   708.87\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 11.56s | valid loss  6.52 | valid ppl   681.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   4 |   300/ 2072 batches | lr 4.85 | ms/batch  5.56 | loss  6.43 | ppl   619.21\n",
      "| epoch   4 |   600/ 2072 batches | lr 4.85 | ms/batch  5.53 | loss  6.02 | ppl   412.58\n",
      "| epoch   4 |   900/ 2072 batches | lr 4.85 | ms/batch  5.45 | loss  6.14 | ppl   462.83\n",
      "| epoch   4 |  1200/ 2072 batches | lr 4.85 | ms/batch  5.44 | loss  6.09 | ppl   440.83\n",
      "| epoch   4 |  1500/ 2072 batches | lr 4.85 | ms/batch  5.56 | loss  5.85 | ppl   348.85\n",
      "| epoch   4 |  1800/ 2072 batches | lr 4.85 | ms/batch  5.54 | loss  5.96 | ppl   386.80\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 11.66s | valid loss  5.94 | valid ppl   380.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   5 |   300/ 2072 batches | lr 4.80 | ms/batch  5.54 | loss  5.95 | ppl   383.49\n",
      "| epoch   5 |   600/ 2072 batches | lr 4.80 | ms/batch  5.54 | loss  5.45 | ppl   232.89\n",
      "| epoch   5 |   900/ 2072 batches | lr 4.80 | ms/batch  5.59 | loss  5.67 | ppl   290.68\n",
      "| epoch   5 |  1200/ 2072 batches | lr 4.80 | ms/batch  5.57 | loss  5.70 | ppl   298.91\n",
      "| epoch   5 |  1500/ 2072 batches | lr 4.80 | ms/batch  5.59 | loss  5.51 | ppl   247.78\n",
      "| epoch   5 |  1800/ 2072 batches | lr 4.80 | ms/batch  5.47 | loss  5.39 | ppl   218.14\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 11.73s | valid loss  5.16 | valid ppl   173.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   6 |   300/ 2072 batches | lr 4.75 | ms/batch  5.48 | loss  5.38 | ppl   215.94\n",
      "| epoch   6 |   600/ 2072 batches | lr 4.75 | ms/batch  5.45 | loss  5.38 | ppl   218.07\n",
      "| epoch   6 |   900/ 2072 batches | lr 4.75 | ms/batch  5.47 | loss  5.20 | ppl   181.64\n",
      "| epoch   6 |  1200/ 2072 batches | lr 4.75 | ms/batch  5.44 | loss  5.16 | ppl   173.71\n",
      "| epoch   6 |  1500/ 2072 batches | lr 4.75 | ms/batch  5.45 | loss  5.06 | ppl   157.65\n",
      "| epoch   6 |  1800/ 2072 batches | lr 4.75 | ms/batch  5.53 | loss  5.06 | ppl   156.95\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 11.60s | valid loss  5.66 | valid ppl   287.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   300/ 2072 batches | lr 4.71 | ms/batch  5.46 | loss  5.03 | ppl   152.22\n",
      "| epoch   7 |   600/ 2072 batches | lr 4.71 | ms/batch  5.45 | loss  4.82 | ppl   123.48\n",
      "| epoch   7 |   900/ 2072 batches | lr 4.71 | ms/batch  5.43 | loss  4.82 | ppl   123.54\n",
      "| epoch   7 |  1200/ 2072 batches | lr 4.71 | ms/batch  5.46 | loss  4.88 | ppl   132.12\n",
      "| epoch   7 |  1500/ 2072 batches | lr 4.71 | ms/batch  5.44 | loss  4.70 | ppl   109.64\n",
      "| epoch   7 |  1800/ 2072 batches | lr 4.71 | ms/batch  5.44 | loss  4.51 | ppl    91.10\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 11.53s | valid loss  4.02 | valid ppl    55.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   8 |   300/ 2072 batches | lr 4.66 | ms/batch  5.47 | loss  4.60 | ppl    99.12\n",
      "| epoch   8 |   600/ 2072 batches | lr 4.66 | ms/batch  5.43 | loss  4.37 | ppl    79.14\n",
      "| epoch   8 |   900/ 2072 batches | lr 4.66 | ms/batch  5.44 | loss  4.55 | ppl    94.31\n",
      "| epoch   8 |  1200/ 2072 batches | lr 4.66 | ms/batch  5.44 | loss  4.47 | ppl    87.29\n",
      "| epoch   8 |  1500/ 2072 batches | lr 4.66 | ms/batch  5.45 | loss  4.51 | ppl    90.48\n",
      "| epoch   8 |  1800/ 2072 batches | lr 4.66 | ms/batch  5.43 | loss  4.33 | ppl    75.71\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 11.52s | valid loss  4.71 | valid ppl   111.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   300/ 2072 batches | lr 4.61 | ms/batch  5.46 | loss  4.20 | ppl    67.01\n",
      "| epoch   9 |   600/ 2072 batches | lr 4.61 | ms/batch  5.42 | loss  4.09 | ppl    59.64\n",
      "| epoch   9 |   900/ 2072 batches | lr 4.61 | ms/batch  5.44 | loss  4.21 | ppl    67.33\n",
      "| epoch   9 |  1200/ 2072 batches | lr 4.61 | ms/batch  5.43 | loss  4.03 | ppl    56.14\n",
      "| epoch   9 |  1500/ 2072 batches | lr 4.61 | ms/batch  5.48 | loss  3.96 | ppl    52.32\n",
      "| epoch   9 |  1800/ 2072 batches | lr 4.61 | ms/batch  5.44 | loss  3.93 | ppl    50.77\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 11.52s | valid loss  3.79 | valid ppl    44.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  10 |   300/ 2072 batches | lr 4.57 | ms/batch  5.46 | loss  3.87 | ppl    47.73\n",
      "| epoch  10 |   600/ 2072 batches | lr 4.57 | ms/batch  5.44 | loss  3.77 | ppl    43.30\n",
      "| epoch  10 |   900/ 2072 batches | lr 4.57 | ms/batch  5.47 | loss  3.77 | ppl    43.25\n",
      "| epoch  10 |  1200/ 2072 batches | lr 4.57 | ms/batch  5.46 | loss  3.69 | ppl    40.24\n",
      "| epoch  10 |  1500/ 2072 batches | lr 4.57 | ms/batch  5.44 | loss  3.73 | ppl    41.62\n",
      "| epoch  10 |  1800/ 2072 batches | lr 4.57 | ms/batch  5.44 | loss  3.70 | ppl    40.43\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 11.54s | valid loss  4.07 | valid ppl    58.49\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |   300/ 2072 batches | lr 4.52 | ms/batch  5.50 | loss  3.69 | ppl    39.87\n",
      "| epoch  11 |   600/ 2072 batches | lr 4.52 | ms/batch  5.44 | loss  3.56 | ppl    35.04\n",
      "| epoch  11 |   900/ 2072 batches | lr 4.52 | ms/batch  5.46 | loss  3.67 | ppl    39.44\n",
      "| epoch  11 |  1200/ 2072 batches | lr 4.52 | ms/batch  6.03 | loss  3.68 | ppl    39.59\n",
      "| epoch  11 |  1500/ 2072 batches | lr 4.52 | ms/batch  5.49 | loss  3.53 | ppl    34.18\n",
      "| epoch  11 |  1800/ 2072 batches | lr 4.52 | ms/batch  5.45 | loss  3.91 | ppl    49.85\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 11.77s | valid loss  3.90 | valid ppl    49.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |   300/ 2072 batches | lr 4.48 | ms/batch  5.62 | loss  3.55 | ppl    34.90\n",
      "| epoch  12 |   600/ 2072 batches | lr 4.48 | ms/batch  5.61 | loss  3.43 | ppl    30.77\n",
      "| epoch  12 |   900/ 2072 batches | lr 4.48 | ms/batch  5.54 | loss  3.59 | ppl    36.17\n",
      "| epoch  12 |  1200/ 2072 batches | lr 4.48 | ms/batch  5.54 | loss  3.58 | ppl    35.91\n",
      "| epoch  12 |  1500/ 2072 batches | lr 4.48 | ms/batch  5.55 | loss  3.64 | ppl    37.96\n",
      "| epoch  12 |  1800/ 2072 batches | lr 4.48 | ms/batch  5.57 | loss  3.47 | ppl    32.01\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 11.76s | valid loss  5.01 | valid ppl   149.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |   300/ 2072 batches | lr 4.43 | ms/batch  5.45 | loss  3.50 | ppl    33.28\n",
      "| epoch  13 |   600/ 2072 batches | lr 4.43 | ms/batch  5.69 | loss  3.46 | ppl    31.86\n",
      "| epoch  13 |   900/ 2072 batches | lr 4.43 | ms/batch  5.48 | loss  3.49 | ppl    32.63\n",
      "| epoch  13 |  1200/ 2072 batches | lr 4.43 | ms/batch  5.49 | loss  3.46 | ppl    31.82\n",
      "| epoch  13 |  1500/ 2072 batches | lr 4.43 | ms/batch  5.46 | loss  3.49 | ppl    32.80\n",
      "| epoch  13 |  1800/ 2072 batches | lr 4.43 | ms/batch  5.47 | loss  3.49 | ppl    32.69\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 11.68s | valid loss  3.59 | valid ppl    36.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  14 |   300/ 2072 batches | lr 4.39 | ms/batch  5.46 | loss  3.46 | ppl    31.92\n",
      "| epoch  14 |   600/ 2072 batches | lr 4.39 | ms/batch  5.44 | loss  3.38 | ppl    29.36\n",
      "| epoch  14 |   900/ 2072 batches | lr 4.39 | ms/batch  5.43 | loss  3.35 | ppl    28.51\n",
      "| epoch  14 |  1200/ 2072 batches | lr 4.39 | ms/batch  5.44 | loss  3.54 | ppl    34.43\n",
      "| epoch  14 |  1500/ 2072 batches | lr 4.39 | ms/batch  5.44 | loss  3.39 | ppl    29.80\n",
      "| epoch  14 |  1800/ 2072 batches | lr 4.39 | ms/batch  5.44 | loss  3.36 | ppl    28.88\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 11.53s | valid loss  3.44 | valid ppl    31.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  15 |   300/ 2072 batches | lr 4.34 | ms/batch  5.46 | loss  3.38 | ppl    29.23\n",
      "| epoch  15 |   600/ 2072 batches | lr 4.34 | ms/batch  5.44 | loss  3.32 | ppl    27.69\n",
      "| epoch  15 |   900/ 2072 batches | lr 4.34 | ms/batch  5.44 | loss  3.42 | ppl    30.60\n",
      "| epoch  15 |  1200/ 2072 batches | lr 4.34 | ms/batch  5.44 | loss  3.32 | ppl    27.77\n",
      "| epoch  15 |  1500/ 2072 batches | lr 4.34 | ms/batch  5.44 | loss  3.31 | ppl    27.26\n",
      "| epoch  15 |  1800/ 2072 batches | lr 4.34 | ms/batch  5.47 | loss  3.47 | ppl    32.15\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 11.53s | valid loss  3.59 | valid ppl    36.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |   300/ 2072 batches | lr 4.30 | ms/batch  5.47 | loss  3.36 | ppl    28.76\n",
      "| epoch  16 |   600/ 2072 batches | lr 4.30 | ms/batch  5.48 | loss  3.19 | ppl    24.25\n",
      "| epoch  16 |   900/ 2072 batches | lr 4.30 | ms/batch  5.45 | loss  3.31 | ppl    27.46\n",
      "| epoch  16 |  1200/ 2072 batches | lr 4.30 | ms/batch  5.45 | loss  3.34 | ppl    28.23\n",
      "| epoch  16 |  1500/ 2072 batches | lr 4.30 | ms/batch  5.44 | loss  3.26 | ppl    26.13\n",
      "| epoch  16 |  1800/ 2072 batches | lr 4.30 | ms/batch  5.45 | loss  3.38 | ppl    29.34\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 11.54s | valid loss  3.18 | valid ppl    24.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  17 |   300/ 2072 batches | lr 4.26 | ms/batch  5.53 | loss  3.28 | ppl    26.49\n",
      "| epoch  17 |   600/ 2072 batches | lr 4.26 | ms/batch  5.51 | loss  3.23 | ppl    25.18\n",
      "| epoch  17 |   900/ 2072 batches | lr 4.26 | ms/batch  5.46 | loss  3.33 | ppl    27.87\n",
      "| epoch  17 |  1200/ 2072 batches | lr 4.26 | ms/batch  5.44 | loss  3.26 | ppl    26.04\n",
      "| epoch  17 |  1500/ 2072 batches | lr 4.26 | ms/batch  5.46 | loss  3.35 | ppl    28.45\n",
      "| epoch  17 |  1800/ 2072 batches | lr 4.26 | ms/batch  5.45 | loss  3.18 | ppl    23.98\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 11.58s | valid loss  4.31 | valid ppl    74.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |   300/ 2072 batches | lr 4.21 | ms/batch  5.52 | loss  3.24 | ppl    25.63\n",
      "| epoch  18 |   600/ 2072 batches | lr 4.21 | ms/batch  5.49 | loss  3.18 | ppl    24.03\n",
      "| epoch  18 |   900/ 2072 batches | lr 4.21 | ms/batch  5.57 | loss  3.29 | ppl    26.71\n",
      "| epoch  18 |  1200/ 2072 batches | lr 4.21 | ms/batch  5.54 | loss  3.32 | ppl    27.56\n",
      "| epoch  18 |  1500/ 2072 batches | lr 4.21 | ms/batch  5.57 | loss  3.22 | ppl    25.12\n",
      "| epoch  18 |  1800/ 2072 batches | lr 4.21 | ms/batch  5.57 | loss  3.26 | ppl    26.07\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 11.74s | valid loss  3.79 | valid ppl    44.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |   300/ 2072 batches | lr 4.17 | ms/batch  5.47 | loss  3.24 | ppl    25.53\n",
      "| epoch  19 |   600/ 2072 batches | lr 4.17 | ms/batch  5.44 | loss  3.20 | ppl    24.57\n",
      "| epoch  19 |   900/ 2072 batches | lr 4.17 | ms/batch  5.44 | loss  3.21 | ppl    24.82\n",
      "| epoch  19 |  1200/ 2072 batches | lr 4.17 | ms/batch  5.44 | loss  3.18 | ppl    24.13\n",
      "| epoch  19 |  1500/ 2072 batches | lr 4.17 | ms/batch  5.42 | loss  3.12 | ppl    22.62\n",
      "| epoch  19 |  1800/ 2072 batches | lr 4.17 | ms/batch  5.49 | loss  3.31 | ppl    27.39\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 11.54s | valid loss  3.50 | valid ppl    33.03\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |   300/ 2072 batches | lr 4.13 | ms/batch  5.47 | loss  3.21 | ppl    24.69\n",
      "| epoch  20 |   600/ 2072 batches | lr 4.13 | ms/batch  5.61 | loss  3.12 | ppl    22.56\n",
      "| epoch  20 |   900/ 2072 batches | lr 4.13 | ms/batch  5.45 | loss  3.26 | ppl    25.95\n",
      "| epoch  20 |  1200/ 2072 batches | lr 4.13 | ms/batch  5.45 | loss  3.18 | ppl    24.12\n",
      "| epoch  20 |  1500/ 2072 batches | lr 4.13 | ms/batch  5.45 | loss  3.22 | ppl    25.15\n",
      "| epoch  20 |  1800/ 2072 batches | lr 4.13 | ms/batch  5.44 | loss  3.27 | ppl    26.22\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 11.59s | valid loss  3.40 | valid ppl    29.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 20\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            try:\n",
    "                val_ppl = math.exp(val_loss)\n",
    "            except OverflowError:\n",
    "                val_ppl = float(\"inf\")\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (2048, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# The learnt model.neural_embedding should contain a permutation of the true neural embedding.\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A.T @ A)  # (input_size, input_size)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B.T @ B)  # (input_size, input_size)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 302]) torch.Size([1, 509, 302]) torch.Size([1, 100, 302])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new data\n",
    "\n",
    "\n",
    "max_new_tokens = 100\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0).to(DEVICE)\n",
    "data = test_dataset[0][:-1, :].unsqueeze(0).to(DEVICE)\n",
    "data_gen = model.generate(data, mask, max_new_tokens, autoregressive=True, top_k=None)\n",
    "\n",
    "print(mask.shape, data.shape, data_gen.shape, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120, 1]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, Yo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown We want to tokenize the neural data.\n",
    "# An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# First run a test on data for which we know what the true token output should be.\n",
    "# This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "with torch.no_grad():\n",
    "    sequence = data\n",
    "    inp_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    # iff correct these two should match\n",
    "    print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")  # ground-truth tokens\n",
    "    print(text_dataset[\"test\"][\"text\"][0], end=\"\\n\\n\")  # ground-truth text\n",
    "    print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 35, 118, 120, 42, 114, 113, 103, 35, 118, 114, 35, 100, 113, 35, 108, 112, 114, 35, 101, 120, 108, 119, 124, 114, 110, 47, 35, 105, 108, 119, 107, 119, 107, 35, 112, 100, 101, 111, 111, 111, 47, 35, 100, 103, 35, 118, 120, 106, 107, 108, 119, 107, 35, 108, 104, 35, 118, 118, 35, 112, 118, 114, 118, 107, 100, 35, 113, 35, 112, 47, 35, 103, 35, 118, 107, 119, 71, 108, 118, 108, 114, 114, 113, 35, 103, 35, 112, 114, 100, 35, 105, 105, 111, 35, 105, 113, 35, 112, 35]\n",
      "\n",
      "r su'ond so an imo buityok, fithth mablll, ad sughith ie ss msosha n m, d shtDisioon d moa ffl fn m \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence = data_gen\n",
    "    gen_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(gen_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(gen_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 302]) torch.Size([65, 302])\n",
      "\n",
      "There are 64 unique embeddings that generated the neural data.\n",
      "The model learned 65 unique neural embeddings. But are they the same?\n",
      "\n",
      "Model learned to reproduce 62/64 embeddings exactly.\n",
      "The remaining 2/64 are superpositions of embeddings!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "all_unique_vectors = torch.vstack(train_dataset).unique(dim=0)\n",
    "learned_unique_vectors = model.neural_embedding.unique(dim=0)\n",
    "print(all_unique_vectors.shape, learned_unique_vectors.shape)\n",
    "print()\n",
    "\n",
    "all_unique_vectors = {tuple(row.round(decimals=3).cpu().numpy()) for row in all_unique_vectors}\n",
    "learned_unique_vectors = {\n",
    "    tuple(row.round(decimals=3).cpu().numpy()) for row in learned_unique_vectors\n",
    "}\n",
    "print(f\"There are {len(all_unique_vectors)} unique embeddings that generated the neural data.\")\n",
    "print(\n",
    "    f\"The model learned {len(learned_unique_vectors)} unique neural embeddings. But are they the same?\"\n",
    ")\n",
    "print()\n",
    "\n",
    "inter = all_unique_vectors.intersection(learned_unique_vectors)\n",
    "diff = all_unique_vectors - learned_unique_vectors\n",
    "print(f\"Model learned to reproduce {len(inter)}/{len(all_unique_vectors)} embeddings exactly.\")\n",
    "print(f\"The remaining {len(diff)}/{len(all_unique_vectors)} are superpositions of embeddings!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal index: 0 \n",
      "neural: tensor([ 0.0191,  0.3506, -0.1098,  0.8953, -0.0308], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([ 0.0191,  0.3506, -0.1098,  0.8953, -0.0308], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0191,  0.3506, -0.1098,  0.8953, -0.0308])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 1 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 2 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 3 \n",
      "neural: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 4 \n",
      "neural: tensor([-1.1925, -0.4978,  1.4387,  0.2168,  0.2590], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 24 \n",
      "mapped: tensor([-1.1925, -0.4978,  1.4387,  0.2168,  0.2590], device='cuda:0')\n",
      "\n",
      "embedding token: 42 \n",
      "character: ' \n",
      "in train set: True \n",
      "embedded: tensor([-1.1925, -0.4978,  1.4387,  0.2168,  0.2590])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 5 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 6 \n",
      "neural: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 7 \n",
      "neural: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 8 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 9 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 10 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 11 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 12 \n",
      "neural: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 2 \n",
      "mapped: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 13 \n",
      "neural: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 14 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 15 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 16 \n",
      "neural: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "embedding token: 112 \n",
      "character: m \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 17 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 18 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 19 \n",
      "neural: tensor([ 0.6311,  0.5889, -1.6794,  1.2177,  1.0238], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.6311,  0.5889, -1.6794,  1.2177,  1.0238], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([ 0.6311,  0.5889, -1.6794,  1.2177,  1.0238])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 20 \n",
      "neural: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 21 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 22 \n",
      "neural: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 16 \n",
      "mapped: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 23 \n",
      "neural: tensor([ 1.2378,  0.7798, -0.9709, -1.1126, -0.4986], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 1.2378,  0.7798, -0.9709, -1.1126, -0.4986], device='cuda:0')\n",
      "\n",
      "embedding token: 124 \n",
      "character: y \n",
      "in train set: True \n",
      "embedded: tensor([ 1.2378,  0.7798, -0.9709, -1.1126, -0.4986])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 24 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 25 \n",
      "neural: tensor([-0.9538, -0.4808, -0.7792,  0.6272,  0.7324], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 14 \n",
      "mapped: tensor([-0.9538, -0.4808, -0.7792,  0.6272,  0.7324], device='cuda:0')\n",
      "\n",
      "embedding token: 110 \n",
      "character: k \n",
      "in train set: True \n",
      "embedded: tensor([-0.9538, -0.4808, -0.7792,  0.6272,  0.7324])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 26 \n",
      "neural: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 27 \n",
      "mapped: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 27 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 28 \n",
      "neural: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 55 \n",
      "mapped: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 29 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 30 \n",
      "neural: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 16 \n",
      "mapped: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 31 \n",
      "neural: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 32 \n",
      "neural: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 16 \n",
      "mapped: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 33 \n",
      "neural: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 34 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 35 \n",
      "neural: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "embedding token: 112 \n",
      "character: m \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 36 \n",
      "neural: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 2 \n",
      "mapped: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 37 \n",
      "neural: tensor([ 0.6311,  0.5889, -1.6794,  1.2177,  1.0238], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.6311,  0.5889, -1.6794,  1.2177,  1.0238], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([ 0.6311,  0.5889, -1.6794,  1.2177,  1.0238])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 38 \n",
      "neural: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 26 \n",
      "mapped: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "embedding token: 111 \n",
      "character: l \n",
      "in train set: True \n",
      "embedded: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 39 \n",
      "neural: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 26 \n",
      "mapped: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "embedding token: 111 \n",
      "character: l \n",
      "in train set: True \n",
      "embedded: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 40 \n",
      "neural: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 26 \n",
      "mapped: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "embedding token: 111 \n",
      "character: l \n",
      "in train set: True \n",
      "embedded: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 41 \n",
      "neural: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 27 \n",
      "mapped: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 42 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 43 \n",
      "neural: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 2 \n",
      "mapped: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 44 \n",
      "neural: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 45 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 46 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 47 \n",
      "neural: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 48 \n",
      "neural: tensor([-0.0648,  0.3661, -0.4114,  0.9050,  0.7112], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 11 \n",
      "mapped: tensor([-0.0648,  0.3661, -0.4114,  0.9050,  0.7112], device='cuda:0')\n",
      "\n",
      "embedding token: 106 \n",
      "character: g \n",
      "in train set: True \n",
      "embedded: tensor([-0.0648,  0.3661, -0.4114,  0.9050,  0.7112])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 49 \n",
      "neural: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 50 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 51 \n",
      "neural: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 16 \n",
      "mapped: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 52 \n",
      "neural: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 53 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 54 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 55 \n",
      "neural: tensor([ 0.5034, -0.1664, -1.0771, -1.5196,  0.0803], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 59 \n",
      "mapped: tensor([ 0.5034, -0.1664, -1.0771, -1.5196,  0.0803], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.5034, -0.1664, -1.0771, -1.5196,  0.0803])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 56 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 57 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 58 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 59 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 60 \n",
      "neural: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "embedding token: 112 \n",
      "character: m \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 61 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 62 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 63 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 64 \n",
      "neural: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 65 \n",
      "neural: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 2 \n",
      "mapped: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 66 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 67 \n",
      "neural: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 68 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 69 \n",
      "neural: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "embedding token: 112 \n",
      "character: m \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 70 \n",
      "neural: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 27 \n",
      "mapped: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([-0.5942,  1.5981, -0.3172, -0.8339, -0.5373])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 71 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 72 \n",
      "neural: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 73 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 74 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 75 \n",
      "neural: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([0.5150, 1.0630, 1.4624, 1.3938, 0.3850])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 76 \n",
      "neural: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 16 \n",
      "mapped: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.5255,  0.9854, -0.5254, -2.0624,  0.1521])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 77 \n",
      "neural: tensor([ 0.6931, -1.3137,  1.4809, -0.1060,  1.1467], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 51 \n",
      "mapped: tensor([ 0.6931, -1.3137,  1.4809, -0.1060,  1.1467], device='cuda:0')\n",
      "\n",
      "embedding token: 71 \n",
      "character: D \n",
      "in train set: True \n",
      "embedded: tensor([ 0.6931, -1.3137,  1.4809, -0.1060,  1.1467])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 78 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 79 \n",
      "neural: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0623,  1.1880, -2.4953,  2.0625,  0.3044])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 80 \n",
      "neural: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 19 \n",
      "mapped: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.7881,  0.4426, -0.0985, -0.5345,  0.1483])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 81 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 82 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 83 \n",
      "neural: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 84 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 85 \n",
      "neural: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-1.1735, -0.0279,  0.5871, -1.4364, -0.9357])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 86 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 87 \n",
      "neural: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "embedding token: 112 \n",
      "character: m \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 88 \n",
      "neural: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4265,  1.4595,  0.6909,  0.5987, -1.0726])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 89 \n",
      "neural: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 2 \n",
      "mapped: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379], device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4663,  0.5590,  1.6086, -1.6965,  0.1379])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 90 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 91 \n",
      "neural: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 55 \n",
      "mapped: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 92 \n",
      "neural: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 55 \n",
      "mapped: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 93 \n",
      "neural: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 26 \n",
      "mapped: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829], device='cuda:0')\n",
      "\n",
      "embedding token: 111 \n",
      "character: l \n",
      "in train set: True \n",
      "embedded: tensor([-1.9343,  2.2354, -0.1158, -0.6550, -0.7829])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 94 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 95 \n",
      "neural: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 55 \n",
      "mapped: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4750,  2.1842,  1.0390,  0.1173, -0.7390])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 96 \n",
      "neural: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([-1.8486, -0.3663, -0.5902, -2.2135,  1.6358])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 97 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 98 \n",
      "neural: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101], device='cuda:0')\n",
      "\n",
      "embedding token: 112 \n",
      "character: m \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3803, -2.3290,  0.3016,  0.9153, -0.6101])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 99 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Assert should not be raised if the model learned to correctly map the tokens in the training set\n",
    "for idx in range(data_gen.shape[1]):\n",
    "    neural = data_gen[:, [idx], :]\n",
    "    print(\"temporal index:\", idx, \"\\nneural:\", neural.squeeze()[:5], end=\"\\n\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ct = model.tokenize_neural_data(neural).item()\n",
    "    mapped = model.neural_embedding[torch.tensor(ct, dtype=torch.long)]\n",
    "    print(\"model.neural_embedding token:\", ct, \"\\nmapped:\", mapped[:5], end=\"\\n\\n\")\n",
    "\n",
    "    assert torch.allclose(neural, mapped), \"Basic check failed; Inconsistency in mapping!\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        et = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    embedded = embedding(torch.tensor(et, dtype=torch.long))\n",
    "    print(\n",
    "        \"embedding token:\",\n",
    "        et,\n",
    "        \"\\ncharacter:\",\n",
    "        tokenizer.decode([et]),\n",
    "        \"\\nin train set:\",\n",
    "        et in real_train_tokens,\n",
    "        \"\\nembedded:\",\n",
    "        embedded[:5],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    if et in real_train_tokens:\n",
    "        ### DEBUG ###\n",
    "        assert torch.any(neural != 0), \"Model did not learn to map a vector it was trained on!\"\n",
    "        assert torch.allclose(\n",
    "            embedded, mapped.cpu()\n",
    "        ), \"The learned embedding did not converge to the true embedding!\"\n",
    "        ### DEBUG ###\n",
    "\n",
    "    print(\"~\" * 99, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
