{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found.\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from utils import DEVICE, BLOCK_SIZE, NUM_TOKENS, init_random_seeds\n",
    "from CreateSyntheticDataset import tokenize_and_chunk  # works because of nbimporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `tokenizer.encode(text)`:\n",
      "\ttext: Welcome to the ðŸ¤— Tokenizers library.\n",
      "\ttokenized: [90, 104, 111, 102, 114, 112, 104, 35, 119, 114, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 114, 110, 104, 113, 108, 125, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: Welcome to the ðŸ¤— Tokenizers library.</s>\n",
      "\n",
      "Calling `tokenizer(text)`:\n",
      "\tobject.keys(): dict_keys(['input_ids', 'attention_mask'])\n",
      "\ttext: We are very happy to show you the ðŸ¤— Transformers library.\n",
      "\ttokenized: [90, 104, 35, 100, 117, 104, 35, 121, 104, 117, 124, 35, 107, 100, 115, 115, 124, 35, 119, 114, 35, 118, 107, 114, 122, 35, 124, 114, 120, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 117, 100, 113, 118, 105, 114, 117, 112, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: We are very happy to show you the ðŸ¤— Transformers library.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-large\")\n",
    "\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "train: <class 'list'> 1 <class 'str'> 1003854\n",
      "\n",
      "validation: <class 'list'> 1 <class 'str'> 55770\n",
      "\n",
      "test: <class 'list'> 1 <class 'str'> 55770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1963\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_dataset['train']['input_ids']:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 1963\n",
      "\n",
      "text_dataset['train']['input_ids'][0]:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 506\n",
      "\n",
      "text_dataset['train']['input_ids'][0][0]:\n",
      " \ttype: <class 'int'> \n",
      "\tvalue: 73\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Original sequence (text):\n",
      "\tFirst Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the\n",
      "\n",
      "Encoded sequence (tokens):\n",
      "\t [73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 69, 104, 105, 114, 117, 104, 35, 122, 104, 35, 115, 117, 114, 102, 104, 104, 103, 35, 100, 113, 124, 35, 105, 120, 117, 119, 107, 104, 117, 47, 35, 107, 104, 100, 117, 35, 112, 104, 35, 118, 115, 104, 100, 110, 49, 35, 68, 111, 111, 61, 35, 86, 115, 104, 100, 110, 47, 35, 118, 115, 104, 100, 110, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 92, 114, 120, 35, 100, 117, 104, 35, 100, 111, 111, 35, 117, 104, 118, 114, 111, 121, 104, 103, 35, 117, 100, 119, 107, 104, 117, 35, 119, 114, 35, 103, 108, 104, 35, 119, 107, 100, 113, 35, 119, 114, 35, 105, 100, 112, 108, 118, 107, 66, 35, 68, 111, 111, 61, 35, 85, 104, 118, 114, 111, 121, 104, 103, 49, 35, 117, 104, 118, 114, 111, 121, 104, 103, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 73, 108, 117, 118, 119, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 35, 70, 100, 108, 120, 118, 35, 80, 100, 117, 102, 108, 120, 118, 35, 108, 118, 35, 102, 107, 108, 104, 105, 35, 104, 113, 104, 112, 124, 35, 119, 114, 35, 119, 107, 104, 35, 115, 104, 114, 115, 111, 104, 49, 35, 68, 111, 111, 61, 35, 90, 104, 35, 110, 113, 114, 122, 42, 119, 47, 35, 122, 104, 35, 110, 113, 114, 122, 42, 119, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 79, 104, 119, 35, 120, 118, 35, 110, 108, 111, 111, 35, 107, 108, 112, 47, 35, 100, 113, 103, 35, 122, 104, 42, 111, 111, 35, 107, 100, 121, 104, 35, 102, 114, 117, 113, 35, 100, 119, 35, 114, 120, 117, 35, 114, 122, 113, 35, 115, 117, 108, 102, 104, 49, 35, 76, 118, 42, 119, 35, 100, 35, 121, 104, 117, 103, 108, 102, 119, 66, 35, 68, 111, 111, 61, 35, 81, 114, 35, 112, 114, 117, 104, 35, 119, 100, 111, 110, 108, 113, 106, 35, 114, 113, 42, 119, 62, 35, 111, 104, 119, 35, 108, 119, 35, 101, 104, 35, 103, 114, 113, 104, 61, 35, 100, 122, 100, 124, 47, 35, 100, 122, 100, 124, 36, 35, 86, 104, 102, 114, 113, 103, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 82, 113, 104, 35, 122, 114, 117, 103, 47, 35, 106, 114, 114, 103, 35, 102, 108, 119, 108, 125, 104, 113, 118, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 90, 104, 35, 100, 117, 104, 35, 100, 102, 102, 114, 120, 113, 119, 104, 103, 35, 115, 114, 114, 117, 35, 102, 108, 119, 108, 125, 104, 113, 118, 47, 35, 119, 107, 104, 1]\n",
      "\n",
      "Decoded sequence (tokens):\n",
      "\t First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 511]) torch.int64 False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create token datasets\n",
    "\n",
    "train_dataset = torch.nested.nested_tensor(text_dataset[\"train\"][\"input_ids\"], dtype=torch.long)\n",
    "validation_dataset = torch.nested.nested_tensor(\n",
    "    text_dataset[\"validation\"][\"input_ids\"], dtype=torch.long\n",
    ")\n",
    "test_dataset = torch.nested.nested_tensor(text_dataset[\"test\"][\"input_ids\"], dtype=torch.long)\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Number of attn heads = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a TransformerModel\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Number of attn heads = {nhead}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler, criterion\n",
    "\n",
    "    num_batches = train_dataset.size(0)\n",
    "    for batch in range(num_batches):\n",
    "        # tokens = text_dataset[\"train\"][\"input_ids\"][batch]\n",
    "        tokens = train_dataset[batch].unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        input = tokens[:, :-1].to(DEVICE)  # ``[batch_size=1, seq_len]``\n",
    "        target = tokens[:, 1:].reshape(-1).to(DEVICE)  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = validation_dataset.size(0)\n",
    "        for batch in range(num_batches):\n",
    "            tokens = validation_dataset[batch].unsqueeze(0)\n",
    "            input = tokens[:, :-1].to(DEVICE)\n",
    "            target = tokens[:, 1:].reshape(-1).to(DEVICE)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1 epoch(s)...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 1963 batches | lr 5.00 | ms/batch 11.00 | loss  3.39 | ppl    29.79\n",
      "| epoch   1 |   600/ 1963 batches | lr 5.00 | ms/batch  6.01 | loss  2.63 | ppl    13.89\n",
      "| epoch   1 |   900/ 1963 batches | lr 5.00 | ms/batch  5.73 | loss  2.61 | ppl    13.53\n",
      "| epoch   1 |  1200/ 1963 batches | lr 5.00 | ms/batch  5.68 | loss  2.56 | ppl    12.91\n",
      "| epoch   1 |  1500/ 1963 batches | lr 5.00 | ms/batch  5.62 | loss  2.54 | ppl    12.73\n",
      "| epoch   1 |  1800/ 1963 batches | lr 5.00 | ms/batch  5.61 | loss  2.52 | ppl    12.47\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 13.02s | valid loss  2.58 | valid ppl    13.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            val_ppl = math.exp(val_loss)\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 510]) torch.Size([1, 610])\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "n enos ide, BABTGHATETangand</s>esounke I s, y</s>\u0018an a s nes fif In I dere</s>unowes d Be Biotal miongumen T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new text\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=None)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 511, 302]) torch.float32 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create neural datasets\n",
    "# @markdown A synthetic dataset where the neural activity is the embeddings of tokens from tiny Shakespeare.\n",
    "\n",
    "init_random_seeds()  # set random seeds\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding = torch.nn.Embedding(ntokens, emsize, _freeze=True)  # fixed embedding map\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "]\n",
    "validation_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "test_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Model internal tokens = 256\n",
      "Number of attn heads = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(\n",
    "    input_size=emsize,\n",
    "    hidden_size=d_hid,\n",
    "    version_2=True,\n",
    "    # NOTE: in reality we won't actually know the underlying vocabulary size (i.e. num_tokens) from which the data was generated\n",
    "    num_tokens=ntokens,\n",
    "    vq_vae=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Model internal tokens = {model.num_tokens}\")\n",
    "print(f\"Number of attn heads = {model.num_heads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 510, 302]) torch.float32 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 510, 302]) torch.float32 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 510, 256]) torch.float16 False cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's input-output functionality\n",
    "\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(input, mask)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([117, 100, 113, 102, 104])\n",
      "\n",
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([234, 205,  67, 236, 193])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's internal tokenizer works as expected\n",
    "\n",
    "# The code below should only work when we cheat and set the codebook to be exactky the embedding table that was used to generate the neural data.\n",
    "# This is because the codebook is initialized randomly. If the model has not been trained then there is no reason for its internal tokenizer to\n",
    "# correctly invert the ground-truth embedding, which should be unknown to us. Thereforem the goal of our optimization is ultimately to learn the\n",
    "# a codebook that is as close as possible to the ground-truth but unknown embedding map.\n",
    "\n",
    "assert not torch.allclose(embedding.weight, model.codebook.cpu())\n",
    "\n",
    "# Replace model codebook with the embedding map use to generate the dataset\n",
    "tmp = model.codebook  # save for later restoration\n",
    "model.codebook = torch.nn.Parameter(embedding.weight.to(DEVICE))  # let's cheat\n",
    "\n",
    "assert torch.allclose(embedding.weight, model.codebook.cpu())\n",
    "\n",
    "# Get some ground-truth test data\n",
    "token_list = text_dataset[\"test\"][\"input_ids\"][0]\n",
    "token_target = torch.LongTensor(token_list)\n",
    "neural_target = torch.vstack([embedding(t) for t in token_target])\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the codebook is the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should be the same\n",
    "assert torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should be the same!\"\n",
    "\n",
    "# Restore the model codebook to its original random initialization\n",
    "model.codebook = tmp\n",
    "\n",
    "assert not torch.allclose(embedding.weight, model.codebook.cpu())\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the codebook is NOT the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should NOT be the same\n",
    "assert not torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should NOT be the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        data = train_dataset[batch].unsqueeze(0)\n",
    "        mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = data[:, :-1, :].to(DEVICE)\n",
    "        target = data[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target, mask\n",
    "        )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            try:\n",
    "                ppl = math.exp(cur_loss)\n",
    "            except OverflowError:\n",
    "                ppl = float(\"inf\")\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(validation_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            data = validation_dataset[batch].unsqueeze(0)\n",
    "            mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = data[:, :-1, :].to(DEVICE)\n",
    "            target = data[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "True \n",
      " None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.token_neural_map.unique(dim=0)) - 1, end=\"\\n\\n\")\n",
    "print(model.codebook.requires_grad, \"\\n\", model.codebook.grad, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (256, 302) (256, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAE3CAYAAACEkGprAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgzklEQVR4nO3deVTVdeL/8dcF5eICuGKYiDT+cgFFEceDS5lbLplaUzbjXtMmbuE0ZeaxLEPbzDIty6QZj6JNbk3a5L7mhAhp5taMJiWmhYJoonI/vz/m6z0RqFy58HnjfT7Ouedw3/fD5/O6XINX78/73o/DsixLAAAABvKzOwAAAMCVUFQAAICxKCoAAMBYFBUAAGAsigoAADAWRQUAABiLogIAAIxFUQEAAMaqZHeA0nC5XDp27JiCgoLkcDjsjgMAAErAsiydOXNG9evXl5/f1edMKnRROXbsmMLDw+2OAQAArkNmZqYaNGhw1W0qdFEJCgqSJLXu+6z8KwfanKaUboArGZz+f/52R/AK/3y7E3jHxdgzdkcotUsXKvSvKDfn/ip2R/CKiKVZdkcotQOjQu2O4BX1N1TsvxmXLp5X2r9ecv8dv5oK/Vvg8uke/8qBqkRRsZ2/8wYpKnYH8BJX1Yt2Ryg1V6UK/SvKzd9ZwX8//Z9Kfk67I5SaX5Ub5LWoXPH/Zkgq0bINFtMCAABjUVQAAICxKCoAAMBYFBUAAGAsigoAADAWRQUAABiLogIAAIxFUQEAAMaiqAAAAGNRVAAAgLEoKgAAwFgUFQAAYCyKCgAAMBZFBQAAGIuiAgAAjEVRAQAAxqKoAAAAY9leVGbPnq3IyEgFBgaqTZs22rJli92RAACAIWwtKosXL9a4ceM0ceJEpaenq1OnTurVq5eOHj1qZywAAGAIW4vK66+/roceekh//vOf1axZM73xxhsKDw/XnDlz7IwFAAAMYVtRuXDhgtLS0tSjR49C4z169ND27dttSgUAAExSya4D//TTTyooKFC9evUKjderV0/Hjx8v9nvy8/OVn5/vvp+bm1umGQEAgL1sX0zrcDgK3bcsq8jYZUlJSQoJCXHfwsPDyyMiAACwiW1FpU6dOvL39y8ye3LixIkisyyXTZgwQTk5Oe5bZmZmeUQFAAA2sa2oBAQEqE2bNlqzZk2h8TVr1qh9+/bFfo/T6VRwcHChGwAAuHHZtkZFkhITEzVkyBDFxcUpPj5ec+fO1dGjR/XYY4/ZGQsAABjC1qIycOBA/fzzz5oyZYqysrIUHR2tVatWKSIiws5YAADAELYWFUkaOXKkRo4caXcMAABgINvf9QMAAHAlFBUAAGAsigoAADAWRQUAABiLogIAAIxFUQEAAMaiqAAAAGNRVAAAgLEoKgAAwFgUFQAAYCyKCgAAMBZFBQAAGIuiAgAAjEVRAQAAxqKoAAAAY1FUAACAsSgqAADAWBQVAABgrEp2B/CGvPty5V813+4YpWJtq2l3hFILyLE7gXfkV/yXQpIU8O8guyOUmivurN0RvCK/lmV3BK/IbneT3RFKLeBnh90RvOJCtYr9b6rgQsnnSZhRAQAAxqKoAAAAY1FUAACAsSgqAADAWBQVAABgLIoKAAAwFkUFAAAYi6ICAACMRVEBAADGoqgAAABjUVQAAICxKCoAAMBYFBUAAGAsigoAADAWRQUAABiLogIAAIxFUQEAAMaiqAAAAGNRVAAAgLEoKgAAwFi2FpXNmzerb9++ql+/vhwOh5YvX25nHAAAYBhbi8rZs2cVExOjWbNm2RkDAAAYqpKdB+/Vq5d69eplZwQAAGAwW4uKp/Lz85Wfn+++n5uba2MaAABQ1irUYtqkpCSFhIS4b+Hh4XZHAgAAZahCFZUJEyYoJyfHfcvMzLQ7EgAAKEMV6tSP0+mU0+m0OwYAACgnFWpGBQAA+BZbZ1Ty8vL07bffuu8fPnxYGRkZqlWrlho2bGhjMgAAYAJbi8rOnTt1xx13uO8nJiZKkoYNG6bk5GSbUgEAAFPYWlQ6d+4sy7LsjAAAAAzGGhUAAGAsigoAADAWRQUAABiLogIAAIzlcVFZu3btFR979913SxUGAADg1zwuKn369NH48eN14cIF99jJkyfVt29fTZgwwavhAACAb/O4qGzevFmffPKJ2rZtq7179+rTTz9VdHS08vLy9NVXX5VFRgAA4KM8Lirt2rVTenq6WrZsqTZt2mjAgAEaP3681q9fz9WMAQCAV13XYtoDBw4oNTVVDRo0UKVKlbR//36dO3fO29kAAICP87ioTJs2TfHx8erevbu+/vprpaamumdYvvjii7LICAAAfJTHRWXmzJlavny53nrrLQUGBioqKkpffvml7rnnHnXu3LkMIgIAAF/l8bV+9uzZozp16hQaq1y5sl555RXdddddXgsGAADg8YxKnTp1dPr0ab3//vuaMGGCsrOzJUm7du1S48aNvR4QAAD4Lo9nVHbv3q1u3bopJCRER44c0cMPP6xatWpp2bJl+u677/S3v/2tLHICAAAf5PGMSmJiooYPH65Dhw4pMDDQPd6rVy9t3rzZq+EAAIBv87iopKam6tFHHy0yfvPNN+v48eNeCQUAACBdR1EJDAxUbm5ukfEDBw6obt26XgkFAAAgXUdR6devn6ZMmaKLFy9KkhwOh44ePaqnn35a9957r9cDAgAA3+XxYtpXX31VvXv3VmhoqH755RfdfvvtOn78uOLj4zV16tSyyHhNecery69K4LU3NNiix9+yO0KpTb6ljd0RvGL8t3vtjuAVo/7xZ7sjlFqtT6vYHcErzv3htN0RvCLvRE27I5Sa34Vrb1MRZPc9a3eEUnGdOy8tKdm2HheV4OBgbd26VevXr9euXbvkcrkUGxurbt26eborAACAq/K4qFzWpUsXdenSxZtZAAAACilRUXnzzTdLvMMxY8ZcdxgAAIBfK1FRmTFjRqH7J0+e1Llz51SjRg1J0unTp1W1alWFhoZSVAAAgNeU6F0/hw8fdt+mTp2qVq1aad++fcrOzlZ2drb27dun2NhYvfDCC2WdFwAA+BCP3548adIkvfXWW2rSpIl7rEmTJpoxY4aeffZZr4YDAAC+zeOikpWV5f4MlV8rKCjQjz/+6JVQAAAA0nUUla5du+rhhx/Wzp07ZVmWJGnnzp169NFHeYsyAADwKo+LygcffKCbb75Zv//97xUYGCin06l27dopLCxM77//fllkBAAAPsrjz1GpW7euVq1apYMHD2r//v2yLEvNmjXTrbfeWhb5AACAD7vuD3y79dZbKScAAKBMeVxUCgoKlJycrHXr1unEiRNyuVyFHl+/fr3XwgEAAN/mcVEZO3askpOT1adPH0VHR8vhcJRFLgAAAM+LSkpKipYsWaLevXuXRR4AAAA3j9/1ExAQoMaNG5dFFgAAgEI8Lirjx4/XzJkz3Z+hAgAAUFY8PvWzdetWbdiwQatXr1ZUVJQqV65c6PGlS5d6LRwAAPBtHheVGjVqaMCAAWWRBQAAoBCPi8r8+fPLIgcAAEARHq9RAQAAKC8lmlGJjY3VunXrVLNmTbVu3fqqn52ya9euEh88KSlJS5cu1f79+1WlShW1b99e06dPV5MmTUq8DwAAcOMqUVHp16+fnE6nJKl///5eO/imTZuUkJCgtm3b6tKlS5o4caJ69Oihb775RtWqVfPacQAAQMVUoqIyefLkYr8urc8++6zQ/fnz5ys0NFRpaWm67bbbvHYcAABQMV33RQnLQk5OjiSpVq1axT6en5+v/Px89/3c3NxyyQUAAOxhzGJay7KUmJiojh07Kjo6uthtkpKSFBIS4r6Fh4eXc0oAAFCejCkqo0aN0u7du7Vo0aIrbjNhwgTl5OS4b5mZmeWYEAAAlDcjTv2MHj1aK1eu1ObNm9WgQYMrbud0Ot2LegEAwI3P1qJiWZZGjx6tZcuWaePGjYqMjLQzDgAAMIzHRaWgoEDJyclat26dTpw4IZfLVejx9evXl3hfCQkJWrhwoVasWKGgoCAdP35ckhQSEqIqVap4Gg0AANxgPC4qY8eOVXJysvr06aPo6OirfvjbtcyZM0eS1Llz50Lj8+fP1/Dhw697vwAA4MbgcVFJSUnRkiVL1Lt371If3LKsUu8DAADcuDx+109AQIAaN25cFlkAAAAK8biojB8/XjNnzmQ2BAAAlDmPT/1s3bpVGzZs0OrVqxUVFaXKlSsXenzp0qVeCwcAAHybx0WlRo0aGjBgQFlkAQAAKMTjojJ//vyyyAEAAFDEdX2E/qVLl7R27Vq9++67OnPmjCTp2LFjysvL82o4AADg2zyeUfnuu+/Us2dPHT16VPn5+erevbuCgoL08ssv6/z583rnnXfKIicAAPBBHs+ojB07VnFxcTp16lShT48dMGCA1q1b59VwAADAt13Xu362bdumgICAQuMRERH64YcfvBYMAADA4xkVl8ulgoKCIuPff/+9goKCvBIKAABAuo6i0r17d73xxhvu+w6HQ3l5eZo8ebJXPlYfAADgMo9P/cyYMUN33HGHmjdvrvPnz+tPf/qTDh06pDp16mjRokVlkREAAPgoj4tK/fr1lZGRoZSUFKWlpcnlcumhhx7SoEGDCi2uBQAAKC2Pi8qCBQs0ePBgjRgxQiNGjCj02JNPPqlXXnnFa+EAAIBv83iNyqhRo/TPf/6zyPgTTzyhBQsWeCUUAACAdB1FJSUlRYMHD9bmzZvdY6NHj9aSJUu0YcMGr4YDAAC+zeOi0rNnT73zzjvq37+/du7cqZEjR2rp0qXasGGDmjZtWhYZAQCAj/J4jYokPfDAAzp16pQ6duyounXratOmTWrcuLG3s5VYtXpn5V/1km3H94bJh/vZHaHUDi+qbXcEr+hRNcPuCF7xuxd22x2h1Api7Pu94k2n9tawO4JX/K73EbsjlNrwm7fZHcErntpyn90RSsX1i6vE25aoqCQmJhY7HhoaqtatW2v27Nnusddff73EBwcAALiaEhWV9PT0Ysd/97vfKTc31/24w+HwXjIAAODzSlRUWCQLAADs4PFi2l/7/vvvuRAhAAAoM9d1UcIpU6YoJCREERERatiwoWrUqKEXXnhBLlfJF8cAAABci8fv+pk4caLmzZunadOmqUOHDrIsS9u2bdNzzz2n8+fPa+rUqWWREwAA+CCPi8qHH36o999/X3fffbd7LCYmRjfffLNGjhxJUQEAAF7j8amf7OzsYj/YrWnTpsrOzvZKKAAAAOk6ikpMTIxmzZpVZHzWrFmKiYnxSigAAADpOk79vPzyy+rTp4/Wrl2r+Ph4ORwObd++XZmZmVq1alVZZAQAAD7K4xmV22+/XQcPHtSAAQN0+vRpZWdn65577tGBAwfUqVOnssgIAAB8lMczKkePHlV4eHixi2aPHj2qhg0beiUYAACAxzMqkZGROnnyZJHxn3/+WZGRkV4JBQAAIF1HUbEsq9hr+uTl5SkwMNAroQAAACQPTv1cvoKyw+HQpEmTVLVqVfdjBQUF+ve//61WrVp5PSAAAPBdJS4ql6+QbFmW9uzZo4CAAPdjAQEBiomJ0V/+8hfvJwQAAD6rxEXl8hWUR4wYoZkzZyo4OLjMQgEAAEjX8a6f+fPnl0UOAACAIjxeTAsAAFBeKCoAAMBYthaVOXPmqGXLlgoODlZwcLDi4+O1evVqOyMBAACD2FpUGjRooGnTpmnnzp3auXOnunTpon79+mnv3r12xgIAAIbweDGtN/Xt27fQ/alTp2rOnDnasWOHoqKibEoFAABMYWtR+bWCggJ99NFHOnv2rOLj44vdJj8/X/n5+e77ubm55RUPAADYwPbFtHv27FH16tXldDr12GOPadmyZWrevHmx2yYlJSkkJMR9Cw8PL+e0AACgPNleVJo0aaKMjAzt2LFDjz/+uIYNG6Zvvvmm2G0nTJignJwc9y0zM7Oc0wIAgPJk+6mfgIAANW7cWJIUFxen1NRUzZw5U++++26RbZ1Op5xOZ3lHBAAANrF9RuW3LMsqtA4FAAD4LltnVJ555hn16tVL4eHhOnPmjFJSUrRx40Z99tlndsYCAACGsLWo/PjjjxoyZIiysrIUEhKili1b6rPPPlP37t3tjAUAAAxha1GZN2+enYcHAACGM26NCgAAwGUUFQAAYCyKCgAAMBZFBQAAGIuiAgAAjEVRAQAAxqKoAAAAY1FUAACAsSgqAADAWBQVAABgLIoKAAAwFkUFAAAYi6ICAACMRVEBAADGoqgAAABjUVQAAICxKCoAAMBYFBUAAGCsSnYH8IazJ6vKr0qg3TFK5e4mW+yOUGptIo/YHcErblk60u4IXhH8kL/dEUott0mB3RG8wu8Xy+4IXnEwraHdEUrtnalhdkfwisrdKtsdoVRc50v+3zYzKgAAwFgUFQAAYCyKCgAAMBZFBQAAGIuiAgAAjEVRAQAAxqKoAAAAY1FUAACAsSgqAADAWBQVAABgLIoKAAAwFkUFAAAYi6ICAACMRVEBAADGoqgAAABjUVQAAICxKCoAAMBYFBUAAGAsigoAADAWRQUAABjLmKKSlJQkh8OhcePG2R0FAAAYwoiikpqaqrlz56ply5Z2RwEAAAaxvajk5eVp0KBBeu+991SzZk274wAAAIPYXlQSEhLUp08fdevW7Zrb5ufnKzc3t9ANAADcuCrZefCUlBTt2rVLqampJdo+KSlJzz//fBmnAgAAprBtRiUzM1Njx47VggULFBgYWKLvmTBhgnJycty3zMzMMk4JAADsZNuMSlpamk6cOKE2bdq4xwoKCrR582bNmjVL+fn58vf3L/Q9TqdTTqezvKMCAACb2FZUunbtqj179hQaGzFihJo2baqnnnqqSEkBAAC+x7aiEhQUpOjo6EJj1apVU+3atYuMAwAA32T7u34AAACuxNZ3/fzWxo0b7Y4AAAAMwowKAAAwFkUFAAAYi6ICAACMRVEBAADGoqgAAABjUVQAAICxKCoAAMBYFBUAAGAsigoAADAWRQUAABiLogIAAIxFUQEAAMaiqAAAAGNRVAAAgLEoKgAAwFgUFQAAYCyKCgAAMFYluwOUhmVZkiTX+fM2Jym9X/Iu2R2h1M5edNkdwStcv1T8f0+SVJDvb3eEUnP9UmB3BO8477A7Af7PpUsX7Y7gFa7zFfv37eW/25f/jl+NwyrJVob6/vvvFR4ebncMAABwHTIzM9WgQYOrblOhi4rL5dKxY8cUFBQkh6Ns/o8lNzdX4eHhyszMVHBwcJkcAyXDa2EOXguz8HqYg9eiZCzL0pkzZ1S/fn35+V19FUqFPvXj5+d3zSbmLcHBwfyjMwSvhTl4LczC62EOXotrCwkJKdF2LKYFAADGoqgAAABjUVSuwel0avLkyXI6nXZH8Xm8FubgtTALr4c5eC28r0IvpgUAADc2ZlQAAICxKCoAAMBYFBUAAGAsigoAADAWReUqZs+ercjISAUGBqpNmzbasmWL3ZF8UlJSktq2baugoCCFhoaqf//+OnDggN2xoP+9Ng6HQ+PGjbM7ik/64YcfNHjwYNWuXVtVq1ZVq1atlJaWZncsn3Pp0iU9++yzioyMVJUqVXTLLbdoypQpcrkq9vV4TEFRuYLFixdr3LhxmjhxotLT09WpUyf16tVLR48etTuaz9m0aZMSEhK0Y8cOrVmzRpcuXVKPHj109uxZu6P5tNTUVM2dO1ctW7a0O4pPOnXqlDp06KDKlStr9erV+uabb/Taa6+pRo0adkfzOdOnT9c777yjWbNmad++fXr55Zf1yiuv6K233rI72g2BtydfQbt27RQbG6s5c+a4x5o1a6b+/fsrKSnJxmQ4efKkQkNDtWnTJt122212x/FJeXl5io2N1ezZs/Xiiy+qVatWeuONN+yO5VOefvppbdu2jZleA9x1112qV6+e5s2b5x679957VbVqVf3973+3MdmNgRmVYly4cEFpaWnq0aNHofEePXpo+/btNqXCZTk5OZKkWrVq2ZzEdyUkJKhPnz7q1q2b3VF81sqVKxUXF6f77rtPoaGhat26td577z27Y/mkjh07at26dTp48KAk6auvvtLWrVvVu3dvm5PdGCr0RQnLyk8//aSCggLVq1ev0Hi9evV0/Phxm1JB+t8VNxMTE9WxY0dFR0fbHccnpaSkaNeuXUpNTbU7ik/773//qzlz5igxMVHPPPOMvvzyS40ZM0ZOp1NDhw61O55Peeqpp5STk6OmTZvK399fBQUFmjp1qv74xz/aHe2GQFG5CofDUei+ZVlFxlC+Ro0apd27d2vr1q12R/FJmZmZGjt2rD7//HMFBgbaHcenuVwuxcXF6aWXXpIktW7dWnv37tWcOXMoKuVs8eLFWrBggRYuXKioqChlZGRo3Lhxql+/voYNG2Z3vAqPolKMOnXqyN/fv8jsyYkTJ4rMsqD8jB49WitXrtTmzZvVoEEDu+P4pLS0NJ04cUJt2rRxjxUUFGjz5s2aNWuW8vPz5e/vb2NC3xEWFqbmzZsXGmvWrJk+/vhjmxL5rieffFJPP/20HnjgAUlSixYt9N133ykpKYmi4gWsUSlGQECA2rRpozVr1hQaX7Nmjdq3b29TKt9lWZZGjRqlpUuXav369YqMjLQ7ks/q2rWr9uzZo4yMDPctLi5OgwYNUkZGBiWlHHXo0KHI2/QPHjyoiIgImxL5rnPnzsnPr/CfU39/f96e7CXMqFxBYmKihgwZori4OMXHx2vu3Lk6evSoHnvsMbuj+ZyEhAQtXLhQK1asUFBQkHumKyQkRFWqVLE5nW8JCgoqsjaoWrVqql27NmuGytkTTzyh9u3b66WXXtL999+vL7/8UnPnztXcuXPtjuZz+vbtq6lTp6phw4aKiopSenq6Xn/9dT344IN2R7sxWLiit99+24qIiLACAgKs2NhYa9OmTXZH8kmSir3Nnz/f7miwLOv222+3xo4da3cMn/TJJ59Y0dHRltPptJo2bWrNnTvX7kg+KTc31xo7dqzVsGFDKzAw0LrlllusiRMnWvn5+XZHuyHwOSoAAMBYrFEBAADGoqgAAABjUVQAAICxKCoAAMBYFBUAAGAsigoAADAWRQUAABiLogJUcJ07d9a4cePsjuGR4cOHq3///u77FeU5OBwOLV++3O4YgE/hI/SBCm7p0qWqXLlyuR/3ueee0/Lly5WRkVHqfdn1HDyVlZWlmjVr2h0D8CkUFaCCq1Wrlt0RSq2iPIebbrrJ7giAz+HUD1DB/fa0SaNGjfTSSy/pwQcfVFBQkBo2bFjoQnVHjhyRw+FQSkqK2rdvr8DAQEVFRWnjxo3ubZKTk1WjRo1Cx1m+fLkcDof78eeff15fffWVHA6HHA6HkpOTi81XUFCgxMRE1ahRQ7Vr19Zf//pX/fbKHcU9hxdffFFDhw5V9erVFRERoRUrVujkyZPq16+fqlevrhYtWmjnzp2F9rN9+3bddtttqlKlisLDwzVmzBidPXu2xD+bCxcuaNSoUQoLC1NgYKAaNWqkpKQk9+O/PfWzZ88edenSRVWqVFHt2rX1yCOPKC8vz/345VNcr776qsLCwlS7dm0lJCTo4sWLxf6sABRFUQFuQK+99pri4uKUnp6ukSNH6vHHH9f+/fsLbfPkk09q/PjxSk9PV/v27XX33Xfr559/LtH+Bw4cqPHjxysqKkpZWVnKysrSwIEDr5jlgw8+0Lx587R161ZlZ2dr2bJl1zzGjBkz1KFDB6Wnp6tPnz4aMmSIhg4dqsGDB2vXrl1q3Lixhg4d6i49e/bs0Z133ql77rlHu3fv1uLFi7V161aNGjWqxD+bN998UytXrtSSJUt04MABLViwQI0aNSo237lz59SzZ0/VrFlTqamp+uijj7R27doix9uwYYP+85//aMOGDfrwww+VnJx8xVIHoBj2XhMRQGn99urFERER1uDBg933XS6XFRoaas2ZM8eyLMs6fPiwJcmaNm2ae5uLFy9aDRo0sKZPn25ZlmXNnz/fCgkJKXScZcuWWb/+lTF58mQrJibmmvnCwsKKPVa/fv1K/ByysrIsSdakSZPcY1988YUlycrKyrIsy7KGDBliPfLII4WOvWXLFsvPz8/65ZdfSvSzGT16tNWlSxfL5XIV+1wkWcuWLbMsy7Lmzp1r1axZ08rLy3M//umnn1p+fn7W8ePHLcuyrGHDhlkRERHWpUuX3Nvcd9991sCBA6/8AwNQCDMqwA2oZcuW7q8dDoduuukmnThxotA28fHx7q8rVaqkuLg47du3z6s5cnJylJWVVeyxruXXz6FevXqSpBYtWhQZu/y80tLSlJycrOrVq7tvd955p1wulw4fPlzsfn/7sxk+fLgyMjLUpEkTjRkzRp9//vkV8+3bt08xMTGqVq2ae6xDhw5yuVw6cOCAeywqKkr+/v7u+2FhYUVeCwBXxmJa4Ab023fQOBwOuVyua37f5TUofn5+RdaRlPe6il8/h8u5ihu7/LxcLpceffRRjRkzpsi+GjZsWOx+L+/n8j5iY2N1+PBhrV69WmvXrtX999+vbt266R//+EeRfVqW5c7wW78ev97XAsD/MKMC+KgdO3a4v7506ZLS0tLUtGlTSVLdunV15syZQgtRf/s25ICAABUUFFz1GCEhIQoLCyv2WN4WGxurvXv3qnHjxkVuAQEBJd5PcHCwBg4cqPfee0+LFy/Wxx9/rOzs7CLbNW/eXBkZGYV+Rtu2bZOfn59uvfVWrzwnABQVwGe9/fbbWrZsmfbv36+EhASdOnVKDz74oCSpXbt2qlq1qp555hl9++23WrhwYZEFoI0aNdLhw4eVkZGhn376Sfn5+cUeZ+zYsZo2bZr7WCNHjtTp06e9/nyeeuopffHFF0pISFBGRoYOHTqklStXavTo0SXex4wZM5SSkqL9+/fr4MGD+uijj3TTTTcVeQeUJA0aNEiBgYEaNmyYvv76a23YsEGjR4/WkCFD3KelAJQeRQXwUdOmTdP06dMVExOjLVu2aMWKFapTp46k/32uyYIFC7Rq1Sq1aNFCixYt0nPPPVfo+++991717NlTd9xxh+rWratFixYVe5zx48dr6NChGj58uOLj4xUUFKQBAwZ4/fm0bNlSmzZt0qFDh9SpUye1bt1akyZNUlhYWIn3Ub16dU2fPl1xcXFq27atjhw5olWrVsnPr+ivyqpVq+pf//qXsrOz1bZtW/3hD39Q165dNWvWLG8+LcDnOazfnogGcEM7cuSIIiMjlZ6erlatWtkdBwCuihkVAABgLIoKAAAwFqd+AACAsZhRAQAAxqKoAAAAY1FUAACAsSgqAADAWBQVAABgLIoKAAAwFkUFAAAYi6ICAACMRVEBAADG+v+U0SBeoI0/UwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.codebook.detach().cpu().numpy()\n",
    "C = model.token_neural_map.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape, C.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(C @ C.T)\n",
    "plt.imshow(C.T @ C)\n",
    "plt.imshow(C[:5, :10])\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE load torch.Size([83, 302])\n",
      "\n",
      "Loading a previously saved model checkpoint...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous validation loss: \t 293.92\n",
      "\n",
      "AFTER load torch.Size([83, 302])\n",
      "\n",
      "NOTE: The neural data embedding used to make the datasets may be different now than when the model was saved.\n",
      "Training for 1 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 1963 batches | lr 5.00 | ms/batch 30.23 | loss 296.31 | ppl 486886595629901464972732361284395384000791346111403443685872572540906791813881424072202987506043826901091255529613178071603478528.00\n",
      "| epoch   1 |   600/ 1963 batches | lr 5.00 | ms/batch 24.68 | loss 295.11 | ppl 145601262822247167030158214472803471399157749463539264293114348751661312739168961302644651225186767615419070493704564861344677888.00\n",
      "| epoch   1 |   900/ 1963 batches | lr 5.00 | ms/batch 22.04 | loss 295.69 | ppl 261580444959991913840874526339953819276467706837910181758769716312567079425413985460318746521335242456980214434873852010409492480.00\n",
      "| epoch   1 |  1200/ 1963 batches | lr 5.00 | ms/batch 35.31 | loss 296.22 | ppl 444122934169010880430933601077481652856575406655946966537672409337684286794063013161275324409718554906326574851461583153821384704.00\n",
      "| epoch   1 |  1500/ 1963 batches | lr 5.00 | ms/batch 27.27 | loss 297.35 | ppl 1373999742921404911019302102510339819423837296405162257453252495462437044286769914172039501495954460497432279750862082162930221056.00\n",
      "| epoch   1 |  1800/ 1963 batches | lr 5.00 | ms/batch 20.88 | loss 298.84 | ppl 6059898728079385915951742315666259186719412279032222491890005303969425347850164195107102609288607357387425426099531712611399761920.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 52.95s | valid loss 317.70 | valid ppl 940700755389089907394337816493027518508582130960141280351275026499959845455310211085087922443219255980679999803988715049179484747762499584.00\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1\n",
    "\n",
    "### DEBUG ###\n",
    "print(\"BEFORE load\", model.token_neural_map.unique(dim=0).shape, end=\"\\n\\n\")\n",
    "### DEBUG ###\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "    ### DEBUG ###\n",
    "    print(\"AFTER load\", model.token_neural_map.unique(dim=0).shape, end=\"\\n\\n\")\n",
    "    print(\n",
    "        \"NOTE: The neural data embedding used to make the datasets may be different now than when the model was saved.\"\n",
    "    )\n",
    "    ### DEBUG ###\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            try:\n",
    "                val_ppl = math.exp(val_loss)\n",
    "            except OverflowError:\n",
    "                val_ppl = float(\"inf\")\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "\n",
      "True \n",
      " tensor([[8.6814e-06, 6.3575e-06, 4.8576e-06,  ..., 1.7200e-06, 5.0517e-06,\n",
      "         5.5407e-06],\n",
      "        [8.5285e-06, 6.4129e-06, 4.9863e-06,  ..., 1.8766e-06, 5.0843e-06,\n",
      "         5.7431e-06],\n",
      "        [8.4983e-06, 6.3270e-06, 4.8138e-06,  ..., 1.7887e-06, 5.1771e-06,\n",
      "         5.6767e-06],\n",
      "        ...,\n",
      "        [8.5006e-06, 6.4774e-06, 5.0401e-06,  ..., 1.8639e-06, 5.2450e-06,\n",
      "         5.6765e-06],\n",
      "        [8.6373e-06, 6.3201e-06, 4.8424e-06,  ..., 1.6300e-06, 5.2069e-06,\n",
      "         5.5701e-06],\n",
      "        [8.4654e-06, 6.3679e-06, 4.6731e-06,  ..., 1.7283e-06, 5.0421e-06,\n",
      "         5.5913e-06]], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.token_neural_map.unique(dim=0)) - 1, end=\"\\n\\n\")\n",
    "print(model.codebook.requires_grad, \"\\n\", model.codebook.grad, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (256, 302) (256, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.codebook.detach().cpu().numpy()\n",
    "C = model.token_neural_map.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape, C.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"codebook\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(C @ C.T)\n",
    "plt.imshow(C.T @ C)\n",
    "plt.imshow(C[:5, :10])\n",
    "plt.title(\"token_neural_map\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 302]) torch.Size([1, 510, 302]) torch.Size([1, 100, 302]) torch.Size([256, 302])\n",
      "\n",
      "tensor([ 0.5456, -0.4229, -0.4225, -0.3058, -0.6988], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new data\n",
    "\n",
    "data = test_dataset[0][:-1, :].unsqueeze(0).to(DEVICE)\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0).to(DEVICE)\n",
    "max_new_tokens = 100\n",
    "\n",
    "data_gen = model.generate(data, mask, max_new_tokens, autoregressive=True, top_k=None)\n",
    "print(mask.shape, data.shape, data_gen.shape, embedding.weight.shape, end=\"\\n\\n\")\n",
    "\n",
    "### DEBUG ###\n",
    "a1 = model.token_neural_map.detach().clone()\n",
    "a2 = model.codebook.detach().clone()\n",
    "assert torch.allclose(b1, a1) and torch.allclose(b2, a2), \"Why the changes?\"\n",
    "print(data.squeeze()[-1][:5])\n",
    "print(data_gen.squeeze()[0][:5])\n",
    "### DEBUG ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120, 1]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown We want to tokenize the neural data.\n",
    "# An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# First run a test on data we know what the true token output should be.\n",
    "# This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "with torch.no_grad():\n",
    "    sequence = data\n",
    "    inp_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=data,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    # iff correct these two should match\n",
    "    print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")  # ground-truth tokens\n",
    "    print(text_dataset[\"test\"][\"text\"][0], end=\"\\n\\n\")  # ground-truth text\n",
    "    print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 100, 119, 122, 35, 100, 113, 66, 35, 100, 35, 107, 100, 113, 35, 100, 113, 35, 100, 110, 104, 117, 35, 100, 113, 35, 100, 113, 70, 104, 117, 35, 100, 113, 35, 100, 119, 35, 100, 113, 103, 35, 100, 113, 35, 100, 113, 103, 100, 35, 100, 113, 35, 100, 113, 103, 35, 100, 113, 35, 107, 100, 35, 100, 117, 35, 100, 113, 70, 104, 35, 100, 118, 66, 35, 100, 113, 117, 35, 100, 113, 103, 100, 35, 100, 113, 103, 35, 100, 119, 35, 100, 113, 117, 35, 100, 113, 35, 100, 247]\n",
      "\n",
      " atw an? a han an aker an anCer an at and an anda an and an ha ar anCe as? anr anda and at anr an a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence = data_gen\n",
    "    gen_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(gen_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(gen_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 \t {35, 36, 39, 41, 42, 47, 48, 49, 54, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# What tokens and their corresponding characters are in the training set\n",
    "real_train_tokens = set()\n",
    "for sequence in text_dataset[\"train\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_train_tokens.update(tokens)\n",
    "print(len(real_train_tokens), \"\\t\", real_train_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_train_tokens)))\n",
    "print(\"\\n\", \"~\" * 99, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence time index: 0 \n",
      "neural: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n",
      "codebook token index 35 \n",
      "mapped: tensor([-1.1940, -0.3092, -0.4478, -1.4195, -0.6186], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Basic check failed; Inconsistency in mapping!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m mapped \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtoken_neural_map[torch\u001b[38;5;241m.\u001b[39mtensor(ct, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcodebook token index\u001b[39m\u001b[38;5;124m\"\u001b[39m, ct, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mmapped:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mapped[:\u001b[38;5;241m5\u001b[39m], end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(neural, mapped), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasic check failed; Inconsistency in mapping!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(neural \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not at learn to map a vector it was trained on!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m et \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenize_neural_data(neural, token_matrix\u001b[38;5;241m=\u001b[39membedding\u001b[38;5;241m.\u001b[39mweight)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Basic check failed; Inconsistency in mapping!"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Assert should not be raised if the model learned to correctly map the tokens in the training  set\n",
    "for idx in range(data_gen.shape[1]):\n",
    "    neural = data_gen[:, [idx], :]\n",
    "    print(\"sequence time index:\", idx, \"\\nneural:\", neural.squeeze()[:5], end=\"\\n\\n\")\n",
    "\n",
    "    ct = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    mapped = model.token_neural_map[torch.tensor(ct, dtype=torch.long)]\n",
    "    print(\"codebook token index\", ct, \"\\nmapped:\", mapped[:5], end=\"\\n\\n\")\n",
    "\n",
    "    assert torch.allclose(neural, mapped), \"Basic check failed; Inconsistency in mapping!\"\n",
    "    assert torch.any(neural != 0), \"Model did not at learn to map a vector it was trained on!\"\n",
    "\n",
    "    et = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    embedded = embedding(torch.tensor(et, dtype=torch.long))\n",
    "    print(\n",
    "        \"embedding token index\",\n",
    "        et,\n",
    "        \"\\ncharacter\",\n",
    "        tokenizer.decode([et]),\n",
    "        \"\\nin train set\",\n",
    "        et in real_train_tokens,\n",
    "        \"\\nembedded:\",\n",
    "        embedded[:5],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    if et in real_train_tokens:\n",
    "        ## DEBUG ###\n",
    "        assert torch.allclose(\n",
    "            embedded, mapped.cpu()\n",
    "        ), \"The learned mapping did not converge to the true embedding!\"\n",
    "        ## DEBUG ###\n",
    "\n",
    "    print(\"~\" * 99, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([302]) tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "torch.Size([302]) tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045], device='cuda:0')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65, 302]) torch.Size([110, 302])\n",
      "\n",
      "65 84\n",
      "\n",
      "51 14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(mapped.shape, mapped[:5])\n",
    "print(neural.squeeze().shape, neural.squeeze()[:5])\n",
    "print()\n",
    "\n",
    "all_unique_vectors = torch.vstack(train_dataset).unique(dim=0)\n",
    "learned_unique_vectors = model.token_neural_map.unique(dim=0)\n",
    "print(all_unique_vectors.shape, learned_unique_vectors.shape)\n",
    "print()\n",
    "\n",
    "all_unique_vectors = {tuple(row.round(decimals=2).cpu().numpy()) for row in all_unique_vectors}\n",
    "learned_unique_vectors = {\n",
    "    tuple(row.round(decimals=2).cpu().numpy()) for row in learned_unique_vectors\n",
    "}\n",
    "print(len(all_unique_vectors), len(learned_unique_vectors))\n",
    "print()\n",
    "\n",
    "inter = all_unique_vectors.intersection(learned_unique_vectors)\n",
    "diff = all_unique_vectors - learned_unique_vectors\n",
    "print(len(inter), len(diff))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Understanding `index_add_` and `scatter_add_`.\n",
    "\n",
    "x = torch.zeros(5, 3)\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "idx = torch.tensor([4, 4, 4])\n",
    "print(f\"self = x \\n {x}\")\n",
    "# INDEX_ADD_: the dim-th dimension of source must have the same size as the length of index (which must be a vector), and all other dimensions must match self\n",
    "print(x.index_add_(0, index=idx, source=t))\n",
    "# SCATTER_ADD_: self, source, and index must have the same number of dimensions\n",
    "print(x.scatter_add_(0, index=idx.unsqueeze(-1), src=t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
