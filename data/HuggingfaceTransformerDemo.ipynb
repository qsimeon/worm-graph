{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found.\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from utils import DEVICE, BLOCK_SIZE\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from preprocess._utils import smooth_data_preprocess, reshape_calcium_data\n",
    "from CreateSyntheticDataset import (\n",
    "    save_synthetic_dataset,\n",
    "    plot_neural_signals,\n",
    "    plot_3d_trajectory,\n",
    "    tokenize_and_chunk,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `tokenizer.encode(text)`:\n",
      "\ttext: Welcome to the ðŸ¤— Tokenizers library.\n",
      "\ttokenized: [101, 6160, 2000, 1996, 100, 19204, 17629, 2015, 3075, 1012, 102]\n",
      "\tdecoded: [CLS] welcome to the [UNK] tokenizers library. [SEP]\n",
      "\n",
      "Calling `tokenizer(text)`:\n",
      "\tobject.keys(): dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "\ttext: We are very happy to show you the ðŸ¤— Transformers library.\n",
      "\ttokenized: [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 100, 19081, 3075, 1012, 102]\n",
      "\tdecoded: [CLS] we are very happy to show you the [UNK] transformers library. [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "train: <class 'list'> 1 <class 'str'> 1003854\n",
      "\n",
      "validation: <class 'list'> 1 <class 'str'> 55770\n",
      "\n",
      "test: <class 'list'> 1 <class 'str'> 55770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1963\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "text_dataset['train']['input_ids']:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 1963\n",
      "\n",
      "text_dataset['train']['input_ids'][0]:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 135\n",
      "\n",
      "text_dataset['train']['input_ids'][0][0]:\n",
      " \ttype: <class 'int'> \n",
      "\tvalue: 101\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Original sequence (text):\n",
      "\tFirst Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the\n",
      "\n",
      "Encoded sequence (tokens):\n",
      "\t [101, 2034, 6926, 1024, 2077, 2057, 10838, 2151, 2582, 1010, 2963, 2033, 3713, 1012, 2035, 1024, 3713, 1010, 3713, 1012, 2034, 6926, 1024, 2017, 2024, 2035, 10395, 2738, 2000, 3280, 2084, 2000, 6904, 15630, 2232, 1029, 2035, 1024, 10395, 1012, 10395, 1012, 2034, 6926, 1024, 2034, 1010, 2017, 2113, 29080, 2271, 7871, 4173, 2003, 2708, 4099, 2000, 1996, 2111, 1012, 2035, 1024, 2057, 2113, 1005, 1056, 1010, 2057, 2113, 1005, 1056, 1012, 2034, 6926, 1024, 2292, 2149, 3102, 2032, 1010, 1998, 2057, 1005, 2222, 2031, 9781, 2012, 2256, 2219, 3976, 1012, 2003, 1005, 1056, 1037, 14392, 1029, 2035, 1024, 2053, 2062, 3331, 2006, 1005, 1056, 1025, 2292, 2009, 2022, 2589, 1024, 2185, 1010, 2185, 999, 2117, 6926, 1024, 2028, 2773, 1010, 2204, 4480, 1012, 2034, 6926, 1024, 2057, 2024, 14729, 3532, 4480, 1010, 1996, 102]\n",
      "\n",
      "Decoded sequence (tokens):\n",
      "\t [CLS] first citizen : before we proceed any further, hear me speak. all : speak, speak. first citizen : you are all resolved rather to die than to famish? all : resolved. resolved. first citizen : first, you know caius marcius is chief enemy to the people. all : we know't, we know't. first citizen : let us kill him, and we'll have corn at our own price. is't a verdict? all : no more talking on't ; let it be done : away, away! second citizen : one word, good citizens. first citizen : we are accounted poor citizens, the [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Initiate an instance\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch\n",
    "\n",
    "    num_batches = len(text_dataset[\"train\"][\"input_ids\"])\n",
    "    for batch in range(num_batches):\n",
    "        tokens = text_dataset[\"train\"][\"input_ids\"][batch]\n",
    "        # parse into input and target\n",
    "        input = (\n",
    "            torch.LongTensor(tokens[:-1]).unsqueeze(0).to(DEVICE)\n",
    "        )  # ``[batch_size=1, seq_len]``\n",
    "        target = (\n",
    "            torch.LongTensor(tokens[1:]).unsqueeze(0).reshape(-1).to(DEVICE)\n",
    "        )  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(text_dataset[\"validation\"][\"input_ids\"])\n",
    "        for batch in range(num_batches):\n",
    "            tokens = text_dataset[\"validation\"][\"input_ids\"][batch]\n",
    "            input = torch.LongTensor(tokens[:-1]).unsqueeze(0).to(DEVICE)\n",
    "            target = torch.LongTensor(tokens[1:]).unsqueeze(0).reshape(-1).to(DEVICE)\n",
    "            seq_len = input.size(1)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a previously saved model checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 1963 batches | lr 5.00 | ms/batch 112.83 | loss  5.29 | ppl   199.05\n",
      "| epoch   1 |   600/ 1963 batches | lr 5.00 | ms/batch 93.16 | loss  5.44 | ppl   230.60\n",
      "| epoch   1 |   900/ 1963 batches | lr 5.00 | ms/batch 92.72 | loss  5.58 | ppl   264.82\n",
      "| epoch   1 |  1200/ 1963 batches | lr 5.00 | ms/batch 92.56 | loss  5.49 | ppl   243.11\n",
      "| epoch   1 |  1500/ 1963 batches | lr 5.00 | ms/batch 92.10 | loss  5.50 | ppl   243.66\n",
      "| epoch   1 |  1800/ 1963 batches | lr 5.00 | ms/batch 103.17 | loss  5.39 | ppl   219.96\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 192.14s | valid loss  5.60 | valid ppl   270.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "Loading and saving the new best model...\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1\n",
    "\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print(\"-\" * 89)\n",
    "        print(\n",
    "            f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "            f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "        )\n",
    "        print(\"-\" * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Loading and saving the new best model...\")\n",
    "    model.load_state_dict(torch.load(best_model_params_path))  # load best model states\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\"),\n",
    "    )  # save the best model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 132]) torch.Size([1, 232])\n",
      "\n",
      "[CLS] rance ta'en as shall with either part's agreement stand? baptista : not in my house, lucentio ; for, you know, pitchers have ears, and i have many servants : besides, old gremio is hearkening still ; and happily we might be interrupted. tranio : then at my lodging, an it like you : there doth my father lie ; and there, this night, we'll pass the business privately and well. send for your daughter by your servant here : my boy shall fetch the scrivener presently. the worst is this, that, at so slender warning, you [SEP]\n",
      "\n",
      ". but i know i will not i do not i will i will have not i will not i will have i will i will not i know i will i will have i will go i will i will go i know i will i do i'll i will go to me : i do have i do not to i will not so? but she be i will be i will i'twere? griea : i must i will not i will go i will be so will\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new text using test input\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = torch.LongTensor(text_dataset[\"test\"][\"input_ids\"][0]).unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=5)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 132, 302]) torch.float32 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create neural datasets\n",
    "# @markdown A synthetic dataset where the neural activity is the embeddings of tokens from the tiny Shakespeare.\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding = torch.nn.Embedding(ntokens, emsize, _freeze=True)\n",
    "\n",
    "train_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "]\n",
    "validation_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "test_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 131, 302]) torch.float32 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 131, 302]) torch.float32 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 131, 2048]) torch.float16 True cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(input_size=emsize, hidden_size=d_hid).to(DEVICE)\n",
    "\n",
    "# test input-output functionality\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "output = model(input, mask)\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the NeuralTransformer model\n",
    "\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        data = train_dataset[batch].unsqueeze(0)\n",
    "        mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = data[:, :-1, :].to(DEVICE)\n",
    "        target = data[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropopagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target\n",
    "        )  # flatens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(validation_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            data = validation_dataset[batch].unsqueeze(0)\n",
    "            mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = data[:, :-1, :].to(DEVICE)\n",
    "            target = data[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 1963 batches | lr 5.00 | ms/batch  7.09 | loss 56.83 | ppl 4796318184993763184607232.00\n",
      "| epoch   1 |   600/ 1963 batches | lr 5.00 | ms/batch  8.54 | loss 42.92 | ppl 4381754759750042112.00\n",
      "| epoch   1 |   900/ 1963 batches | lr 5.00 | ms/batch 13.50 | loss 38.76 | ppl 68220055670569984.00\n",
      "| epoch   1 |  1200/ 1963 batches | lr 5.00 | ms/batch 10.25 | loss 35.29 | ppl 2115669240251705.50\n",
      "| epoch   1 |  1500/ 1963 batches | lr 5.00 | ms/batch  7.86 | loss 32.56 | ppl 137766364132098.03\n",
      "| epoch   1 |  1800/ 1963 batches | lr 5.00 | ms/batch  7.22 | loss 29.51 | ppl 6567100387453.71\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 17.85s | valid loss 24.69 | valid ppl 52830751510.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   300/ 1963 batches | lr 4.95 | ms/batch  7.15 | loss 26.67 | ppl 381942194859.47\n",
      "| epoch   2 |   600/ 1963 batches | lr 4.95 | ms/batch  7.18 | loss 26.19 | ppl 236944814676.46\n",
      "| epoch   2 |   900/ 1963 batches | lr 4.95 | ms/batch  7.08 | loss 25.37 | ppl 104341715309.95\n",
      "| epoch   2 |  1200/ 1963 batches | lr 4.95 | ms/batch  7.14 | loss 23.95 | ppl 25204957611.11\n",
      "| epoch   2 |  1500/ 1963 batches | lr 4.95 | ms/batch  7.13 | loss 23.01 | ppl 9843093485.66\n",
      "| epoch   2 |  1800/ 1963 batches | lr 4.95 | ms/batch  7.05 | loss 21.55 | ppl 2285547085.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 14.35s | valid loss 17.70 | valid ppl 48631246.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   300/ 1963 batches | lr 4.90 | ms/batch  7.17 | loss 20.22 | ppl 604558685.69\n",
      "| epoch   3 |   600/ 1963 batches | lr 4.90 | ms/batch  7.07 | loss 20.46 | ppl 767597208.65\n",
      "| epoch   3 |   900/ 1963 batches | lr 4.90 | ms/batch  7.05 | loss 20.00 | ppl 487425482.22\n",
      "| epoch   3 |  1200/ 1963 batches | lr 4.90 | ms/batch  6.99 | loss 19.16 | ppl 209192816.82\n",
      "| epoch   3 |  1500/ 1963 batches | lr 4.90 | ms/batch  7.02 | loss 18.45 | ppl 103163204.53\n",
      "| epoch   3 |  1800/ 1963 batches | lr 4.90 | ms/batch  7.11 | loss 17.35 | ppl 34174924.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 14.26s | valid loss 14.81 | valid ppl 2696598.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   300/ 1963 batches | lr 4.85 | ms/batch  7.14 | loss 15.89 | ppl 7976722.70\n",
      "| epoch   4 |   600/ 1963 batches | lr 4.85 | ms/batch  6.99 | loss 15.24 | ppl 4144585.38\n",
      "| epoch   4 |   900/ 1963 batches | lr 4.85 | ms/batch  7.04 | loss 13.92 | ppl 1107448.91\n",
      "| epoch   4 |  1200/ 1963 batches | lr 4.85 | ms/batch 15.84 | loss 10.87 | ppl 52777.15\n",
      "| epoch   4 |  1500/ 1963 batches | lr 4.85 | ms/batch 12.27 | loss  7.81 | ppl  2463.50\n",
      "| epoch   4 |  1800/ 1963 batches | lr 4.85 | ms/batch  7.04 | loss  0.88 | ppl     2.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 18.41s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   300/ 1963 batches | lr 4.80 | ms/batch  7.09 | loss  0.79 | ppl     2.21\n",
      "| epoch   5 |   600/ 1963 batches | lr 4.80 | ms/batch  6.99 | loss  0.79 | ppl     2.20\n",
      "| epoch   5 |   900/ 1963 batches | lr 4.80 | ms/batch  7.00 | loss  0.79 | ppl     2.20\n",
      "| epoch   5 |  1200/ 1963 batches | lr 4.80 | ms/batch  7.05 | loss  0.79 | ppl     2.20\n",
      "| epoch   5 |  1500/ 1963 batches | lr 4.80 | ms/batch  7.08 | loss  0.79 | ppl     2.20\n",
      "| epoch   5 |  1800/ 1963 batches | lr 4.80 | ms/batch  7.17 | loss  0.79 | ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 14.22s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   300/ 1963 batches | lr 4.75 | ms/batch  7.32 | loss  0.79 | ppl     2.21\n",
      "| epoch   6 |   600/ 1963 batches | lr 4.75 | ms/batch  7.10 | loss  0.79 | ppl     2.20\n",
      "| epoch   6 |   900/ 1963 batches | lr 4.75 | ms/batch  7.10 | loss  0.79 | ppl     2.20\n",
      "| epoch   6 |  1200/ 1963 batches | lr 4.75 | ms/batch  7.20 | loss  0.79 | ppl     2.20\n",
      "| epoch   6 |  1500/ 1963 batches | lr 4.75 | ms/batch  7.08 | loss  0.79 | ppl     2.20\n",
      "| epoch   6 |  1800/ 1963 batches | lr 4.75 | ms/batch  7.33 | loss  0.79 | ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 14.45s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   300/ 1963 batches | lr 4.71 | ms/batch  7.23 | loss  0.79 | ppl     2.21\n",
      "| epoch   7 |   600/ 1963 batches | lr 4.71 | ms/batch  7.12 | loss  0.79 | ppl     2.20\n",
      "| epoch   7 |   900/ 1963 batches | lr 4.71 | ms/batch  7.10 | loss  0.79 | ppl     2.20\n",
      "| epoch   7 |  1200/ 1963 batches | lr 4.71 | ms/batch  7.11 | loss  0.79 | ppl     2.20\n",
      "| epoch   7 |  1500/ 1963 batches | lr 4.71 | ms/batch  7.06 | loss  0.79 | ppl     2.20\n",
      "| epoch   7 |  1800/ 1963 batches | lr 4.71 | ms/batch  7.08 | loss  0.79 | ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 14.35s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   300/ 1963 batches | lr 4.66 | ms/batch  7.28 | loss  0.79 | ppl     2.21\n",
      "| epoch   8 |   600/ 1963 batches | lr 4.66 | ms/batch  7.04 | loss  0.79 | ppl     2.20\n",
      "| epoch   8 |   900/ 1963 batches | lr 4.66 | ms/batch  7.02 | loss  0.79 | ppl     2.20\n",
      "| epoch   8 |  1200/ 1963 batches | lr 4.66 | ms/batch  7.11 | loss  0.79 | ppl     2.20\n",
      "| epoch   8 |  1500/ 1963 batches | lr 4.66 | ms/batch  7.08 | loss  0.79 | ppl     2.20\n",
      "| epoch   8 |  1800/ 1963 batches | lr 4.66 | ms/batch  7.10 | loss  0.79 | ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 14.30s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |   300/ 1963 batches | lr 4.61 | ms/batch  7.08 | loss  0.79 | ppl     2.21\n",
      "| epoch   9 |   600/ 1963 batches | lr 4.61 | ms/batch  7.23 | loss  0.79 | ppl     2.20\n",
      "| epoch   9 |   900/ 1963 batches | lr 4.61 | ms/batch  7.25 | loss  0.79 | ppl     2.20\n",
      "| epoch   9 |  1200/ 1963 batches | lr 4.61 | ms/batch  7.15 | loss  0.79 | ppl     2.20\n",
      "| epoch   9 |  1500/ 1963 batches | lr 4.61 | ms/batch  7.11 | loss  0.79 | ppl     2.20\n",
      "| epoch   9 |  1800/ 1963 batches | lr 4.61 | ms/batch  7.10 | loss  0.79 | ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 14.37s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |   300/ 1963 batches | lr 4.57 | ms/batch  7.17 | loss  0.79 | ppl     2.21\n",
      "| epoch  10 |   600/ 1963 batches | lr 4.57 | ms/batch  7.05 | loss  0.79 | ppl     2.20\n",
      "| epoch  10 |   900/ 1963 batches | lr 4.57 | ms/batch  7.05 | loss  0.79 | ppl     2.20\n",
      "| epoch  10 |  1200/ 1963 batches | lr 4.57 | ms/batch  7.12 | loss  0.79 | ppl     2.20\n",
      "| epoch  10 |  1500/ 1963 batches | lr 4.57 | ms/batch  6.94 | loss  0.79 | ppl     2.20\n",
      "| epoch  10 |  1800/ 1963 batches | lr 4.57 | ms/batch  7.08 | loss  0.79 | ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 14.27s | valid loss  0.79 | valid ppl     2.20\n",
      "-----------------------------------------------------------------------------------------\n",
      "Loading and saving the new best model...\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 10\n",
    "\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print(\"-\" * 89)\n",
    "        print(\n",
    "            f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "            f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "        )\n",
    "        print(\"-\" * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Loading and saving the new best model...\")\n",
    "    model.load_state_dict(torch.load(best_model_params_path))  # load best model states\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        os.path.join(\"../models/\", \"neural_transformer_model.pt\"),\n",
    "    )  # save the best model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 132, 302]) torch.Size([1, 232, 302])\n",
      "\n",
      "torch.Size([1, 132, 30522])\n",
      "\n",
      "[101, 2743, 3401, 11937, 1005, 4372, 2004, 4618, 2007, 2593, 2112, 1005, 1055, 3820, 3233, 1029, 7550, 2050, 1024, 2025, 1999, 2026, 2160, 1010, 19913, 16778, 2080, 1025, 2005, 1010, 2017, 2113, 1010, 23232, 2031, 5551, 1010, 1998, 1045, 2031, 2116, 8858, 1024, 4661, 1010, 2214, 24665, 23238, 2080, 2003, 2963, 7520, 2075, 2145, 1025, 1998, 11361, 2057, 2453, 2022, 7153, 1012, 25283, 3695, 1024, 2059, 2012, 2026, 26859, 1010, 2019, 2009, 2066, 2017, 1024, 2045, 11089, 2232, 2026, 2269, 4682, 1025, 1998, 2045, 1010, 2023, 2305, 1010, 2057, 1005, 2222, 3413, 1996, 2449, 9139, 1998, 2092, 1012, 4604, 2005, 2115, 2684, 2011, 2115, 7947, 2182, 1024, 2026, 2879, 4618, 18584, 1996, 8040, 3089, 8159, 2121, 12825, 1012, 1996, 5409, 2003, 2023, 1010, 2008, 1010, 2012, 2061, 10944, 5432, 1010, 2017, 102]\n",
      "\n",
      "[CLS] rance ta'en as shall with either part's agreement stand? baptista : not in my house, lucentio ; for, you know, pitchers have ears, and i have many servants : besides, old gremio is hearkening still ; and happily we might be interrupted. tranio : then at my lodging, an it like you : there doth my father lie ; and there, this night, we'll pass the business privately and well. send for your daughter by your servant here : my boy shall fetch the scrivener presently. the worst is this, that, at so slender warning, you [SEP]\n",
      "\n",
      "[101, 2743, 3401, 11937, 1005, 4372, 2004, 4618, 2007, 2593, 2112, 1005, 1055, 3820, 3233, 1029, 7550, 2050, 1024, 2025, 1999, 2026, 2160, 1010, 19913, 16778, 2080, 1025, 2005, 1010, 2017, 2113, 1010, 23232, 2031, 5551, 1010, 1998, 1045, 2031, 2116, 8858, 1024, 4661, 1010, 2214, 24665, 23238, 2080, 2003, 2963, 7520, 2075, 2145, 1025, 1998, 11361, 2057, 2453, 2022, 7153, 1012, 25283, 3695, 1024, 2059, 2012, 2026, 26859, 1010, 2019, 2009, 2066, 2017, 1024, 2045, 11089, 2232, 2026, 2269, 4682, 1025, 1998, 2045, 1010, 2023, 2305, 1010, 2057, 1005, 2222, 3413, 1996, 2449, 9139, 1998, 2092, 1012, 4604, 2005, 2115, 2684, 2011, 2115, 7947, 2182, 1024, 2026, 2879, 4618, 18584, 1996, 8040, 3089, 8159, 2121, 12825, 1012, 1996, 5409, 2003, 2023, 1010, 2008, 1010, 2012, 2061, 10944, 5432, 1010, 2017, 102]\n",
      "\n",
      "torch.Size([1, 100, 30522])\n",
      "\n",
      "[12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934, 12934]\n",
      "\n",
      "mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock mock\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new data using test input\n",
    "\n",
    "data = test_dataset[0].unsqueeze(0).to(DEVICE)\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0).to(DEVICE)\n",
    "embedding = embedding.to(DEVICE)\n",
    "\n",
    "max_new_tokens = 100\n",
    "data_gen = model.transformer_generate(data, mask, max_new_tokens)\n",
    "\n",
    "print(data.shape, data_gen.shape, end=\"\\n\\n\")\n",
    "\n",
    "# @markdown We want to find the nearest token to each generated embedding.\n",
    "# We can do this by finding the nearest embedding to each generated embedding\n",
    "# and then finding the index corresponding to that embedding.\n",
    "\n",
    "# First run a test on data we know what the true token output should be\n",
    "with torch.no_grad():\n",
    "    sequence_expanded = data.unsqueeze(2)\n",
    "    matrix_expanded = embedding.weight.unsqueeze(0).unsqueeze(0)\n",
    "    dist = torch.linalg.vector_norm(sequence_expanded - matrix_expanded, dim=3)\n",
    "    print(dist.shape, end=\"\\n\\n\")\n",
    "    tokens = dist.argmin(dim=2)\n",
    "    print(tokens.squeeze().tolist(), end=\"\\n\\n\")\n",
    "    # decode into text\n",
    "    print(tokenizer.decode(tokens.squeeze().tolist()), end=\"\\n\\n\")\n",
    "\n",
    "# If correct this should match\n",
    "print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")\n",
    "\n",
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence_expanded = data_gen[:, -max_new_tokens:, :].unsqueeze(2)\n",
    "    matrix_expanded = embedding.weight.unsqueeze(0).unsqueeze(0)\n",
    "    dist = torch.linalg.vector_norm(sequence_expanded - matrix_expanded, dim=3)\n",
    "    print(dist.shape, end=\"\\n\\n\")\n",
    "    tokens = dist.argmin(dim=2)\n",
    "    print(tokens.squeeze().tolist(), end=\"\\n\\n\")\n",
    "    # decode into text\n",
    "    print(tokenizer.decode(tokens.squeeze().tolist()), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
