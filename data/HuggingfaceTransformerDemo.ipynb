{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from utils import DEVICE, BLOCK_SIZE, NUM_TOKENS, init_random_seeds\n",
    "from CreateSyntheticDataset import tokenize_and_chunk  # works because of nbimporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `tokenizer.encode(text)`:\n",
      "\ttext: Welcome to the ðŸ¤— Tokenizers library.\n",
      "\ttokenized: [90, 104, 111, 102, 114, 112, 104, 35, 119, 114, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 114, 110, 104, 113, 108, 125, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: Welcome to the ðŸ¤— Tokenizers library.</s>\n",
      "\n",
      "Calling `tokenizer(text)`:\n",
      "\tobject.keys(): dict_keys(['input_ids', 'attention_mask'])\n",
      "\ttext: We are very happy to show you the ðŸ¤— Transformers library.\n",
      "\ttokenized: [90, 104, 35, 100, 117, 104, 35, 121, 104, 117, 124, 35, 107, 100, 115, 115, 124, 35, 119, 114, 35, 118, 107, 114, 122, 35, 124, 114, 120, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 117, 100, 113, 118, 105, 114, 117, 112, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: We are very happy to show you the ðŸ¤— Transformers library.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-large\")\n",
    "\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "train: <class 'list'> 1 <class 'str'> 1003854\n",
      "\n",
      "validation: <class 'list'> 1 <class 'str'> 55770\n",
      "\n",
      "test: <class 'list'> 1 <class 'str'> 55770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1963\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_dataset['train']['input_ids']:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 1963\n",
      "\n",
      "text_dataset['train']['input_ids'][0]:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 506\n",
      "\n",
      "text_dataset['train']['input_ids'][0][0]:\n",
      " \ttype: <class 'int'> \n",
      "\tvalue: 73\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Original sequence (text):\n",
      "\tFirst Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the\n",
      "\n",
      "Encoded sequence (tokens):\n",
      "\t [73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 69, 104, 105, 114, 117, 104, 35, 122, 104, 35, 115, 117, 114, 102, 104, 104, 103, 35, 100, 113, 124, 35, 105, 120, 117, 119, 107, 104, 117, 47, 35, 107, 104, 100, 117, 35, 112, 104, 35, 118, 115, 104, 100, 110, 49, 35, 68, 111, 111, 61, 35, 86, 115, 104, 100, 110, 47, 35, 118, 115, 104, 100, 110, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 92, 114, 120, 35, 100, 117, 104, 35, 100, 111, 111, 35, 117, 104, 118, 114, 111, 121, 104, 103, 35, 117, 100, 119, 107, 104, 117, 35, 119, 114, 35, 103, 108, 104, 35, 119, 107, 100, 113, 35, 119, 114, 35, 105, 100, 112, 108, 118, 107, 66, 35, 68, 111, 111, 61, 35, 85, 104, 118, 114, 111, 121, 104, 103, 49, 35, 117, 104, 118, 114, 111, 121, 104, 103, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 73, 108, 117, 118, 119, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 35, 70, 100, 108, 120, 118, 35, 80, 100, 117, 102, 108, 120, 118, 35, 108, 118, 35, 102, 107, 108, 104, 105, 35, 104, 113, 104, 112, 124, 35, 119, 114, 35, 119, 107, 104, 35, 115, 104, 114, 115, 111, 104, 49, 35, 68, 111, 111, 61, 35, 90, 104, 35, 110, 113, 114, 122, 42, 119, 47, 35, 122, 104, 35, 110, 113, 114, 122, 42, 119, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 79, 104, 119, 35, 120, 118, 35, 110, 108, 111, 111, 35, 107, 108, 112, 47, 35, 100, 113, 103, 35, 122, 104, 42, 111, 111, 35, 107, 100, 121, 104, 35, 102, 114, 117, 113, 35, 100, 119, 35, 114, 120, 117, 35, 114, 122, 113, 35, 115, 117, 108, 102, 104, 49, 35, 76, 118, 42, 119, 35, 100, 35, 121, 104, 117, 103, 108, 102, 119, 66, 35, 68, 111, 111, 61, 35, 81, 114, 35, 112, 114, 117, 104, 35, 119, 100, 111, 110, 108, 113, 106, 35, 114, 113, 42, 119, 62, 35, 111, 104, 119, 35, 108, 119, 35, 101, 104, 35, 103, 114, 113, 104, 61, 35, 100, 122, 100, 124, 47, 35, 100, 122, 100, 124, 36, 35, 86, 104, 102, 114, 113, 103, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 82, 113, 104, 35, 122, 114, 117, 103, 47, 35, 106, 114, 114, 103, 35, 102, 108, 119, 108, 125, 104, 113, 118, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 90, 104, 35, 100, 117, 104, 35, 100, 102, 102, 114, 120, 113, 119, 104, 103, 35, 115, 114, 114, 117, 35, 102, 108, 119, 108, 125, 104, 113, 118, 47, 35, 119, 107, 104, 1]\n",
      "\n",
      "Decoded sequence (tokens):\n",
      "\t First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 511]) torch.int64 False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create token datasets\n",
    "\n",
    "train_dataset = [torch.LongTensor(sequence) for sequence in text_dataset[\"train\"][\"input_ids\"]]\n",
    "validation_dataset = [\n",
    "    torch.LongTensor(sequence) for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "test_dataset = [torch.LongTensor(sequence) for sequence in text_dataset[\"test\"][\"input_ids\"]]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Number of attn heads = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a TransformerModel\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Number of attn heads = {nhead}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler, criterion\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        tokens = train_dataset[batch].unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        input = tokens[:, :-1].to(DEVICE)  # ``[batch_size=1, seq_len]``\n",
    "        target = tokens[:, 1:].reshape(-1).to(DEVICE)  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(validation_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            tokens = validation_dataset[batch].unsqueeze(0)\n",
    "            input = tokens[:, :-1].to(DEVICE)\n",
    "            target = tokens[:, 1:].reshape(-1).to(DEVICE)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1 epoch(s)...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 1963 batches | lr 5.00 | ms/batch  8.92 | loss  3.37 | ppl    29.14\n",
      "| epoch   1 |   600/ 1963 batches | lr 5.00 | ms/batch  6.99 | loss  2.64 | ppl    13.99\n",
      "| epoch   1 |   900/ 1963 batches | lr 5.00 | ms/batch  7.05 | loss  2.60 | ppl    13.47\n",
      "| epoch   1 |  1200/ 1963 batches | lr 5.00 | ms/batch  7.32 | loss  2.56 | ppl    12.88\n",
      "| epoch   1 |  1500/ 1963 batches | lr 5.00 | ms/batch 10.70 | loss  2.54 | ppl    12.73\n",
      "| epoch   1 |  1800/ 1963 batches | lr 5.00 | ms/batch  7.38 | loss  2.51 | ppl    12.33\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 15.61s | valid loss  2.62 | valid ppl    13.70\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 1\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            val_ppl = math.exp(val_loss)\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 510]) torch.Size([1, 610])\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "r we wo mel l y. meer wean Yieay t go all f I an  e, o ave'ld aper ak Byo ju AMATCI I fenc t he kee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new text\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=None)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 511, 302]) torch.float32 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create neural datasets\n",
    "# @markdown A synthetic dataset where the neural activity is the embeddings of tokens from tiny Shakespeare.\n",
    "\n",
    "init_random_seeds()  # set random seeds\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding = torch.nn.Embedding(ntokens, emsize, _freeze=True)  # fixed embedding map\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "]\n",
    "validation_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "test_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence)])\n",
    "    for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 \t {35, 36, 39, 41, 42, 47, 48, 49, 54, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# What tokens and their corresponding characters are in the training set\n",
    "real_train_tokens = set()\n",
    "for sequence in text_dataset[\"train\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_train_tokens.update(tokens)\n",
    "print(len(real_train_tokens), \"\\t\", real_train_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_train_tokens)))\n",
    "print(\"\\n\", \"~\" * 333, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Model internal tokens = 256\n",
      "Number of attn heads = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(\n",
    "    input_size=emsize,\n",
    "    hidden_size=d_hid,\n",
    "    version_2=True,\n",
    "    num_tokens=ntokens,\n",
    "    # num_tokens=NUM_TOKENS,\n",
    "    vq_vae=True,\n",
    "    # vq_vae=False,\n",
    ").to(DEVICE)\n",
    "# NOTE: In reality we don't actually know the underlying vocabulary size (i.e. num_tokens) of the embedding table used to generated the neural data.\n",
    "\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Model internal tokens = {model.num_tokens}\")\n",
    "print(f\"Number of attn heads = {model.num_heads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 510, 302]) torch.float32 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 510, 302]) torch.float32 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 510, 256]) torch.float16 False cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's input-output functionality\n",
    "\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(input, mask)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([117, 100, 113, 102, 104])\n",
      "\n",
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([168, 137, 114, 110,  39])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's internal tokenizer works as expected\n",
    "\n",
    "# The code below should only work when we cheat and set the codebook to be exactky the embedding table that was used to generate the neural data.\n",
    "# This is because the codebook is initialized randomly. If the model has not been trained then there is no reason for its internal tokenizer to\n",
    "# correctly invert the ground-truth embedding, which should be unknown to us. Thereforem the goal of our optimization is ultimately to learn the\n",
    "# a codebook that is as close as possible to the ground-truth but unknown embedding map.\n",
    "\n",
    "if embedding.weight.shape == model.codebook.shape:\n",
    "    assert not torch.allclose(embedding.weight, model.codebook.cpu())\n",
    "\n",
    "# Replace model codebook with the embedding map use to generate the dataset\n",
    "tmp = model.codebook  # save for later restoration\n",
    "model.codebook = torch.nn.Parameter(embedding.weight.to(DEVICE))  # let's cheat\n",
    "\n",
    "assert torch.allclose(embedding.weight, model.codebook.cpu())\n",
    "\n",
    "# Get some ground-truth test data\n",
    "token_list = text_dataset[\"test\"][\"input_ids\"][0]\n",
    "token_target = torch.LongTensor(token_list)\n",
    "neural_target = torch.vstack([embedding(t) for t in token_target])\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the codebook is the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should be the same\n",
    "assert torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should be the same!\"\n",
    "\n",
    "# Restore the model codebook to its original random initialization\n",
    "model.codebook = tmp\n",
    "\n",
    "if embedding.weight.shape == model.codebook.shape:\n",
    "    assert not torch.allclose(embedding.weight, model.codebook.cpu())\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the codebook is NOT the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should NOT be the same\n",
    "assert not torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should NOT be the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        data = train_dataset[batch].unsqueeze(0)\n",
    "        mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = data[:, :-1, :].to(DEVICE)\n",
    "        target = data[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target, mask\n",
    "        )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            try:\n",
    "                ppl = math.exp(cur_loss)\n",
    "            except OverflowError:\n",
    "                ppl = float(\"inf\")\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(validation_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            data = validation_dataset[batch].unsqueeze(0)\n",
    "            mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = data[:, :-1, :].to(DEVICE)\n",
    "            target = data[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "codebook trainable? True\n",
      "\n",
      "codebook trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.token_neural_map.unique(dim=0)) - 1, end=\"\\n\\n\")\n",
    "print(\"codebook trainable?\", model.codebook.requires_grad, end=\"\\n\\n\")\n",
    "print(\"codebook trained?\", model.codebook.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (256, 302) (256, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAFLCAYAAAD4cKfRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAn8ElEQVR4nO3deXhU5eH+/3sIZEIgCSQhyBIglh9bkLAE/QRUkH2RAi6gsqqfKrILtYiUC4rFAFoRpaC4gJWyWra2QGUJQbYalgCy6wdNKGENEAISIPN8/+jF/BwTNEMmnJPM+3Vdc8l55sk595lhuT3nzByHMcYIAADAhkpZHQAAAOB2KCoAAMC2KCoAAMC2KCoAAMC2KCoAAMC2KCoAAMC2KCoAAMC2KCoAAMC2KCoAAMC2KCoAitymTZvkcDi0adMmr3924sSJcjgcOnfunO+D/YKBAweqfPnyd327AP5/FBUAAGBbFBUAAGBbFBUAkqTDhw/r6aefVuXKleV0OlWjRg31799fOTk5kqSvv/5a3bt3V8WKFRUUFKTGjRvr008/zXc9nTp1UnBwsCIjIzVo0CBdvnw5322uX79ebdu2VWhoqIKDg9WyZUtt2LAh37np6el67LHHFBoaqrCwMPXt21dnz571mONyuTRt2jTVq1dPTqdTUVFR6t+/v06cOJFnfZ988oni4uIUFBSk8PBw9ezZU4cOHfrF12nr1q2KjIzUo48+qitXrvzifACFQ1EBoL1796p58+basWOHJk2apDVr1igxMVE5OTm6fv26jhw5ohYtWujAgQN69913tWzZMjVo0EADBw7UtGnT3Os5ffq0WrVqpa+//lqzZs3SZ599puzsbA0dOjTPNufPn68OHTooNDRUn376qZYsWaLw8HB17Ngx37LSs2dP1a5dW59//rkmTpyoFStWqGPHjrpx44Z7zksvvaQxY8aoffv2WrVqlV5//XWtXbtWLVq08LjGJTExUc8//7xiY2O1bNkyzZgxQ/v27VNCQoKOHTt229dpyZIlatu2rXr16qWVK1eqXLlyd/qSAygoA8DvtWnTxlSoUMGcOXMm3+efeuop43Q6TVpamsd4586dTXBwsLl48aIxxpgxY8YYh8NhUlNTPea1b9/eSDJJSUnGGGOuXLliwsPDTbdu3Tzm5ebmmri4OHP//fe7xyZMmGAkmZdfftlj7l//+lcjycyfP98YY8yhQ4eMJDN48GCPef/+97+NJPPaa68ZY4y5cOGCKVu2rOnSpYvHvLS0NON0Os0zzzzjHhswYIApV66cMcaYKVOmmICAADN16tR8XyMARYMjKoCfu3r1qpKTk9WrVy9VqlQp3zkbN25U27ZtFR0d7TE+cOBAXb16Vdu3b5ckJSUlKTY2VnFxcR7znnnmGY/lbdu2KTMzUwMGDNDNmzfdD5fLpU6dOiklJSXPaZU+ffp4LPfq1UulS5dWUlKSe9u3Mv3Y/fffr/r167uP0mzfvl0//PBDnnnR0dFq06ZNnqM5xhi9+OKLmjBhghYsWKDf/e53+b5GAIpGaasDALDWhQsXlJubq+rVq992zvnz51WlSpU841WrVnU/f+u/MTExeebdc889HsunT5+WJD3xxBO33WZmZqbHqZWfrqN06dKKiIjw2Lak2+b8/vvvCzRv3bp1HmPXr1/X4sWLFRsbq86dO982L4CiQVEB/Fx4eLgCAgLyveD0loiICGVkZOQZP3nypCQpMjLSPe/UqVN55v107Nb89957T//zP/+T7zYrV66cZx3VqlVzL9+8eVPnz59XRESEe9uSlJGRkad0nTx50iPjrXn57c+tebc4nU4lJSWpY8eOateundauXauKFSvmmxmA73HqB/BzZcuWVatWrbR06dLbfqla27ZttXHjRncxueUvf/mLgoOD3WXjkUce0YEDB7R3716PeQsWLPBYbtmypSpUqKCDBw8qPj4+30dgYKDHz/z1r3/1WF6yZIlu3ryp1q1bS5LatGkj6b8X6f5YSkqKDh06pLZt20qSEhISVLZs2TzzTpw44T7F9VNNmjRRcnKyTpw4odatW+vMmTP5vk4AioDVF8kAsF5qaqopX768uffee82cOXPMxo0bzcKFC83TTz9tsrKyzOHDh01ISIipU6eOmT9/vlm9erXp06ePkWSmTZvmXk9GRoapVKmSqVatmpk7d657XnR0tMfFtMYY89lnn5lSpUqZ3r17m6VLl5rk5GTz+eefm/Hjx5tBgwa55926mLZmzZrmlVdeMV988YWZPn26KV++vImLizM5OTnuuS+88IJxOBxm5MiR5l//+pf54IMPTFRUlImOjjbnzp1zz3vjjTeMJNOvXz+zevVq89lnn5natWubsLAwc/ToUfe8H19Ma4wx3377rYmJiTF169Y16enpvn4bAOSDogLAGGPMwYMHzZNPPmkiIiJMYGCgqVGjhhk4cKC5du2aMcaY/fv3m27dupmwsDATGBho4uLizNy5c/NdT/v27U1QUJAJDw83zz//vFm5cmWeomKMMcnJyaZr164mPDzclClTxlSrVs107drVLF261D3nVlHZtWuX6datmylfvrwJCQkxTz/9tDl9+rTH+nJzc83UqVNNnTp1TJkyZUxkZKTp27dvvqXio48+Mo0aNTKBgYEmLCzMdO/e3Rw4cMBjzk+LijHGnDhxwtSrV8/UqlXLfPvtt968xADugMMYY6w8ogMAAHA7XKMCAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsq1h/hb7L5dLJkycVEhIih8NhdRwAAFAAxhhdvnxZVatWValSP3/MpFgXlZMnT+a5mysAACge0tPTf/aGqFIxLyohISGSpJgPRqlUWafFaQqn9M4QqyMUWu9nNlodwSd+cAX+8qRi4LXIw1ZHKLRvblyxOoJPTD5ZMu66nDmh+P+P4f/3xhGrI/jEE+FfWR2hUK5ku/REizT3v+M/p1gXlVune0qVdSogOMjiNIUT4Cze+SUpqHwZqyP4hMtVMvYjNKT4X4JW/kbx3wdJKlOuZJTf0qWL/99TgSXk76lyJeDPt6QCXbZRMvYUAACUSBQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgWxQVAABgW5YXlVmzZikmJkZBQUFq1qyZvvzyS6sjAQAAm7C0qCxevFgjR47UuHHjtGfPHj300EPq3Lmz0tLSrIwFAABswtKi8vbbb+v555/X//7v/6p+/fp65513FB0drdmzZ1sZCwAA2IRlReX69evatWuXOnTo4DHeoUMHbdu2Ld+fycnJUVZWlscDAACUXJYVlXPnzik3N1eVK1f2GK9cubJOnTqV788kJiYqLCzM/YiOjr4bUQEAgEUsv5jW4XB4LBtj8ozdMnbsWF26dMn9SE9PvxsRAQCARUpbteHIyEgFBATkOXpy5syZPEdZbnE6nXI6nXcjHgAAsAHLjqgEBgaqWbNmWrduncf4unXr1KJFC4tSAQAAO7HsiIokjRo1Sv369VN8fLwSEhI0Z84cpaWladCgQVbGAgAANmFpUendu7fOnz+vSZMmKSMjQw0bNtTq1atVs2ZNK2MBAACbsLSoSNLgwYM1ePBgq2MAAAAbsvxTPwAAALdDUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZFUQEAALZV2uoAvuDcFqIAZ5DVMQqlwjc3rI5QaGtPNbA6gk+8VXup1RF8omPV+62OUGjfvplgdQSfyC2Xa3UEn2ie+K3VEQpt91tNrI7gE6++ucHqCIVyubSrwHM5ogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGyLogIAAGzL0qKyefNmdevWTVWrVpXD4dCKFSusjAMAAGzG0qJy5coVxcXFaebMmVbGAAAANlXayo137txZnTt3tjICAACwMUuLirdycnKUk5PjXs7KyrIwDQAAKGrF6mLaxMREhYWFuR/R0dFWRwIAAEWoWBWVsWPH6tKlS+5Henq61ZEAAEARKlanfpxOp5xOp9UxAADAXVKsjqgAAAD/YukRlezsbH3zzTfu5ePHjys1NVXh4eGqUaOGhckAAIAdWFpUdu7cqUceecS9PGrUKEnSgAEDNG/ePItSAQAAu7C0qLRu3VrGGCsjAAAAG+MaFQAAYFsUFQAAYFsUFQAAYFsUFQAAYFteF5X169ff9rkPPvigUGEAAAB+zOui0rVrV40ePVrXr193j509e1bdunXT2LFjfRoOAAD4N6+LyubNm/X3v/9dzZs314EDB/TPf/5TDRs2VHZ2tvbu3VsUGQEAgJ/yuqg88MAD2rNnjxo1aqRmzZqpZ8+eGj16tDZu3MjdjAEAgE/d0cW0R44cUUpKiqpXr67SpUvr8OHDunr1qq+zAQAAP+d1UZkyZYoSEhLUvn17ff3110pJSXEfYdm+fXtRZAQAAH7K66IyY8YMrVixQu+9956CgoIUGxurr776So899phat25dBBEBAIC/8vpeP/v371dkZKTHWJkyZfTmm2/q0Ucf9VkwAAAAr4+oREZG6uLFi/roo480duxYZWZmSpJ2796t2rVr+zwgAADwX14fUdm3b5/atWunsLAwfffdd/rNb36j8PBwLV++XN9//73+8pe/FEVOAADgh7w+ojJq1CgNHDhQx44dU1BQkHu8c+fO2rx5s0/DAQAA/+Z1UUlJSdGLL76YZ7xatWo6deqUT0IBAABId1BUgoKClJWVlWf8yJEjqlSpkk9CAQAASHdQVLp3765Jkybpxo0bkiSHw6G0tDS9+uqrevzxx30eEAAA+C+vL6Z966231KVLF0VFRemHH35Qq1atdOrUKSUkJGjy5MlFkfEXBV1wKSDQZcm2faXM6BJw2mxChNUJfOLbT0rGkcErTzxgdYRCC/neYXUEn4jpddzqCD7x/Zw6VkcotHOPXrM6gk88/vtXrI5QKLnXr0kaV6C5XheV0NBQbdmyRRs3btTu3bvlcrnUtGlTtWvXzttVAQAA/Cyvi8otbdq0UZs2bXyZBQAAwEOBisq7775b4BUOHz78jsMAAAD8WIGKyvTp0z2Wz549q6tXr6pChQqSpIsXLyo4OFhRUVEUFQAA4DMF+tTP8ePH3Y/JkyercePGOnTokDIzM5WZmalDhw6padOmev3114s6LwAA8CNefzx5/Pjxeu+991S3bl33WN26dTV9+nT9/ve/92k4AADg37wuKhkZGe7vUPmx3NxcnT592iehAAAApDsoKm3bttVvfvMb7dy5U8YYSdLOnTv14osv8hFlAADgU14XlU8++UTVqlXT/fffr6CgIDmdTj3wwAOqUqWKPvroo6LICAAA/JTX36NSqVIlrV69WkePHtXhw4dljFH9+vVVp07x/8ZCAABgL3f8hW916tShnAAAgCLldVHJzc3VvHnztGHDBp05c0Yul+c9djZu3OizcAAAwL95XVRGjBihefPmqWvXrmrYsKEcjpJx0zAAAGA/XheVRYsWacmSJerSpUtR5AEAAHDz+lM/gYGBql27dlFkAQAA8OB1URk9erRmzJjh/g4VAACAouL1qZ8tW7YoKSlJa9asUWxsrMqUKePx/LJly3wWDgAA+Devi0qFChXUs2fPosgCAADgweuiMnfu3KLIAQAAkIfX16gAAADcLQU6otK0aVNt2LBBFStWVJMmTX72u1N2795d4I0nJiZq2bJlOnz4sMqWLasWLVpo6tSpqlu3boHXAQAASq4CFZXu3bvL6XRKknr06OGzjScnJ2vIkCFq3ry5bt68qXHjxqlDhw46ePCgypUr57PtAACA4qlARWXChAn5/rqw1q5d67E8d+5cRUVFadeuXXr44Yd9th0AAFA83fFNCYvCpUuXJEnh4eH5Pp+Tk6OcnBz3clZW1l3JBQAArGGbi2mNMRo1apQefPBBNWzYMN85iYmJCgsLcz+io6PvckoAAHA32aaoDB06VPv27dPChQtvO2fs2LG6dOmS+5Genn4XEwIAgLvNFqd+hg0bplWrVmnz5s2qXr36bec5nU73Rb0AAKDks7SoGGM0bNgwLV++XJs2bVJMTIyVcQAAgM14XVRyc3M1b948bdiwQWfOnJHL5fJ4fuPGjQVe15AhQ7RgwQKtXLlSISEhOnXqlCQpLCxMZcuW9TYaAAAoYbwuKiNGjNC8efPUtWtXNWzY8Ge//O2XzJ49W5LUunVrj/G5c+dq4MCBd7xeAABQMnhdVBYtWqQlS5aoS5cuhd64MabQ6wAAACWX15/6CQwMVO3atYsiCwAAgAevi8ro0aM1Y8YMjoYAAIAi5/Wpny1btigpKUlr1qxRbGysypQp4/H8smXLfBYOAAD4N6+LSoUKFdSzZ8+iyAIAAODB66Iyd+7cosgBAACQxx19hf7Nmze1fv16ffDBB7p8+bIk6eTJk8rOzvZpOAAA4N+8PqLy/fffq1OnTkpLS1NOTo7at2+vkJAQTZs2TdeuXdP7779fFDkBAIAf8vqIyogRIxQfH68LFy54fHtsz549tWHDBp+GAwAA/u2OPvWzdetWBQYGeozXrFlT//nPf3wWDAAAwOsjKi6XS7m5uXnGT5w4oZCQEJ+EAgAAkO6gqLRv317vvPOOe9nhcCg7O1sTJkzwydfqAwAA3OL1qZ/p06frkUceUYMGDXTt2jU988wzOnbsmCIjI7Vw4cKiyAgAAPyU10WlatWqSk1N1aJFi7Rr1y65XC49//zz6tOnj8fFtQAAAIXldVGZP3+++vbtq2effVbPPvusx3OvvPKK3nzzTZ+FAwAA/s3ra1SGDh2qf/zjH3nGX375Zc2fP98noQAAAKQ7KCqLFi1S3759tXnzZvfYsGHDtGTJEiUlJfk0HAAA8G9eF5VOnTrp/fffV48ePbRz504NHjxYy5YtU1JSkurVq1cUGQEAgJ/y+hoVSXrqqad04cIFPfjgg6pUqZKSk5NVu3ZtX2crsHInr6t06Tu6bZFt3MgNsDpCoTV/d6/VEXxi5u96Wx3BJ36oXLz/TEjSzbYXrY7gE2ffudfqCD7x2fS3rI5QaL/97nGrI/jEoYYxVkcoFNe1gs8tUFEZNWpUvuNRUVFq0qSJZs2a5R57++23C751AACAn1GgorJnz558x3/1q18pKyvL/bzD4fBdMgAA4PcKVFS4SBYAAFihUCexT5w4wY0IAQBAkbmjmxJOmjRJYWFhqlmzpmrUqKEKFSro9ddfl8vlKoqMAADAT3n9qZ9x48bp448/1pQpU9SyZUsZY7R161ZNnDhR165d0+TJk4siJwAA8ENeF5VPP/1UH330kX7961+7x+Li4lStWjUNHjyYogIAAHzG61M/mZmZ+X6xW7169ZSZmemTUAAAANIdFJW4uDjNnDkzz/jMmTMVFxfnk1AAAADSHZz6mTZtmrp27ar169crISFBDodD27ZtU3p6ulavXl0UGQEAgJ/y+ohKq1atdPToUfXs2VMXL15UZmamHnvsMR05ckQPPfRQUWQEAAB+yusjKmlpaYqOjs73otm0tDTVqFHDJ8EAAAC8PqISExOjs2fP5hk/f/68YmKK902SAACAvXhdVIwx+d7TJzs7W0FBQT4JBQAAIHlx6ufWHZQdDofGjx+v4OBg93O5ubn697//rcaNG/s8IAAA8F8FLiq37pBsjNH+/fsVGBjofi4wMFBxcXH67W9/6/uEAADAbxW4qNy6g/Kzzz6rGTNmKDQ0tMhCAQAASHfwqZ+5c+cWRQ4AAIA8vL6YFgAA4G6hqAAAANuytKjMnj1bjRo1UmhoqEJDQ5WQkKA1a9ZYGQkAANiIpUWlevXqmjJlinbu3KmdO3eqTZs26t69uw4cOGBlLAAAYBNeX0zrS926dfNYnjx5smbPnq0dO3YoNjbWolQAAMAuLC0qP5abm6ulS5fqypUrSkhIyHdOTk6OcnJy3MtZWVl3Kx4AALCA5RfT7t+/X+XLl5fT6dSgQYO0fPlyNWjQIN+5iYmJCgsLcz+io6PvcloAAHA3WV5U6tatq9TUVO3YsUMvvfSSBgwYoIMHD+Y7d+zYsbp06ZL7kZ6efpfTAgCAu8nyUz+BgYGqXbu2JCk+Pl4pKSmaMWOGPvjggzxznU6nnE7n3Y4IAAAsYvkRlZ8yxnhchwIAAPyXpUdUXnvtNXXu3FnR0dG6fPmyFi1apE2bNmnt2rVWxgIAADZhaVE5ffq0+vXrp4yMDIWFhalRo0Zau3at2rdvb2UsAABgE5YWlY8//tjKzQMAAJuz3TUqAAAAt1BUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbVFUAACAbZW2OoAvHO9ZWqXKFu9dqeYq/p3xHysTrI7gE46+WVZH8Iluv/ra6giFNjJii9URfKLlydFWR/CJ3tNesTpCof3x5U+sjuATYzLvtTpCoeTmOAo8t/j/6wgAAEosigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAtigoAALAt2xSVxMREORwOjRw50uooAADAJmxRVFJSUjRnzhw1atTI6igAAMBGLC8q2dnZ6tOnjz788ENVrFjR6jgAAMBGLC8qQ4YMUdeuXdWuXbtfnJuTk6OsrCyPBwAAKLlKW7nxRYsWaffu3UpJSSnQ/MTERP3hD38o4lQAAMAuLDuikp6erhEjRmj+/PkKCgoq0M+MHTtWly5dcj/S09OLOCUAALCSZUdUdu3apTNnzqhZs2busdzcXG3evFkzZ85UTk6OAgICPH7G6XTK6XTe7agAAMAilhWVtm3bav/+/R5jzz77rOrVq6cxY8bkKSkAAMD/WFZUQkJC1LBhQ4+xcuXKKSIiIs84AADwT5Z/6gcAAOB2LP3Uz09t2rTJ6ggAAMBGOKICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsi6ICAABsq7TVAQrDGCNJcl27ZnGSwrt5JcfqCIWWWwLeB0lyXC0Z+5GTfcPqCIV2OdBldQSfcP1QMn5P5V4PsDpCoV29nGt1BJ/IzSnev6du5b/17/jPcZiCzLKpEydOKDo62uoYAADgDqSnp6t69eo/O6dYFxWXy6WTJ08qJCREDoejSLaRlZWl6OhopaenKzQ0tEi2gYLhvbAP3gt74f2wD96LgjHG6PLly6patapKlfr5q1CK9amfUqVK/WIT85XQ0FB+09kE74V98F7YC++HffBe/LKwsLACzeNiWgAAYFsUFQAAYFsUlV/gdDo1YcIEOZ1Oq6P4Pd4L++C9sBfeD/vgvfC9Yn0xLQAAKNk4ogIAAGyLogIAAGyLogIAAGyLogIAAGyLovIzZs2apZiYGAUFBalZs2b68ssvrY7klxITE9W8eXOFhIQoKipKPXr00JEjR6yOBf33vXE4HBo5cqTVUfzSf/7zH/Xt21cREREKDg5W48aNtWvXLqtj+Z2bN2/q97//vWJiYlS2bFnde++9mjRpklyuknGvKqtRVG5j8eLFGjlypMaNG6c9e/booYceUufOnZWWlmZ1NL+TnJysIUOGaMeOHVq3bp1u3rypDh066MqVK1ZH82spKSmaM2eOGjVqZHUUv3ThwgW1bNlSZcqU0Zo1a3Tw4EH96U9/UoUKFayO5nemTp2q999/XzNnztShQ4c0bdo0vfnmm3rvvfesjlYi8PHk23jggQfUtGlTzZ492z1Wv3599ejRQ4mJiRYmw9mzZxUVFaXk5GQ9/PDDVsfxS9nZ2WratKlmzZqlP/7xj2rcuLHeeecdq2P5lVdffVVbt27lSK8NPProo6pcubI+/vhj99jjjz+u4OBgffbZZxYmKxk4opKP69eva9euXerQoYPHeIcOHbRt2zaLUuGWS5cuSZLCw8MtTuK/hgwZoq5du6pdu3ZWR/Fbq1atUnx8vJ588klFRUWpSZMm+vDDD62O5ZcefPBBbdiwQUePHpUk7d27V1u2bFGXLl0sTlYyFOubEhaVc+fOKTc3V5UrV/YYr1y5sk6dOmVRKkj/vePmqFGj9OCDD6phw4ZWx/FLixYt0u7du5WSkmJ1FL/2f//3f5o9e7ZGjRql1157TV999ZWGDx8up9Op/v37Wx3Pr4wZM0aXLl1SvXr1FBAQoNzcXE2ePFlPP/201dFKBIrKz3A4HB7Lxpg8Y7i7hg4dqn379mnLli1WR/FL6enpGjFihL744gsFBQVZHcevuVwuxcfH64033pAkNWnSRAcOHNDs2bMpKnfZ4sWLNX/+fC1YsECxsbFKTU3VyJEjVbVqVQ0YMMDqeMUeRSUfkZGRCggIyHP05MyZM3mOsuDuGTZsmFatWqXNmzerevXqVsfxS7t27dKZM2fUrFkz91hubq42b96smTNnKicnRwEBARYm9B9VqlRRgwYNPMbq16+vv/3tbxYl8l+vvPKKXn31VT311FOSpPvuu0/ff/+9EhMTKSo+wDUq+QgMDFSzZs20bt06j/F169apRYsWFqXyX8YYDR06VMuWLdPGjRsVExNjdSS/1bZtW+3fv1+pqanuR3x8vPr06aPU1FRKyl3UsmXLPB/TP3r0qGrWrGlRIv919epVlSrl+c9pQEAAH0/2EY6o3MaoUaPUr18/xcfHKyEhQXPmzFFaWpoGDRpkdTS/M2TIEC1YsEArV65USEiI+0hXWFiYypYta3E6/xISEpLn2qBy5copIiKCa4buspdfflktWrTQG2+8oV69eumrr77SnDlzNGfOHKuj+Z1u3bpp8uTJqlGjhmJjY7Vnzx69/fbbeu6556yOVjIY3Naf//xnU7NmTRMYGGiaNm1qkpOTrY7klyTl+5g7d67V0WCMadWqlRkxYoTVMfzS3//+d9OwYUPjdDpNvXr1zJw5c6yO5JeysrLMiBEjTI0aNUxQUJC59957zbhx40xOTo7V0UoEvkcFAADYFteoAAAA26KoAAAA26KoAAAA26KoAAAA26KoAAAA26KoAAAA26KoAAAA26KoAAAA26KoAMVc69atNXLkSKtjeGXgwIHq0aOHe7m47IPD4dCKFSusjgH4Fe71AxRzy5YtU5kyZe76didOnKgVK1YoNTW10Ouyah+8lZGRoYoVK1odA/ArFBWgmAsPD7c6QqEVl3245557rI4A+B1O/QDF3E9Pm9SqVUtvvPGGnnvuOYWEhKhGjRoed9T97rvv5HA4tGjRIrVo0UJBQUGKjY3Vpk2b3HPmzZunChUqeGxnxYoVcjgc7uf/8Ic/aO/evXI4HHI4HJo3b16++XJzczVq1ChVqFBBERER+t3vfqef3mIsv3344x//qP79+6t8+fKqWbOmVq5cqbNnz6p79+4qX7687rvvPu3cudNjPdu2bdPDDz+ssmXLKjo6WsOHD9eVK1cK/Npcv35dQ4cOVZUqVRQUFKRatWopMTHR/fxPT/3s379fbdq0UdmyZRUREaEXXnhB2dnZ7udvneJ66623VKVKFUVERGjIkCG6ceNGvq8VgLwoKkAJ9Kc//Unx8fHas2ePBg8erJdeekmHDx/2mPPKK69o9OjR2rNnj1q0aKFf//rXOn/+fIHW37t3b40ePVqxsbHKyMhQRkaGevfufdssn3zyiT7++GNt2bJFmZmZWr58+S9uY/r06WrZsqX27Nmjrl27ql+/furfv7/69u2r3bt3q3bt2urfv7+79Ozfv18dO3bUY489pn379mnx4sXasmWLhg4dWuDX5t1339WqVau0ZMkSHTlyRPPnz1etWrXyzXf16lV16tRJFStWVEpKipYuXar169fn2V5SUpK+/fZbJSUl6dNPP9W8efNuW+oA5MPamzcDKKxWrVqZESNGuJdr1qxp+vbt6152uVwmKirKzJ492xhjzPHjx40kM2XKFPecGzdumOrVq5upU6caY4yZO3euCQsL89jO8uXLzY//ypgwYYKJi4v7xXxVqlTJd1vdu3cv8D5kZGQYSWb8+PHuse3btxtJJiMjwxhjTL9+/cwLL7zgse0vv/zSlCpVyvzwww8Fem2GDRtm2rRpY1wuV777IsksX77cGGPMnDlzTMWKFU12drb7+X/+85+mVKlS5tSpU8YYYwYMGGBq1qxpbt686Z7z5JNPmt69e9/+BQPggSMqQAnUqFEj968dDofuuecenTlzxmNOQkKC+9elS5dWfHy8Dh065NMcly5dUkZGRr7b+iU/3ofKlStLku677748Y7f2a9euXZo3b57Kly/vfnTs2FEul0vHjx/Pd70/fW0GDhyo1NRU1a1bV8OHD9cXX3xx23yHDh1SXFycypUr5x5r2bKlXC6Xjhw54h6LjY1VQECAe7lKlSp53gsAt8fFtEAJ9NNP0DgcDrlcrl/8uVvXoJQqVSrPdSR3+7qKH+/DrVz5jd3aL5fLpRdffFHDhw/Ps64aNWrku95b67m1jqZNm+r48eNas2aN1q9fr169eqldu3b6/PPP86zTGOPO8FM/Hr/T9wLAf3FEBfBTO3bscP/65s2b2rVrl+rVqydJqlSpki5fvuxxIepPP4YcGBio3Nzcn91GWFiYqlSpku+2fK1p06Y6cOCAateunecRGBhY4PWEhoaqd+/e+vDDD7V48WL97W9/U2ZmZp55DRo0UGpqqsdrtHXrVpUqVUp16tTxyT4BoKgAfuvPf/6zli9frsOHD2vIkCG6cOGCnnvuOUnSAw88oODgYL322mv65ptvtGDBgjwXgNaqVUvHjx9Xamqqzp07p5ycnHy3M2LECE2ZMsW9rcGDB+vixYs+358xY8Zo+/btGjJkiFJTU3Xs2DGtWrVKw4YNK/A6pk+frkWLFunw4cM6evSoli5dqnvuuSfPJ6AkqU+fPgoKCtKAAQP09ddfKykpScOGDVO/fv3cp6UAFB5FBfBTU6ZM0dSpUxUXF6cvv/xSK1euVGRkpKT/fq/J/PnztXr1at13331auHChJk6c6PHzjz/+uDp16qRHHnlElSpV0sKFC/PdzujRo9W/f38NHDhQCQkJCgkJUc+ePX2+P40aNVJycrKOHTumhx56SE2aNNH48eNVpUqVAq+jfPnymjp1quLj49W8eXN99913Wr16tUqVyvtXZXBwsP71r38pMzNTzZs31xNPPKG2bdtq5syZvtwtwO85zE9PRAMo0b777jvFxMRoz549aty4sdVxAOBncUQFAADYFkUFAADYFqd+AACAbXFEBQAA2BZFBQAA2BZFBQAA2BZFBQAA2BZFBQAA2BZFBQAA2BZFBQAA2BZFBQAA2Nb/A+8lZ/lHZ/mLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.codebook.detach().cpu().numpy()\n",
    "C = model.token_neural_map.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape, C.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"codebook\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(C @ C.T)\n",
    "plt.imshow(C.T @ C)\n",
    "plt.imshow(C[:5, :10])\n",
    "plt.title(\"token_neural_map\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 1963 batches | lr 5.00 | ms/batch  6.94 | loss 1247.69 | ppl      inf\n",
      "| epoch   1 |   600/ 1963 batches | lr 5.00 | ms/batch  6.74 | loss 1025.96 | ppl      inf\n",
      "| epoch   1 |   900/ 1963 batches | lr 5.00 | ms/batch  6.78 | loss 846.06 | ppl      inf\n",
      "| epoch   1 |  1200/ 1963 batches | lr 5.00 | ms/batch  6.92 | loss 726.87 | ppl      inf\n",
      "| epoch   1 |  1500/ 1963 batches | lr 5.00 | ms/batch  7.31 | loss 660.71 | ppl 87525300432314803497263009325319426359245576021308247733287222909518702982228788091976807706099758032070736151583273790587339670751478009583148386357526178674841459247786209371925998255357550474229023275723721461524225580886747938344909520043854578281508586604917910201958872067371696128.00\n",
      "| epoch   1 |  1800/ 1963 batches | lr 5.00 | ms/batch  7.16 | loss 622.02 | ppl 1380365019441081044422803490314499935812813417282126558841074018277264982584974596543003202449454877211062024935527635262256478618431138344588208470926605106528495219361876358103647939903782630780543144758510169425034831385675602875805884735002974384556101200735539036160.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 14.07s | valid loss 599.64 | valid ppl 262109227875177688766375381680250354246601423208124401110710220231654133269632344535226937587912912741571010425523448791045902851738259285282135221218853511004437553206736813082541931852003905658270585564147362279010299231607581691888636240938855166258832211968.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   2 |   300/ 1963 batches | lr 4.95 | ms/batch  7.75 | loss 598.75 | ppl 107584142439352171073664575585652596084764354812142290352625803534000995912960584298943411118265090974776854492490829152023357162438586956670413290560830046501321345637324500197731883871529428982467536431746721745450733356641719285869499210594358477028899946496.00\n",
      "| epoch   2 |   600/ 1963 batches | lr 4.95 | ms/batch 10.56 | loss 587.74 | ppl 1780065358861236949901618186376893415208041631044003430465560244611072586951144910694945023002361305169563665488901243902810825076649866631628713109502350633007061653176023398808688570936810542975981804321407963165712992360063091747836572882816208121888768.00\n",
      "| epoch   2 |   900/ 1963 batches | lr 4.95 | ms/batch  9.24 | loss 583.19 | ppl 18834784693777963366245673196161256595137260318298924392495258303196733831915662962968931685085540490791986024515590224558682510396280285463624467059149909961571755775077728098888680478088329358053321511155258619879788378460272951210058295670860945555456.00\n",
      "| epoch   2 |  1200/ 1963 batches | lr 4.95 | ms/batch  7.75 | loss 586.26 | ppl 405426096790852721141455040206372892151342620486647330042635853236956113113569505577083142501123172645794560966295954906650170238118907101513907190278031670827829133216980923195563059392556999799271474882364461835595251681678082990590013811655304573616128.00\n",
      "| epoch   2 |  1500/ 1963 batches | lr 4.95 | ms/batch  7.06 | loss 584.90 | ppl 104666239663505114451258426920341319033474508540435541895840251736959700923784163841026919643761499399490845507692212076719665989239118990581386919795062223552218610152833496284895868392452910638370825976108496125899027914977380645416072753134600902934528.00\n",
      "| epoch   2 |  1800/ 1963 batches | lr 4.95 | ms/batch  7.36 | loss 585.25 | ppl 147464203099437215198394906954601974288273960726426811091402391289986503165174390207901063867365435558598349354581738844449107246220737885816703288714822825343655187701411617338556344081278586145271067045049009719361599089848863947426244344927540746387456.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 16.42s | valid loss 591.41 | valid ppl 70459726581797122086272567810688862459633030668338978395004575523941590346696492763137794451230967390206529605392186042349092504359419571720507575899251023986619038434529304048870154148148632527039597933182448478478678882921345108328408833568342092067897344.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   3 |   300/ 1963 batches | lr 4.90 | ms/batch  6.99 | loss 585.26 | ppl 149074571636584023169218347693691726245373568729406068578482986759884343934212622474587352834277919357989958619884667824073502899826483876995779667496968359168316254945604801605618384166280716503208104876519537354972189612389242739582188021404204129058816.00\n",
      "| epoch   3 |   600/ 1963 batches | lr 4.90 | ms/batch  6.97 | loss 583.35 | ppl 22149663678716605893921671930198257819482778439244199492447154241818138768187891425693710402378903051913815404170743145624244329795079477820687339923848074124544674440519900833053510752581124609940082866795660478924325069106431584433914014909671615234048.00\n",
      "| epoch   3 |   900/ 1963 batches | lr 4.90 | ms/batch  7.07 | loss 586.95 | ppl 808049285147614731380726608224608144030215762969403583970639374856850387813531092882418101793607092885865223483569102079788255388066682915900361471148125370181151488686372227772288826973378453602967805067592318292746161607627760717866416134860424611889152.00\n",
      "| epoch   3 |  1200/ 1963 batches | lr 4.90 | ms/batch  7.22 | loss 600.98 | ppl 1003988235678672561834288741429798730046336016477066888397167641277639486770592463066149925984078898402154220042994799538217897517429135251246971250700751175928010609499780682304769626119158004380663067116739392178260546626551353296068240509026393352813695467520.00\n",
      "| epoch   3 |  1500/ 1963 batches | lr 4.90 | ms/batch  7.67 | loss 600.09 | ppl 414800041829369770300340499875071842771234368805821969462786280188194632847269297911547369420922682714613626163051024696228596096779067661888798598853488038167558793162622609592718695385576382945818478863532474322703853549680933819279204943572402672069125341184.00\n",
      "| epoch   3 |  1800/ 1963 batches | lr 4.90 | ms/batch  7.18 | loss 600.62 | ppl 699327221993930013022976042746165001738119059812661489500558178138740758429666240405629597608669652217710166633952736018188377785770085619872719500177107564737513446611208183821694481553229939205504060337888284222552693068264932513463471807747184848076846137344.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 14.42s | valid loss 582.27 | valid ppl 7490299107374034725351912475384513680049488615492449654425159914847779831557100564301073456148514728458313486377769023997305630506236988221877953498180147300072544666157847320279181959134127648304285510583720521720717842987213826553524199633482432905216.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   4 |   300/ 1963 batches | lr 4.85 | ms/batch  7.08 | loss 602.54 | ppl 4782837425238621979318675062218559003276806788089235451328682288428014579060492378259591310987487630795204798279345899387275115674597857969666028888875561537951832140475821125232864924328622217379480693381928960712957690580114292023791660755699174063130468679680.00\n",
      "| epoch   4 |   600/ 1963 batches | lr 4.85 | ms/batch  6.98 | loss 601.35 | ppl 1458417712155151085047693241715711484175420068181872798914131979110356289615400107480700390840217763802417319294131726294765350939722987424942572064762659705090020759795284418726433707825405632406771134701255815195123485140213112271758463410442117866699760861184.00\n",
      "| epoch   4 |   900/ 1963 batches | lr 4.85 | ms/batch  7.01 | loss 597.11 | ppl 20909487220269681746774860206728346315744526572165662187081371410726588939625958187542302079778849077964949271306721305438643724210457875926485626525863943548753403808169348149449751015875406601855119728243758145966585261124967419549970803365252946784757481472.00\n",
      "| epoch   4 |  1200/ 1963 batches | lr 4.85 | ms/batch  7.04 | loss 598.66 | ppl 98618663211947141868497173174415778518306614920421628210376690477522850792498199623408950591456687840094704869211237583727930973787651457311601564924101470138291595125373840054760986828848229955443728052144354429180585474385501352786643987309509428682023763968.00\n",
      "| epoch   4 |  1500/ 1963 batches | lr 4.85 | ms/batch  7.07 | loss 596.25 | ppl 8882168817565829594832917841522551381778745548079642703556946098371560498912098523040917029389146347803873733106888394177034059200112364321840569520973390558011765412690797636483414812218099720413022009864537539406486328013595423243872546249547382943215779840.00\n",
      "| epoch   4 |  1800/ 1963 batches | lr 4.85 | ms/batch  8.12 | loss 597.37 | ppl 27082993719834541833746179605937763668038034425009245586972997973890328263740495095707672868288050341525479158150732447873427989521938755484709220246723691113349212400302616159425735050008567127329155066611123743566293401724662583880315797496421298836319764480.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 14.83s | valid loss 594.83 | valid ppl 2150558048589002450291572070782254288974073578696638019437300804519739018316288648807752298861040482929373362686180037175411162381919314074037438586389813028119939816760106269749238660265383579842339940692984716403901303385831834087432149084350713446424117248.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   300/ 1963 batches | lr 4.80 | ms/batch  7.99 | loss 601.43 | ppl 1573116803148232471036576207432626820544323871146509199477685319015893446655597883902735466891919012753120503847784636140027717385901844538269388340441344692008884992544436822221618540604924065204207820769960020790585769810719810103670518142899767020733054582784.00\n",
      "| epoch   5 |   600/ 1963 batches | lr 4.80 | ms/batch  8.69 | loss 598.31 | ppl 69818299499147650076278533603309102247298263121492181134868153104327697188185313637382489115023069067124382613555148164270977237267021423661195306937605813083612937263956366482437013424190319947157956596171436672525821807113726624470486448871261908764855369728.00\n",
      "| epoch   5 |   900/ 1963 batches | lr 4.80 | ms/batch 11.48 | loss 602.25 | ppl 3578994833845418666709943173568561159410052378554745655012480861997459660897022494010726796977883987601237412600398641793217228221395008384480178148456139726858795507956257379819513091501885111007118558117872044760680138936322262811727787976067951492799286738944.00\n",
      "| epoch   5 |  1200/ 1963 batches | lr 4.80 | ms/batch  9.88 | loss 598.09 | ppl 55594894805859964818129635127125722510688329368081209266607853963560542944054607858212428973937699917563359726395178989489361351045599036474754046037964420871573902002453382447823264620261136815607283505763121902268206221315534072107310307065703204707178119168.00\n",
      "| epoch   5 |  1500/ 1963 batches | lr 4.80 | ms/batch  6.74 | loss 597.21 | ppl 23121127575934138330869106735512087692554335356545734809510091556731760695925401743349736770272504053315058381220361814216171199133821102129034083689356972556349467657956723316142476594363366741743479352339956904742778170230569874601071391379363271578098860032.00\n",
      "| epoch   5 |  1800/ 1963 batches | lr 4.80 | ms/batch  6.74 | loss 595.03 | ppl 2631636626416235063073207144252277396543844263613530377267614920004724100611094307148661050008244064645657845291016000818696547155059674742873800668891917055092617600456766196201412059059845515674711291398909037371956937788599124916464641903448211084023955456.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 16.90s | valid loss 588.40 | valid ppl 3463442741987691494839046055364317455240765070757370313718393711588830131053453515916215132873350988522996687685894887396693310941182510878617194980199987168364702686779891659505609752089601789872366479196690071986293312577661702207569512870634378695278592.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   300/ 1963 batches | lr 4.75 | ms/batch  7.40 | loss 596.37 | ppl 10051649624178000203301786177703407479919563125558942387843405342182160378865002470324819573473472242522942049233606500292237367575426889016418214879963065650020120157897036450212210351397424888114952013374105615189340966533147600027599288315941046517571256320.00\n",
      "| epoch   6 |   600/ 1963 batches | lr 4.75 | ms/batch  7.98 | loss 596.24 | ppl 8758950018241671859818900120419139451963424394360539212041952777305725446585160156607504176289010391681343068582327850787151612300255060042449081665869504921159548882237635319558778079165329539168766029457975518353790142354283092913048745076283723146583867392.00\n",
      "| epoch   6 |   900/ 1963 batches | lr 4.75 | ms/batch  7.62 | loss 592.02 | ppl 129230179360197794238008161047131666936001224066866839891691627693917859325415950049842166161927447828243078766741586046809729873649959116653072187452398450740496754148721528028905918515036364629604728404265243421085797548963445066640085626768570345330835456.00\n",
      "| epoch   6 |  1200/ 1963 batches | lr 4.75 | ms/batch  8.07 | loss 591.37 | ppl 67599800924856366786310033114159771644613465500297357434371313267840248822836674590417466680276676981763733760040496858002122358915922404645023609974111537518262450394034380933390482643507962316834133103440831696512065721166299797124128768983937276918628352.00\n",
      "| epoch   6 |  1500/ 1963 batches | lr 4.75 | ms/batch  8.18 | loss 592.60 | ppl 230820444795979828914888277278704196376757391425371929788545955742652834824278840485728612332575247051314230212058934109810260019926092790157684312039925904533953336587940502741847006700072128851103520743755668225546513971557014233928738304115644043815288832.00\n",
      "| epoch   6 |  1800/ 1963 batches | lr 4.75 | ms/batch  9.01 | loss 590.54 | ppl 29267454533683243715018336772784230345687545896925198580533702044617435647143248462645083329102327264254983004220235640402047935640848916191935317607702606676307431830853825486346002466922306207434476679908528467005806029784389801354692789097824518144000000.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 16.36s | valid loss 592.15 | valid ppl 146326498527220500540560167566434271044201167774018431676846874598162604374316043406385723914553553773176386267662417984604056118808626623271836902911684567965989707845704458889594958286620383165486928017773740068723996932397442707861327946511299021878853632.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   300/ 1963 batches | lr 4.71 | ms/batch  9.03 | loss 592.91 | ppl 315528612088008329909900897373304727144586810393774266722190062078233656374083816622356984580339145343500710581678695155861931604132577532591274202946303044283553126139072130017540929002755696006165152742442142166706094985681091105788586242884692751109062656.00\n",
      "| epoch   7 |   600/ 1963 batches | lr 4.71 | ms/batch  8.98 | loss 589.92 | ppl 15838059456967892273634659966289456954087980259126220571997104867993876322240840349227641804693753287636273275232638203550619770380462632782081980038162127849244213077099979849308597075712087924921509391832631348973622528951757848457394619936506037344927744.00\n",
      "| epoch   7 |   900/ 1963 batches | lr 4.71 | ms/batch  9.00 | loss 589.03 | ppl 6484359211487854524122766707707445354889243506398915953411637738527602598049497244486441587063635522698548224635749628228554725681698825411333712173909857790941384009997891680011452141232719729358193472464253333623488327276482724597919910494554161344937984.00\n",
      "| epoch   7 |  1200/ 1963 batches | lr 4.71 | ms/batch  9.00 | loss 588.38 | ppl 3404870843804129728541970700185631288870575315760674288653370067057985598257763017424220276576552250049821662557626998468724154586889962554700346133568092237898721889395407844040263875630332915273051894233202983106907887168038223015761984257556208393650176.00\n",
      "| epoch   7 |  1500/ 1963 batches | lr 4.71 | ms/batch  9.03 | loss 590.21 | ppl 21206405458989027557875826403572923253242261483312708761624690004525030766295186558127328580586463971741428968315970524760039588681414276716441103402375709222348007510398013783838565763787373797389248401419923927569489614221929560644540190164654818617982976.00\n",
      "| epoch   7 |  1800/ 1963 batches | lr 4.71 | ms/batch  8.98 | loss 593.06 | ppl 364462313352460708534617719514969669781774191068974710577432315933295097133322584359690759913309911868293347912629009740820571668436567743448450738795727218766318671455912755684011953734297773303154423605571348995209066948132643778596813388340737792949616640.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 18.22s | valid loss 592.31 | valid ppl 173238888050834478424329426375255950539444180048676793564141375075725461112359586003779879484294667162004216160775251745227253778162191187226974569428604653818057736593712123356964671928859499689289357807972980512567153239900587034054886792874632303226126336.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   300/ 1963 batches | lr 4.66 | ms/batch  9.10 | loss 598.58 | ppl 91473800626800003931074747333483939692993339770086844923299889295554349742284759367227775743875032718216276739987064138791251871091065367597955801641545277878632515457812244004452669899880339502338824694885060142857685277029799237381295057131066455744281837568.00\n",
      "| epoch   8 |   600/ 1963 batches | lr 4.66 | ms/batch  7.59 | loss 598.48 | ppl 82461598315520024863106607098689165574408440354329597635932848438068055278704939870952286912310864262652959977955451895616994468259957696974706944166062333200894329707927198116975847560490863091623980674574153967466375316580679222328490708057048698448538238976.00\n",
      "| epoch   8 |   900/ 1963 batches | lr 4.66 | ms/batch  6.66 | loss 597.12 | ppl 21255185698860264109732051944611303059617053442947923891937129520715199216997560663022507936520008716537708506455811480268783476351522818182903948982448895560472612121711984338251901782681828166471191335403515556440369360831556278223642476181415003016090615808.00\n",
      "| epoch   8 |  1200/ 1963 batches | lr 4.66 | ms/batch  6.71 | loss 594.74 | ppl 1967373829608337547693807713179885295537964192039876230757174623312796045411231442899863966355561137152774559380182527133096318575143540203138638223283612355565156609674854885952727101937678832680479020689007249778680238416366146641713629112221981501844094976.00\n",
      "| epoch   8 |  1500/ 1963 batches | lr 4.66 | ms/batch  6.75 | loss 594.61 | ppl 1723505499569769749045179737377839492093248280255984195913718281278940384980968664168467229461157626967945432339881296991160579855059738225496371630810537798210862264137667879823858310147262476618745196675471361156008786575179189789706928829549513954132230144.00\n",
      "| epoch   8 |  1800/ 1963 batches | lr 4.66 | ms/batch  6.83 | loss 591.75 | ppl 98535527845771618047728007414222089558555526121210631381227572400685238905613494000735369080231029293564625668087144948156659174446608323339094646843784574873518164109569923417487899172734238805264308245549293187793392583727559557236232169169473395639713792.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 14.57s | valid loss 581.94 | valid ppl 5430372724010570369411957336689377944972273292274524176845804085681041766955175488289480957805091299466234425099603820577559802899523105579379367583103367141599711851509749402453452944986773983739102771662035177237516570150140722598488598245987909107712.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   9 |   300/ 1963 batches | lr 4.61 | ms/batch  7.75 | loss 593.54 | ppl 590646409384254810977961690065079448187046803216836960275248613576640980417827352930479104076787919642265232810970508079287394155004856332239160183636846493481458434322875289701242576596301962785111606851061439260507834514601084861515376542237111514136838144.00\n",
      "| epoch   9 |   600/ 1963 batches | lr 4.61 | ms/batch  8.63 | loss 592.06 | ppl 135052137239930938876801558899920724559843640892352979675849167087050652860003325657189154335737652255544161803699105306922004064997743670297588939374992381137269499726171508887495356543396990127493747757126986236548774909428144657942973348350173251205332992.00\n",
      "| epoch   9 |   900/ 1963 batches | lr 4.61 | ms/batch  8.86 | loss 590.58 | ppl 30484697299257220899714873618716329382058210998176213287428119477221206946979616816268854060495717510266463487475701670481878631266714446261093677886262294254102783958177385444009436104899711819411642479977301734406095356076925213895933151134670725715066880.00\n",
      "| epoch   9 |  1200/ 1963 batches | lr 4.61 | ms/batch  8.93 | loss 585.14 | ppl 133326275416420432188723424039054547586032109494282563090606620373114906341592810508804622411116457959296447325027495739299895588019940873925574395479437215831151683527862601017253485261295920004286652814666605362677908088613926450984991130399175033749504.00\n",
      "| epoch   9 |  1500/ 1963 batches | lr 4.61 | ms/batch  9.30 | loss 573.03 | ppl 727659720171799519575768659916935303221453846046839385437268363284293348918669223645053828650913473983736504795263366755646518669262271757962558937306055389691926936261440962136188519457096519312584672687505106796439419997413491960086549076880916480.00\n",
      "| epoch   9 |  1800/ 1963 batches | lr 4.61 | ms/batch  8.98 | loss 571.38 | ppl 140799569633165137532007392290349440665663410097525167863726035226214516717753568664066073315253203169115174794419863958031590657900492781564478010016158117733207826016994389210742499759467024131308511957719394974608480249642435256216528044228083712.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 17.62s | valid loss 572.19 | valid ppl 314789693656168460534949765140450097613849722707015794330759164149632427052050307444137544233266212148310759613346260403786459094798844531821698077382629714919103219495752097624640607860346110881470328990287576886020072137637937133616143786626252800.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  10 |   300/ 1963 batches | lr 4.57 | ms/batch  8.78 | loss 574.41 | ppl 2916420625548488688180564471301505604656581295081434995606420152757247113872789172045419155577124761961739806885154377977276938838661491056664101104129723167563226471261821766456166136897713289383168939527170120452092889320473846230068276584781971456.00\n",
      "| epoch  10 |   600/ 1963 batches | lr 4.57 | ms/batch  6.97 | loss 573.15 | ppl 825595954161785583287234300617443328742397794324793223107092650654081422130561987877383761276888137037861456380007013675098797588020118493676657134117620918008696471537105060954588775361795828915686049385547737309102899725894114868460983440992370688.00\n",
      "| epoch  10 |   900/ 1963 batches | lr 4.57 | ms/batch  8.82 | loss 572.76 | ppl 556115778120615742861377794196939916061070939636754810293756779905218040840168477730549059353361029652076799449813360971717105437917158802713818076066301011361861520340403826990428350568674135734579012934537261152866907467867883905937376260745330688.00\n",
      "| epoch  10 |  1200/ 1963 batches | lr 4.57 | ms/batch  9.03 | loss 572.61 | ppl 482014397442101997231844410540247017811218437860595639571009941002932778000017404239645887026782048983647016583718136176148602677168829029152699447253141531272219382934420250831144440845174569472281930150731173057100381708978305129985454744564400128.00\n",
      "| epoch  10 |  1500/ 1963 batches | lr 4.57 | ms/batch 10.61 | loss 572.19 | ppl 314263330728338185611582808969805738804253477909959808079151839647022979972603755079859694264990071551367404968171202089217194341469439826075986041454862146692401633366441539246082390940389965103841450194586393066917700344932443997015975895171596288.00\n",
      "| epoch  10 |  1800/ 1963 batches | lr 4.57 | ms/batch  9.25 | loss 571.76 | ppl 204411274946787843575751794575315909517338903778916417708840941802031092465533005712550547891831537218629875979956996424766813983267461206874712303853710925958570686918063363794336863135991995918690440961851253180806484933470170752607423559530184704.00\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 17.90s | valid loss 572.17 | valid ppl 307735994647496536879880098113111859156487421008029196174907998899088375331167038455777439838575199538875804066906549582658147866325301592903238927363853753241926299043286763593300102575559448560000718836858985357457758675293266084709753031955054592.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 10\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            try:\n",
    "                val_ppl = math.exp(val_loss)\n",
    "            except OverflowError:\n",
    "                val_ppl = float(\"inf\")\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "\n",
      "codebook trainable? True\n",
      "\n",
      "codebook trained? True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.token_neural_map.unique(dim=0)) - 1, end=\"\\n\\n\")\n",
    "print(\"codebook trainable?\", model.codebook.requires_grad, end=\"\\n\\n\")\n",
    "print(\"codebook trained?\", model.codebook.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (256, 302) (256, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.codebook.detach().cpu().numpy()\n",
    "C = model.token_neural_map.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape, C.shape)\n",
    "\n",
    "plt.imshow(A.T @ A)  # (input_size, input_size)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B.T @ B)  # (input_size, input_size)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"codebook\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(C.T @ C)  # (input_size, input_size)\n",
    "plt.imshow(C[:5, :10])\n",
    "plt.title(\"token_neural_map\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 302]) torch.Size([1, 510, 302]) torch.Size([1, 100, 302]) torch.Size([256, 302])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new data\n",
    "\n",
    "data = test_dataset[0][:-1, :].unsqueeze(0).to(DEVICE)\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0).to(DEVICE)\n",
    "max_new_tokens = 100\n",
    "data_gen = model.generate(data, mask, max_new_tokens, autoregressive=True, top_k=None)\n",
    "print(mask.shape, data.shape, data_gen.shape, embedding.weight.shape, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120, 1]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown We want to tokenize the neural data.\n",
    "# An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# First run a test on data we know what the true token output should be.\n",
    "# This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "with torch.no_grad():\n",
    "    sequence = data\n",
    "    inp_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=data,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    # iff correct these two should match\n",
    "    print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")  # ground-truth tokens\n",
    "    print(text_dataset[\"test\"][\"text\"][0], end=\"\\n\\n\")  # ground-truth text\n",
    "    print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 78, 106, 104, 35, 106, 104, 35, 119, 42, 111, 117, 104, 35, 123, 92, 61, 35, 119, 114, 113, 103, 35, 113, 103, 104, 35, 113, 106, 104, 35, 119, 110, 121, 104, 35, 101, 78, 119, 107, 104, 35, 123, 92, 61, 35, 113, 101, 78, 115, 104, 35, 119, 103, 104, 35, 123, 92, 61, 35, 113, 114, 113, 103, 104, 35, 113, 35, 113, 103, 114, 113, 92, 61, 35, 85, 85, 85, 88, 80, 76, 101, 78, 111, 42, 111, 104, 35, 101, 78, 106, 104, 35, 119, 121, 104, 35, 101, 78, 106]\n",
      "\n",
      "bKge ge t'lre xY: tond nde nge tkve bKthe xY: nbKpe tde xY: nonde n ndonY: RRRUMIbKl'le bKge tve bKg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence = data_gen\n",
    "    gen_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(gen_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(gen_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence time index: 0 \n",
      "neural: tensor([-0.3808,  0.2510, -0.2421, -0.7008, -0.1304], device='cuda:0')\n",
      "\n",
      "codebook token index: 0 \n",
      "coded: tensor([-0.3462,  0.2841, -0.2114, -0.6557, -0.1494], device='cuda:0') \n",
      "mapped: tensor([-0.3808,  0.2510, -0.2421, -0.7008, -0.1304], device='cuda:0')\n",
      "\n",
      "embedding token index: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-1.1267, -0.4185, -0.5118, -1.8685, -0.6045])\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The learned mapping did not converge to the true embedding!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m et \u001b[38;5;129;01min\u001b[39;00m real_train_tokens:\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m## DEBUG ###\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(neural \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not learn to map a vector it was trained on!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[1;32m     33\u001b[0m         embedded, mapped\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     34\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe learned mapping did not converge to the true embedding!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m## DEBUG ###\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m99\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The learned mapping did not converge to the true embedding!"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Assert should not be raised if the model learned to correctly map the tokens in the training  set\n",
    "for idx in range(data_gen.shape[1]):\n",
    "    neural = data_gen[:, [idx], :]\n",
    "    print(\"sequence time index:\", idx, \"\\nneural:\", neural.squeeze()[:5], end=\"\\n\\n\")\n",
    "\n",
    "    ct = model.tokenize_neural_data(neural).item()\n",
    "    coded = model.codebook[torch.tensor(ct, dtype=torch.long)].detach()\n",
    "    mapped = model.token_neural_map[torch.tensor(ct, dtype=torch.long)]\n",
    "    print(\"codebook token index:\", ct, \"\\ncoded:\", coded[:5], \"\\nmapped:\", mapped[:5], end=\"\\n\\n\")\n",
    "\n",
    "    assert torch.allclose(neural, mapped), \"Basic check failed; Inconsistency in mapping!\"\n",
    "\n",
    "    et = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    embedded = embedding(torch.tensor(et, dtype=torch.long))\n",
    "    print(\n",
    "        \"embedding token index:\",\n",
    "        et,\n",
    "        \"\\ncharacter:\",\n",
    "        tokenizer.decode([et]),\n",
    "        \"\\nin train set:\",\n",
    "        et in real_train_tokens,\n",
    "        \"\\nembedded:\",\n",
    "        embedded[:5],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    if et in real_train_tokens:\n",
    "        ## DEBUG ###\n",
    "        assert torch.any(neural != 0), \"Model did not learn to map a vector it was trained on!\"\n",
    "        assert torch.allclose(\n",
    "            embedded, mapped.cpu()\n",
    "        ), \"The learned mapping did not converge to the true embedding!\"\n",
    "        ## DEBUG ###\n",
    "\n",
    "    print(\"~\" * 99, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "\n",
    "all_unique_vectors = torch.vstack(train_dataset).unique(dim=0)\n",
    "learned_unique_vectors = model.token_neural_map.unique(dim=0)\n",
    "print(all_unique_vectors.shape, learned_unique_vectors.shape)\n",
    "print()\n",
    "\n",
    "all_unique_vectors = {tuple(row.round(decimals=2).cpu().numpy()) for row in all_unique_vectors}\n",
    "learned_unique_vectors = {\n",
    "    tuple(row.round(decimals=2).cpu().numpy()) for row in learned_unique_vectors\n",
    "}\n",
    "print(len(all_unique_vectors), len(learned_unique_vectors))\n",
    "print()\n",
    "\n",
    "inter = all_unique_vectors.intersection(learned_unique_vectors)\n",
    "diff = all_unique_vectors - learned_unique_vectors\n",
    "print(len(inter), len(diff))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
