{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found.\n"
     ]
    }
   ],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from CreateSyntheticDataset import tokenize_and_chunk  # works because of nbimporter\n",
    "from utils import DEVICE, BLOCK_SIZE, NUM_TOKENS, init_random_seeds\n",
    "\n",
    "# Initialize the random seeds\n",
    "init_random_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `tokenizer.encode(text)`:\n",
      "\ttext: Welcome to the ðŸ¤— Tokenizers library.\n",
      "\ttokenized: [90, 104, 111, 102, 114, 112, 104, 35, 119, 114, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 114, 110, 104, 113, 108, 125, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: Welcome to the ðŸ¤— Tokenizers library.</s>\n",
      "\n",
      "Calling `tokenizer(text)`:\n",
      "\tobject.keys(): dict_keys(['input_ids', 'attention_mask'])\n",
      "\ttext: We are very happy to show you the ðŸ¤— Transformers library.\n",
      "\ttokenized: [90, 104, 35, 100, 117, 104, 35, 121, 104, 117, 124, 35, 107, 100, 115, 115, 124, 35, 119, 114, 35, 118, 107, 114, 122, 35, 124, 114, 120, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 117, 100, 113, 118, 105, 114, 117, 112, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: We are very happy to show you the ðŸ¤— Transformers library.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-large\")\n",
    "\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "train: <class 'list'> 1 <class 'str'> 1003854\n",
      "\n",
      "validation: <class 'list'> 1 <class 'str'> 55770\n",
      "\n",
      "test: <class 'list'> 1 <class 'str'> 55770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1963\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "text_dataset['train']['input_ids']:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 1963\n",
      "\n",
      "text_dataset['train']['input_ids'][0]:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 506\n",
      "\n",
      "text_dataset['train']['input_ids'][0][0]:\n",
      " \ttype: <class 'int'> \n",
      "\tvalue: 73\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Original sequence (text):\n",
      "\tFirst Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the\n",
      "\n",
      "Encoded sequence (tokens):\n",
      "\t [73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 69, 104, 105, 114, 117, 104, 35, 122, 104, 35, 115, 117, 114, 102, 104, 104, 103, 35, 100, 113, 124, 35, 105, 120, 117, 119, 107, 104, 117, 47, 35, 107, 104, 100, 117, 35, 112, 104, 35, 118, 115, 104, 100, 110, 49, 35, 68, 111, 111, 61, 35, 86, 115, 104, 100, 110, 47, 35, 118, 115, 104, 100, 110, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 92, 114, 120, 35, 100, 117, 104, 35, 100, 111, 111, 35, 117, 104, 118, 114, 111, 121, 104, 103, 35, 117, 100, 119, 107, 104, 117, 35, 119, 114, 35, 103, 108, 104, 35, 119, 107, 100, 113, 35, 119, 114, 35, 105, 100, 112, 108, 118, 107, 66, 35, 68, 111, 111, 61, 35, 85, 104, 118, 114, 111, 121, 104, 103, 49, 35, 117, 104, 118, 114, 111, 121, 104, 103, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 73, 108, 117, 118, 119, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 35, 70, 100, 108, 120, 118, 35, 80, 100, 117, 102, 108, 120, 118, 35, 108, 118, 35, 102, 107, 108, 104, 105, 35, 104, 113, 104, 112, 124, 35, 119, 114, 35, 119, 107, 104, 35, 115, 104, 114, 115, 111, 104, 49, 35, 68, 111, 111, 61, 35, 90, 104, 35, 110, 113, 114, 122, 42, 119, 47, 35, 122, 104, 35, 110, 113, 114, 122, 42, 119, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 79, 104, 119, 35, 120, 118, 35, 110, 108, 111, 111, 35, 107, 108, 112, 47, 35, 100, 113, 103, 35, 122, 104, 42, 111, 111, 35, 107, 100, 121, 104, 35, 102, 114, 117, 113, 35, 100, 119, 35, 114, 120, 117, 35, 114, 122, 113, 35, 115, 117, 108, 102, 104, 49, 35, 76, 118, 42, 119, 35, 100, 35, 121, 104, 117, 103, 108, 102, 119, 66, 35, 68, 111, 111, 61, 35, 81, 114, 35, 112, 114, 117, 104, 35, 119, 100, 111, 110, 108, 113, 106, 35, 114, 113, 42, 119, 62, 35, 111, 104, 119, 35, 108, 119, 35, 101, 104, 35, 103, 114, 113, 104, 61, 35, 100, 122, 100, 124, 47, 35, 100, 122, 100, 124, 36, 35, 86, 104, 102, 114, 113, 103, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 82, 113, 104, 35, 122, 114, 117, 103, 47, 35, 106, 114, 114, 103, 35, 102, 108, 119, 108, 125, 104, 113, 118, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 90, 104, 35, 100, 117, 104, 35, 100, 102, 102, 114, 120, 113, 119, 104, 103, 35, 115, 114, 114, 117, 35, 102, 108, 119, 108, 125, 104, 113, 118, 47, 35, 119, 107, 104, 1]\n",
      "\n",
      "Decoded sequence (tokens):\n",
      "\t First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        # initrange = 0.1\n",
    "        # self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.embedding.weight.data.normal_()\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.normal_()\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 510]) torch.int64 False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create token datasets\n",
    "\n",
    "# train_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"train\"][\"input_ids\"]]\n",
    "train_dataset = [\n",
    "    torch.LongTensor(sequence[:-1])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"test\"][\"input_ids\"]]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Number of attn heads = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a TransformerModel\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Number of attn heads = {nhead}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler, criterion\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        tokens = train_dataset[batch].unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        input = tokens[:, :-1].to(DEVICE)  # ``[batch_size=1, seq_len]``\n",
    "        target = tokens[:, 1:].reshape(-1).to(DEVICE)  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            tokens = test_dataset[batch].unsqueeze(0)\n",
    "            input = tokens[:, :-1].to(DEVICE)\n",
    "            target = tokens[:, 1:].reshape(-1).to(DEVICE)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "epochs = 0\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs ** (1 / 3)), gamma=0.9)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            val_ppl = math.exp(val_loss)\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 509]) torch.Size([1, 609])\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, Yo\n",
      "\n",
      "+FG-fzN <ËœzN ËœzN ËœzN \u000f3XqN \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new text\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=None)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.4836, -0.2698,  0.8191,  ...,  0.3567,  1.1336,  0.0284],\n",
       "        [ 0.7726,  0.1965,  0.6936,  ...,  0.4193,  0.0172,  0.4886],\n",
       "        [ 0.7067,  0.2085, -0.5425,  ..., -0.5684, -0.2380, -0.4697],\n",
       "        ...,\n",
       "        [ 0.8706, -0.0356,  1.4579,  ...,  0.4546, -0.2519, -0.2257],\n",
       "        [-0.2055,  0.4185,  0.4247,  ...,  0.5892,  0.3196, -0.6849],\n",
       "        [-0.0620,  0.7760, -0.4380,  ...,  0.0501,  1.0111,  0.5296]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @title Create a fixed embedding table\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding_weight = torch.randn(ntokens, emsize)\n",
    "embedding = torch.nn.Embedding(\n",
    "    num_embeddings=ntokens,\n",
    "    embedding_dim=emsize,\n",
    "    dtype=torch.half,\n",
    "    _weight=embedding_weight,\n",
    "    _freeze=True,\n",
    ")  # fixed embedding map\n",
    "torch.nn.init.normal_(embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Create neural datasets\n",
    "# # @markdown A synthetic dataset where the neural activity is the embeddings of tokens from tiny Shakespeare.\n",
    "\n",
    "# # Create datasets\n",
    "# # train_dataset = [\n",
    "# #     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "# #     for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "# # ]\n",
    "# train_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "# # validation_dataset = [\n",
    "# #     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "# #     for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# # ]\n",
    "# test_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "# ]\n",
    "# print(f\"train_dataset: {len(train_dataset)}\", end=\"\\n\\n\")\n",
    "# print(f\"test_dataset: {len(test_dataset)}\", end=\"\\n\\n\")\n",
    "\n",
    "# # get a test sample for an example\n",
    "# data = test_dataset[0].unsqueeze(0)\n",
    "# print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "# mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "# print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 2000\n",
      "\n",
      "test_dataset: 200\n",
      "\n",
      "data:  torch.Size([1, 180, 302]) torch.float16 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: @title Create neural datasets\n",
    "\n",
    "# Create Shakespeare neural dataset\n",
    "\n",
    "from data._utils import create_combined_dataset, split_combined_dataset\n",
    "from CreateSyntheticDataset import create_synthetic_dataset_shakespeare, save_synthetic_dataset\n",
    "\n",
    "\n",
    "# Initialize parameters\n",
    "max_timesteps = 1500\n",
    "num_worms = 200\n",
    "num_signals = 302\n",
    "num_named_neurons = 50  # None  # all neurons\n",
    "smooth_method = None\n",
    "transform = None\n",
    "dataset_name = \"Shakespeare0000\"\n",
    "\n",
    "# Creating and saving datasets\n",
    "dataset = create_synthetic_dataset_shakespeare(\n",
    "    max_timesteps=max_timesteps,\n",
    "    num_worms=num_worms,\n",
    "    num_signals=num_signals,\n",
    "    num_named_neurons=num_named_neurons,\n",
    "    tokenizer=tokenizer,\n",
    "    embedding_weight=embedding_weight,\n",
    "    smooth_method=smooth_method,\n",
    "    transform=transform,\n",
    "    dataset_name=dataset_name,\n",
    ")\n",
    "\n",
    "# Get the number of worms in the dataset\n",
    "num_worms = len(dataset)\n",
    "\n",
    "# Save the dataset\n",
    "save_synthetic_dataset(f\"processed/neural/{dataset_name}.pickle\", dataset)\n",
    "\n",
    "# Load the dataset\n",
    "datasets = {\"Shakespeare0000\": \"all\"}\n",
    "combined_dataset, dataset_info = create_combined_dataset(datasets, num_named_neurons=None)\n",
    "num_worms = len(combined_dataset)\n",
    "\n",
    "# Split into train and validation sets\n",
    "num_train_samples = 10\n",
    "num_test_samples = 1\n",
    "reverse = use_residual = False\n",
    "smooth_data = True\n",
    "train_split_first = False\n",
    "train_split_ratio = 0.5\n",
    "seq_len = 180\n",
    "train_dataset, test_dataset, timestep_info = split_combined_dataset(\n",
    "    combined_dataset,\n",
    "    num_train_samples,\n",
    "    num_test_samples,\n",
    "    seq_len,\n",
    "    reverse,\n",
    "    use_residual,\n",
    "    smooth_data,\n",
    "    train_split_first,\n",
    "    train_split_ratio,\n",
    ")\n",
    "print(f\"train_dataset: {len(train_dataset)}\", end=\"\\n\\n\")\n",
    "print(f\"test_dataset: {len(test_dataset)}\", end=\"\\n\\n\")\n",
    "\n",
    "# get a test sample for an example\n",
    "input, target, mask, meta = test_dataset[0]\n",
    "\n",
    "data = input.unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = mask.unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed TRAIN tokens:\n",
      " 64 \t {35, 36, 39, 41, 42, 47, 48, 49, 54, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "\n",
      "observed TEST tokens:\n",
      " 59 \t {35, 36, 42, 47, 48, 49, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !',-.:;?ABCDEFGHIJKLMNOPRSTUVWYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# What tokens and their corresponding characters are in the train and test set\n",
    "real_train_tokens = set()\n",
    "for sequence in text_dataset[\"train\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_train_tokens.update(tokens)\n",
    "print(\"observed TRAIN tokens:\\n\", len(real_train_tokens), \"\\t\", real_train_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_train_tokens)))\n",
    "print(\"\\n\", \"~\" * 333, \"\\n\")\n",
    "\n",
    "real_test_tokens = set()\n",
    "for sequence in text_dataset[\"test\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_test_tokens.update(tokens)\n",
    "print(\"observed TEST tokens:\\n\", len(real_test_tokens), \"\\t\", real_test_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_test_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Model internal tokens = 2048\n",
      "Number of attn heads = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(\n",
    "    input_size=emsize,\n",
    "    hidden_size=d_hid,\n",
    "    version_2=True,\n",
    "    num_tokens=NUM_TOKENS,\n",
    ").to(DEVICE)\n",
    "# NOTE: In reality we don't actually know the underlying vocabulary size (i.e. num_tokens) of the embedding table used to generated the neural data.\n",
    "\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Model internal tokens = {model.num_tokens}\")\n",
    "print(f\"Number of attn heads = {model.num_heads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 179, 302]) torch.float16 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 179, 302]) torch.float16 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 179, 2048]) torch.float16 False cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's input-output functionality\n",
    "\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(input, mask)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([117, 100, 113, 102, 104], device='cuda:0')\n",
      "\n",
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's internal tokenizer\n",
    "\n",
    "# The code below should only work when we cheat and set the neural_embedding to be exactly the embedding table that was used to generate the neural data.\n",
    "# This is because the neural_embedding is initialized randomly. If the model has not been trained then there is no reason for its internal tokenizer to\n",
    "# correctly invert the ground-truth embedding, which should be unknown to us. Thereforem the goal of our optimization is ultimately to learn the\n",
    "# a neural_embedding that is as close as possible to the ground-truth but unknown embedding map.\n",
    "\n",
    "if embedding.weight.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(\n",
    "        embedding.weight, model.neural_embedding.cpu()\n",
    "    ), \"The neural_embedding should be different from the embedding map!\"\n",
    "\n",
    "# Replace model neural_embedding with the embedding map use to generate the dataset\n",
    "tmp = model.neural_embedding  # save for later restoration\n",
    "model.neural_embedding = embedding.weight.to(DEVICE)  # let's cheat\n",
    "\n",
    "if tmp.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(\n",
    "        tmp, model.neural_embedding\n",
    "    ), \"Unexpected aliasing of tmp to model.neural_embedding!\"\n",
    "\n",
    "    assert torch.allclose(\n",
    "        embedding.weight, model.neural_embedding.cpu()\n",
    "    ), \"The neural_embedding should be the same as the embedding map!\"\n",
    "\n",
    "# Get some ground-truth test data\n",
    "token_list = text_dataset[\"test\"][\"input_ids\"][0]\n",
    "token_target = torch.LongTensor(token_list)\n",
    "neural_target = torch.vstack([embedding(t) for t in token_target])\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the neural_embedding is the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0).to(DEVICE)).squeeze(\n",
    "        0\n",
    "    )\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should be the same\n",
    "assert torch.allclose(\n",
    "    token_target, retokenized_target.cpu()\n",
    "), \"The tokenized and retokenized sequences should be the same!\"\n",
    "\n",
    "# Restore the model neural_embedding to its original random initialization\n",
    "model.neural_embedding = tmp\n",
    "\n",
    "if embedding.weight.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(embedding.weight, model.neural_embedding.cpu())\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the neural_embedding is NOT the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0).to(DEVICE)).squeeze(\n",
    "        0\n",
    "    )\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should NOT be the same\n",
    "assert not torch.allclose(\n",
    "    token_target, retokenized_target.cpu()\n",
    "), \"The tokenized and retokenized sequences should NOT be the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "# def train(model: torch.nn.Module) -> None:\n",
    "#     model.train()  # turn on train mode\n",
    "#     total_loss = 0.0\n",
    "#     log_interval = 300\n",
    "#     start_time = time.time()\n",
    "#     global epoch, optimizer, scheduler\n",
    "\n",
    "#     num_batches = len(train_dataset)\n",
    "#     for batch in range(num_batches):\n",
    "#         data = train_dataset[batch].unsqueeze(0)\n",
    "#         mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "#         # parse into input and target\n",
    "#         mask = mask.to(DEVICE)\n",
    "#         input = data[:, :-1, :].to(DEVICE)\n",
    "#         target = data[:, 1:, :].to(DEVICE)\n",
    "#         # forward pass\n",
    "#         output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "#         # backpropagation step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = model.loss_fn()(\n",
    "#             output, target, mask\n",
    "#         )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "#         # check if the computed loss requires gradient\n",
    "#         if loss.requires_grad:\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "#             optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#         if batch % log_interval == 0 and batch > 0:\n",
    "#             lr = scheduler.get_last_lr()[0]\n",
    "#             ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "#             cur_loss = total_loss / log_interval\n",
    "#             try:\n",
    "#                 ppl = math.exp(cur_loss)\n",
    "#             except OverflowError:\n",
    "#                 ppl = float(\"inf\")\n",
    "#             print(\n",
    "#                 f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "#                 f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "#                 f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "#             )\n",
    "#             total_loss = 0\n",
    "#             start_time = time.time()\n",
    "\n",
    "\n",
    "# def evaluate(model: torch.nn.Module) -> float:\n",
    "#     model.eval()  # turn on evaluation mode\n",
    "#     total_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         num_batches = len(test_dataset)\n",
    "#         for batch in range(num_batches):\n",
    "#             data = test_dataset[batch].unsqueeze(0)\n",
    "#             mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "#             mask = mask.to(DEVICE)\n",
    "#             input = data[:, :-1, :].to(DEVICE)\n",
    "#             target = data[:, 1:, :].to(DEVICE)\n",
    "#             output = model(input, mask)\n",
    "#             loss = model.loss_fn()(output, target, mask)\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#     return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        input, target, mask, _ = train_dataset[batch]\n",
    "        input, target, mask = input.unsqueeze(0), target.unsqueeze(0), mask.unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = input[:, :-1, :].to(DEVICE)\n",
    "        target = target[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target, mask\n",
    "        )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            try:\n",
    "                ppl = math.exp(cur_loss)\n",
    "            except OverflowError:\n",
    "                ppl = float(\"inf\")\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            input, target, mask, _ = test_dataset[batch]\n",
    "            input, target, mask = input.unsqueeze(0), target.unsqueeze(0), mask.unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = input[:, :-1, :].to(DEVICE)\n",
    "            target = target[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (2048, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAFLCAYAAAD4cKfRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsaklEQVR4nO3deVyU5f7/8fcomyCgoCgmImXmlivWccsNVzSXTOu4QJYtbhi2SJ4elWW4VLZ4oiyTzKOohUsnPZWKmlpH3MrMpU4qdMQ0SRYrZLm/f5wf82sElUHwvnVez8djHnlfc819fe6Zeei7677ue2yGYRgCAACwoCpmFwAAAHAxBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBUAAGBZBBXABMeOHZPNZlNiYqLTr928ebNsNps2b95c4XVZTcOGDRUdHW12GaVKTEyUzWbTrl27Kn2sZ599VjabrUx9bTabnn32Wft2cZ3Hjh2rnOKASkZQAYDrWGRkpL788ksFBwebXQpQLm5mFwDANRQWFqqgoECenp5ml+JSateurdq1a5tdBlBuzKjAZRVPp3/zzTe6++675e/vr4CAAMXGxqqgoECHDx9W37595evrq4YNG2rOnDkOr09LS9OoUaMUFBQkT09PNW3aVC+//LKKiooc+p04cULDhw+Xr6+v/P39NWLECJ08ebLUmnbt2qU777xTAQEB8vLyUps2bbRixYpyHV/xlH9KSooeeeQR1apVS4GBgRo6dKhOnDhRov/y5cvVoUMH+fj4qHr16urTp4/27t3r0Kdbt27q1q1biddGR0erYcOG9u3iU1tz5szRCy+8oLCwMHl6eiolJUV//PGHpk6dqtatW9vf8w4dOmjNmjXlOs7SlOVYoqOjVb16dR06dEh9+vSRj4+PgoODNWvWLEnSV199pc6dO8vHx0eNGzfW+++/X+pYv/76q+677z4FBATIx8dHAwcO1I8//lii34YNG9SzZ0/5+fnJ29tbnTp10saNG0v0++STT9S6dWt5enoqLCxML730UqnjZmdna9y4cQoMDFT16tXVt29fHTlypES/0k79dOvWTS1atFBqaqq6dOkib29v3XjjjZo1a1aJ7++BAwfUu3dveXt7q3bt2powYYI++eQTlzn9CPMRVODyhg8frlatWumjjz7SuHHjNG/ePD366KMaPHiwIiMjtWrVKvXo0UNPPvmkkpOTJUmnT59Wx44d9dlnn+n555/X2rVrFRERoccee0wTJ0607/v3339XRESEPvvsM8XHx2vlypWqW7euRowYUaKOlJQUderUSWfPntVbb72lNWvWqHXr1hoxYkS51rIUe+CBB+Tu7q6lS5dqzpw52rx5s0aNGuXQ58UXX9S9996rZs2aacWKFfrggw+Uk5OjLl266Lvvviv32K+//ro2bdqkl156SevXr1eTJk2Ul5enzMxMPfbYY1q9erWWLVumzp07a+jQoVq8eHG5xyrPseTn52vo0KGKjIzUmjVr1K9fP8XFxempp55SVFSUxo4dq1WrVumWW25RdHS0du/eXWK8+++/X1WqVNHSpUv16quvaufOnerWrZvOnj1r77NkyRL17t1bfn5+ev/997VixQoFBASoT58+DmFl48aNGjRokHx9fZWUlKS5c+dqxYoVWrRokcOYhmFo8ODB+uCDDzR16lStWrVKf/nLX9SvX78yv08nT57UyJEjNWrUKK1du9Z+7EuWLLH3ycjIUNeuXXX48GElJCRo8eLFysnJcfiOA5XOAFzUM888Y0gyXn75ZYf21q1bG5KM5ORke1t+fr5Ru3ZtY+jQoYZhGMa0adMMSca///1vh9c+8sgjhs1mMw4fPmwYhmEkJCQYkow1a9Y49Bs3bpwhyVi0aJG9rUmTJkabNm2M/Px8h74DBgwwgoODjcLCQsMwDCMlJcWQZKSkpFzy+BYtWmRIMsaPH+/QPmfOHEOSkZGRYRiGYaSlpRlubm7GpEmTHPrl5OQYdevWNYYPH25v69q1q9G1a9cSY0VFRRmhoaH27aNHjxqSjJtuusk4f/78JessKCgw8vPzjfvvv99o06aNw3OhoaFGVFTUJV//Z84cS1RUlCHJ+Oijj+xtxZ+zJGPPnj329jNnzhhVq1Y1YmNj7W3F7++QIUMcxtq+fbshyXjhhRcMwzCMc+fOGQEBAcbAgQMd+hUWFhqtWrUybrvtNnvb7bffbtSrV8/4/fff7W3Z2dlGQECA8ee/rtevX29IMl577TWHfc6cOdOQZDzzzDMl6jx69Ki9rWvXrqV+f5s1a2b06dPHvv34448bNpvNOHDggEO/Pn36lOk7CFQEZlTg8gYMGOCw3bRpU9lsNof/O3Vzc1OjRo10/PhxSdKmTZvUrFkz3XbbbQ6vjY6OlmEY2rRpk6T/zZL4+vrqzjvvdOj317/+1WH7hx9+0KFDhzRy5EhJUkFBgf3Rv39/ZWRk6PDhw+U6vgvHbtmypSTZj+XTTz9VQUGBxowZ4zCul5eXunbtekXT+3feeafc3d1LtK9cuVKdOnVS9erV5ebmJnd3dy1cuFAHDx4s91iS88dis9nUv39/+3bx5xwcHKw2bdrY2wMCAhQUFGR/z/6s+DMr1rFjR4WGhiolJUWStGPHDmVmZioqKsqhpqKiIvXt21epqak6d+6czp07p9TUVA0dOlReXl72/fn6+mrgwIEOYxTv+8KxL/xeXUrdunVLfH9btmzpcIxbtmxRixYt1KxZM4d+9957b5nHAa4Ui2nh8gICAhy2PTw85O3t7fCPRXF7dna2JOnMmTMOazKK1atXz/588X/r1KlTol/dunUdtn/++WdJ0mOPPabHHnus1Dp/+eWXMhxNSYGBgQ7bxYtZf//9d4ex27dvX+rrq1Qp///PlHalSXJysoYPH667775bjz/+uOrWrSs3NzclJCTovffeK/dYkvPHcrHP+cLvRHH7H3/8UaL9ws+yuK34O1Bc07Bhwy5ad2Zmpmw2m4qKii66vz87c+aM3NzcSny2pb32Yi58rfS/70bx96J4nLCwsBL9SvtOA5WFoAKUQ2BgoDIyMkq0Fy9SrVWrlr3fzp07S/S7cDFtcf+4uDgNHTq01DFvueWWK6r5YorH/vDDDxUaGnrJvl5eXsrKyirRfrEQVdq9P5YsWaKwsDAtX77c4fm8vDxnyi6VM8dSUUpbGH3y5Ek1atTIoaY33nhDf/nLX0rdR506dZSfny+bzXbR/f1ZYGCgCgoKdObMGYfAcbFF2uUVGBhoD1qXqgeoTJz6AcqhZ8+e+u6777Rnzx6H9sWLF8tms6l79+6SpO7duysnJ0dr16516Ld06VKH7VtuuUU333yzvv76a4WHh5f68PX1rZRj6dOnj9zc3PSf//znomMXa9iwoY4cOeIQKs6cOaMdO3aUeTybzSYPDw+HkHLy5MkKuerHmWOpKP/4xz8ctnfs2KHjx4/br47q1KmTatSooe++++6iNXl4eMjHx0e33XabkpOTHWZucnJy9PHHHzuMUfz9unDsC79XV6pr16769ttvSyxCTkpKqtBxgEthRgUoh0cffVSLFy9WZGSkZsyYodDQUH3yySd688039cgjj6hx48aSpDFjxmjevHkaM2aMZs6cqZtvvlnr1q3Tp59+WmKfb7/9tvr166c+ffooOjpaN9xwgzIzM3Xw4EHt2bNHK1euvGg9ixcv1tixY/Xee+9pzJgxTh1Lw4YNNWPGDE2fPl0//vij+vbtq5o1a+rnn3/Wzp075ePjo+eee06SNHr0aL399tsaNWqUxo0bpzNnzmjOnDny8/Mr83gDBgxQcnKyxo8fr2HDhik9PV3PP/+8goOD9f333ztV+5UcS0XZtWuXHnjgAd19991KT0/X9OnTdcMNN2j8+PGSpOrVq+uNN95QVFSUMjMzNWzYMAUFBen06dP6+uuvdfr0aSUkJEiSnn/+efXt21e9evXS1KlTVVhYqNmzZ8vHx0eZmZn2MXv37q077rhDTzzxhM6dO6fw8HBt375dH3zwQYUe25QpU/Tee++pX79+mjFjhurUqaOlS5fq0KFDkq7stCBQVnzLgHKoXbu2duzYoR49eiguLk4DBgzQp59+qjlz5uiNN96w9/P29tamTZsUERGhadOmadiwYfrpp59K/T/S7t27a+fOnapRo4amTJmiiIgIPfLII9qwYYMiIiIuWU9RUZEKCwtL3AOjrOLi4vThhx/qyJEjioqKUp8+ffTEE0/o+PHjuuOOO+z9OnXqpPfff18HDhzQoEGD9MILLyguLq7Ue6tczH333adZs2Zp/fr16t+/v2bPnq1p06Y5tRC0Io6loixcuFDnz5/XPffco8mTJys8PFybN292WOcyatQopaSkKDc3Vw899JAiIiIUExOjPXv2qGfPnvZ+vXr10urVq5Wdna0RI0YoNjZWd911l8aOHeswZpUqVbR27VqNHDlSc+bM0eDBg7Vjxw6tW7euQo+tXr162rJlixo3bqyHH35YI0eOlIeHh2bMmCFJqlGjRoWOB5TGZhiGYXYRAIBrx4MPPqhly5bpzJkz8vDwMLscXOc49QMAuKgZM2aoXr16uvHGG5Wbm6t//vOfevfdd/W3v/2NkIKrgqAC4JpQWFioS00A22w2Va1a9SpW5Brc3d01d+5c/fTTTyooKNDNN9+sV155RTExMWaXBhfBqR8A14SGDRuWesO1Yld6czoA1sSMCoBrwscff3zJe61U1uXbAMzFjAoAALAsLk8GAACWdU2f+ikqKtKJEyfk6+tb6q26AQCA9RiGoZycHNWrV++yNw68poPKiRMnFBISYnYZAACgHNLT01W/fv1L9rmmg0rx4rnO6i83lfwpeQAAYD0Fytc2rSvTIvhrOqgUn+5xk7vcbAQVAACuCf/vMp6yLNtgMS0AALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAsggoAALAs04PKm2++qbCwMHl5ealdu3b64osvzC4JAABYhKlBZfny5ZoyZYqmT5+uvXv3qkuXLurXr5/S0tLMLAsAAFiEqUHllVde0f33368HHnhATZs21auvvqqQkBAlJCSYWRYAALAI04LK+fPntXv3bvXu3duhvXfv3tqxY0epr8nLy1N2drbDAwAAXL9MCyq//PKLCgsLVadOHYf2OnXq6OTJk6W+Jj4+Xv7+/vZHSEjI1SgVAACYxPTFtDabzWHbMIwSbcXi4uKUlZVlf6Snp1+NEgEAgEnczBq4Vq1aqlq1aonZk1OnTpWYZSnm6ekpT0/Pq1EeAACwANNmVDw8PNSuXTt9/vnnDu2ff/65OnbsaFJVAADASkybUZGk2NhYjR49WuHh4erQoYMWLFigtLQ0Pfzww2aWBQAALMLUoDJixAidOXNGM2bMUEZGhlq0aKF169YpNDTUzLIAAIBF2AzDMMwuoryys7Pl7++vbhokN5u72eUAAIAyKDDytVlrlJWVJT8/v0v2Nf2qHwAAgIshqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMsyNahs3bpVAwcOVL169WSz2bR69WozywEAABZjalA5d+6cWrVqpfnz55tZBgAAsCg3Mwfv16+f+vXrZ2YJAADAwkwNKs7Ky8tTXl6efTs7O9vEagAAQGW7phbTxsfHy9/f3/4ICQkxuyQAAFCJrqmgEhcXp6ysLPsjPT3d7JIAAEAluqZO/Xh6esrT09PsMgAAwFVyTc2oAAAA12LqjEpubq5++OEH+/bRo0e1b98+BQQEqEGDBiZWBgAArMDUoLJr1y51797dvh0bGytJioqKUmJioklVAQAAqzA1qHTr1k2GYZhZAgAAsDDWqAAAAMsiqAAAAMsiqAAAAMsiqAAAAMtyOqhs2LDhos+9/fbbV1QMAADAnzkdVCIjIzV16lSdP3/e3nb69GkNHDhQcXFxFVocAABwbU4Hla1bt+rjjz9W+/btdeDAAX3yySdq0aKFcnNz9fXXX1dGjQAAwEU5HVRuv/127d27Vy1btlS7du00ZMgQTZ06VZs2beLXjAEAQIUq12Law4cPKzU1VfXr15ebm5sOHTqk3377raJrAwAALs7poDJr1ix16NBBvXr10rfffqvU1FT7DMuXX35ZGTUCAAAX5XRQee2117R69Wq98cYb8vLyUvPmzbVz504NHTpU3bp1q4QSAQCAq3L6t37279+vWrVqObS5u7tr7ty5GjBgQIUVBgAA4PSMSq1atXT27Fm9++67iouLU2ZmpiRpz549atSoUYUXCAAAXJfTMyrffPONIiIi5O/vr2PHjmncuHEKCAjQqlWrdPz4cS1evLgy6gQAAC7I6RmV2NhYRUdH6/vvv5eXl5e9vV+/ftq6dWuFFgcAAFyb00ElNTVVDz30UIn2G264QSdPnqyQogAAAKRyBBUvLy9lZ2eXaD98+LBq165dIUUBAABI5QgqgwYN0owZM5Sfny9JstlsSktL07Rp03TXXXdVeIEAAMB1OR1UXnrpJZ0+fVpBQUH6/fff1bVrVzVq1Ei+vr6aOXNmZdQIAABclNNX/fj5+Wnbtm3atGmT9uzZo6KiIrVt21YRERGVUR8AAHBhTgeVYj169FCPHj0qshYAAAAHZQoqr7/+epl3OHny5HIXAwAA8GdlCirz5s1z2D59+rR+++031ahRQ5J09uxZeXt7KygoiKACAAAqTJkW0x49etT+mDlzplq3bq2DBw8qMzNTmZmZOnjwoNq2bavnn3++susFAAAuxGYYhuHMC2666SZ9+OGHatOmjUP77t27NWzYMB09erRCC7yU7Oxs+fv7q5sGyc3mftXGBQAA5Vdg5Guz1igrK0t+fn6X7Ov05ckZGRn2e6j8WWFhoX7++WdndwcAAHBRTgeVnj17aty4cdq1a5eKJ2N27dqlhx56iEuUAQBAhXI6qLz33nu64YYbdNttt8nLy0uenp66/fbbFRwcrHfffbcyagQAAC7K6fuo1K5dW+vWrdORI0d06NAhGYahpk2bqnHjxpVRHwAAcGHlvuFb48aNCScAAKBSOR1UCgsLlZiYqI0bN+rUqVMqKipyeH7Tpk0VVhwAAHBtTgeVmJgYJSYmKjIyUi1atJDNZquMugAAAJwPKklJSVqxYoX69+9fGfUAAADYOX3Vj4eHhxo1alQZtQAAADhwOqhMnTpVr732mpy8oS0AAIDTnD71s23bNqWkpGj9+vVq3ry53N0db12fnJxcYcUBAADX5nRQqVGjhoYMGVIZtQAAADhwOqgsWrSoMuoAAAAowek1KgAAAFdLmWZU2rZtq40bN6pmzZpq06bNJe+dsmfPnjIPHh8fr+TkZB06dEjVqlVTx44dNXv2bN1yyy1l3gcAALh+lSmoDBo0SJ6enpKkwYMHV9jgW7Zs0YQJE9S+fXsVFBRo+vTp6t27t7777jv5+PhU2DgAAODaZDMsdJ3x6dOnFRQUpC1btuiOO+64bP/s7Gz5+/urmwbJzeZ+2f4AAMB8BUa+NmuNsrKy5Ofnd8m+5f5RwsqQlZUlSQoICCj1+by8POXl5dm3s7Ozr0pdAADAHJZZTGsYhmJjY9W5c2e1aNGi1D7x8fHy9/e3P0JCQq5ylQAA4GqyTFCZOHGivvnmGy1btuyifeLi4pSVlWV/pKenX8UKAQDA1WaJUz+TJk3S2rVrtXXrVtWvX/+i/Tw9Pe2LegEAwPXP1KBiGIYmTZqkVatWafPmzQoLCzOzHAAAYDFOB5XCwkIlJiZq48aNOnXqlIqKihye37RpU5n3NWHCBC1dulRr1qyRr6+vTp48KUny9/dXtWrVnC0NAABcZ5wOKjExMUpMTFRkZKRatGhxyZu/XU5CQoIkqVu3bg7tixYtUnR0dLn3CwAArg9OB5WkpCStWLFC/fv3v+LBLXQLFwAAYEFOX/Xj4eGhRo0aVUYtAAAADpwOKlOnTtVrr73GbAgAAKh0Tp/62bZtm1JSUrR+/Xo1b95c7u6Ot65PTk6usOIAAIBrczqo1KhRQ0OGDKmMWgAAABw4HVQWLVpUGXUAAACUUK5b6BcUFGjDhg16++23lZOTI0k6ceKEcnNzK7Q4AADg2pyeUTl+/Lj69u2rtLQ05eXlqVevXvL19dWcOXP0xx9/6K233qqMOgEAgAtyekYlJiZG4eHh+vXXXx3uHjtkyBBt3LixQosDAACurVxX/Wzfvl0eHh4O7aGhofrvf/9bYYUBAAA4PaNSVFSkwsLCEu0//fSTfH19K6QoAAAAqRxBpVevXnr11Vft2zabTbm5uXrmmWcq5Lb6AAAAxZw+9TNv3jx1795dzZo10x9//KG//vWv+v7771WrVi0tW7asMmoEAAAuyumgUq9ePe3bt09JSUnavXu3ioqKdP/992vkyJEOi2sBAACulM1w8kd7lixZolGjRpX63OOPP665c+dWSGFlkZ2dLX9/f3XTILnZ3C//AgAAYLoCI1+btUZZWVny8/O7ZF+n16hMnDhR//znP0u0P/roo1qyZImzuwMAALgop4NKUlKSRo0apa1bt9rbJk2apBUrViglJaVCiwMAAK7N6aDSt29fvfXWWxo8eLB27dql8ePHKzk5WSkpKWrSpEll1AgAAFyU04tpJemee+7Rr7/+qs6dO6t27drasmWLGjVqVNG1AQAAF1emoBIbG1tqe1BQkNq0aaM333zT3vbKK69UTGUAAMDllSmo7N27t9T2m266SdnZ2fbnbTZbxVUGAABcXpmCCotkAQCAGZxeTPtnP/30Ez9ECAAAKk25fpRwxowZ8vf3V2hoqBo0aKAaNWro+eefV1FRUWXUCAAAXJTTV/1Mnz5dCxcu1KxZs9SpUycZhqHt27fr2Wef1R9//KGZM2dWRp0AAMAFOR1U3n//fb377ru688477W2tWrXSDTfcoPHjxxNUAABAhXH61E9mZmapN3Zr0qSJMjMzK6QoAAAAqRxBpVWrVpo/f36J9vnz56tVq1YVUhQAAIBUjlM/c+bMUWRkpDZs2KAOHTrIZrNpx44dSk9P17p16yqjRgAA4KKcnlHp2rWrjhw5oiFDhujs2bPKzMzU0KFDdfjwYXXp0qUyagQAAC7K6RmVtLQ0hYSElLpoNi0tTQ0aNKiQwgAAAJyeUQkLC9Pp06dLtJ85c0ZhYWEVUhQAAIBUjqBiGEapv+mTm5srLy+vCikKAABAcuLUT/EvKNtsNj399NPy9va2P1dYWKh///vfat26dYUXCAAAXFeZg0rxLyQbhqH9+/fLw8PD/pyHh4datWqlxx57rOIrBAAALqvMQaX4F5Tvu+8+vfbaa/Lz86u0ogAAAKRyXPWzaNGiyqgDAACgBKcX0wIAAFwtBBUAAGBZpgaVhIQEtWzZUn5+fvLz81OHDh20fv16M0sCAAAWYmpQqV+/vmbNmqVdu3Zp165d6tGjhwYNGqQDBw6YWRYAALAIm2EYhtlF/FlAQIDmzp2r+++//7J9s7Oz5e/vr24aJDeb+1WoDgAAXKkCI1+btUZZWVmXvYrY6at+KkthYaFWrlypc+fOqUOHDqX2ycvLU15enn07Ozv7apUHAABMYPpi2v3796t69ery9PTUww8/rFWrVqlZs2al9o2Pj5e/v7/9ERIScpWrBQAAV5Ppp37Onz+vtLQ0nT17Vh999JHeffddbdmypdSwUtqMSkhICKd+AAC4hjhz6sf0oHKhiIgI3XTTTXr77bcv25c1KgAAXHucCSqmn/q5kGEYDrMmAADAdZm6mPapp55Sv379FBISopycHCUlJWnz5s3617/+ZWZZAADAIkwNKj///LNGjx6tjIwM+fv7q2XLlvrXv/6lXr16mVkWAACwCFODysKFC80cHgAAWJzl1qgAAAAUI6gAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLIqgAAADLskxQiY+Pl81m05QpU8wuBQAAWIQlgkpqaqoWLFigli1bml0KAACwENODSm5urkaOHKl33nlHNWvWNLscAABgIaYHlQkTJigyMlIRERGX7ZuXl6fs7GyHBwAAuH65mTl4UlKS9uzZo9TU1DL1j4+P13PPPVfJVQEAAKswbUYlPT1dMTExWrJkiby8vMr0mri4OGVlZdkf6enplVwlAAAwk2kzKrt379apU6fUrl07e1thYaG2bt2q+fPnKy8vT1WrVnV4jaenpzw9Pa92qQAAwCSmBZWePXtq//79Dm333XefmjRpoieffLJESAEAAK7HtKDi6+urFi1aOLT5+PgoMDCwRDsAAHBNpl/1AwAAcDGmXvVzoc2bN5tdAgAAsBBmVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGURVAAAgGW5mV3AlTAMQ5JUoHzJMLkYAABQJgXKl/T//x2/lGs6qOTk5EiStmmdyZUAAABn5eTkyN/f/5J9bEZZ4oxFFRUV6cSJE/L19ZXNZquUMbKzsxUSEqL09HT5+flVyhgoGz4L6+CzsBY+D+vgsygbwzCUk5OjevXqqUqVS69CuaZnVKpUqaL69etflbH8/Pz40lkEn4V18FlYC5+HdfBZXN7lZlKKsZgWAABYFkEFAABYFkHlMjw9PfXMM8/I09PT7FJcHp+FdfBZWAufh3XwWVS8a3oxLQAAuL4xowIAACyLoAIAACyLoAIAACyLoAIAACyLoHIJb775psLCwuTl5aV27drpiy++MLsklxQfH6/27dvL19dXQUFBGjx4sA4fPmx2WdD/PhubzaYpU6aYXYpL+u9//6tRo0YpMDBQ3t7eat26tXbv3m12WS6noKBAf/vb3xQWFqZq1arpxhtv1IwZM1RUVGR2adcFgspFLF++XFOmTNH06dO1d+9edenSRf369VNaWprZpbmcLVu2aMKECfrqq6/0+eefq6CgQL1799a5c+fMLs2lpaamasGCBWrZsqXZpbikX3/9VZ06dZK7u7vWr1+v7777Ti+//LJq1KhhdmkuZ/bs2Xrrrbc0f/58HTx4UHPmzNHcuXP1xhtvmF3adYHLky/i9ttvV9u2bZWQkGBva9q0qQYPHqz4+HgTK8Pp06cVFBSkLVu26I477jC7HJeUm5urtm3b6s0339QLL7yg1q1b69VXXzW7LJcybdo0bd++nZleCxgwYIDq1KmjhQsX2tvuuusueXt764MPPjCxsusDMyqlOH/+vHbv3q3evXs7tPfu3Vs7duwwqSoUy8rKkiQFBASYXInrmjBhgiIjIxUREWF2KS5r7dq1Cg8P1913362goCC1adNG77zzjtlluaTOnTtr48aNOnLkiCTp66+/1rZt29S/f3+TK7s+XNM/SlhZfvnlFxUWFqpOnToO7XXq1NHJkydNqgrS/35xMzY2Vp07d1aLFi3MLsclJSUlac+ePUpNTTW7FJf2448/KiEhQbGxsXrqqae0c+dOTZ48WZ6enhozZozZ5bmUJ598UllZWWrSpImqVq2qwsJCzZw5U/fee6/ZpV0XCCqXYLPZHLYNwyjRhqtr4sSJ+uabb7Rt2zazS3FJ6enpiomJ0WeffSYvLy+zy3FpRUVFCg8P14svvihJatOmjQ4cOKCEhASCylW2fPlyLVmyREuXLlXz5s21b98+TZkyRfXq1VNUVJTZ5V3zCCqlqFWrlqpWrVpi9uTUqVMlZllw9UyaNElr167V1q1bVb9+fbPLcUm7d+/WqVOn1K5dO3tbYWGhtm7dqvnz5ysvL09Vq1Y1sULXERwcrGbNmjm0NW3aVB999JFJFbmuxx9/XNOmTdM999wjSbr11lt1/PhxxcfHE1QqAGtUSuHh4aF27drp888/d2j//PPP1bFjR5Oqcl2GYWjixIlKTk7Wpk2bFBYWZnZJLqtnz57av3+/9u3bZ3+Eh4dr5MiR2rdvHyHlKurUqVOJy/SPHDmi0NBQkypyXb/99puqVHH857Rq1apcnlxBmFG5iNjYWI0ePVrh4eHq0KGDFixYoLS0ND388MNml+ZyJkyYoKVLl2rNmjXy9fW1z3T5+/urWrVqJlfnWnx9fUusDfLx8VFgYCBrhq6yRx99VB07dtSLL76o4cOHa+fOnVqwYIEWLFhgdmkuZ+DAgZo5c6YaNGig5s2ba+/evXrllVc0duxYs0u7Phi4qL///e9GaGio4eHhYbRt29bYsmWL2SW5JEmlPhYtWmR2aTAMo2vXrkZMTIzZZbikjz/+2GjRooXh6elpNGnSxFiwYIHZJbmk7OxsIyYmxmjQoIHh5eVl3Hjjjcb06dONvLw8s0u7LnAfFQAAYFmsUQEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAEAAJZFUAGucd26ddOUKVPMLsMp0dHRGjx4sH37WjkGm82m1atXm10G4FL4rR/gGpecnCx3d/erPu6zzz6r1atXa9++fVe8L7OOwVkZGRmqWbOm2WUALoWgAlzjAgICzC7hil0rx1C3bl2zSwBcDqd+gGvchadNGjZsqBdffFFjx46Vr6+vGjRo4PCLuseOHZPNZlNSUpI6duwoLy8vNW/eXJs3b7b3SUxMVI0aNRzGWb16tWw2m/355557Tl9//bVsNptsNpsSExNLra+wsFCxsbGqUaOGAgMD9cQTT+jCnxgr7RheeOEFjRkzRtWrV1doaKjWrFmj06dPa9CgQapevbpuvfVW7dq1y2E/O3bs0B133KFq1aopJCREkydP1rlz58r83pw/f14TJ05UcHCwvLy81LBhQ8XHx9ufv/DUz/79+9WjRw9Vq1ZNgYGBevDBB5Wbm2t/vvgU10svvaTg4GAFBgZqwoQJys/PL/W9AlASQQW4Dr388ssKDw/X3r17NX78eD3yyCM6dOiQQ5/HH39cU6dO1d69e9WxY0fdeeedOnPmTJn2P2LECE2dOlXNmzdXRkaGMjIyNGLEiIvW8t5772nhwoXatm2bMjMztWrVqsuOMW/ePHXq1El79+5VZGSkRo8erTFjxmjUqFHas2ePGjVqpDFjxthDz/79+9WnTx8NHTpU33zzjZYvX65t27Zp4sSJZX5vXn/9da1du1YrVqzQ4cOHtWTJEjVs2LDU+n777Tf17dtXNWvWVGpqqlauXKkNGzaUGC8lJUX/+c9/lJKSovfff1+JiYkXDXUASmHujzcDuFJdu3Y1YmJi7NuhoaHGqFGj7NtFRUVGUFCQkZCQYBiGYRw9etSQZMyaNcveJz8/36hfv74xe/ZswzAMY9GiRYa/v7/DOKtWrTL+/FfGM888Y7Rq1eqy9QUHB5c61qBBg8p8DBkZGYYk4+mnn7a3ffnll4YkIyMjwzAMwxg9erTx4IMPOoz9xRdfGFWqVDF+//33Mr03kyZNMnr06GEUFRWVeiySjFWrVhmGYRgLFiwwatasaeTm5tqf/+STT4wqVaoYJ0+eNAzDMKKioozQ0FCjoKDA3ufuu+82RowYcfE3DIADZlSA61DLli3tf7bZbKpbt65OnTrl0KdDhw72P7u5uSk8PFwHDx6s0DqysrKUkZFR6liX8+djqFOnjiTp1ltvLdFWfFy7d+9WYmKiqlevbn/06dNHRUVFOnr0aKn7vfC9iY6O1r59+3TLLbdo8uTJ+uyzzy5a38GDB9WqVSv5+PjY2zp16qSioiIdPnzY3ta8eXNVrVrVvh0cHFziswBwcSymBa5DF15BY7PZVFRUdNnXFa9BqVKlSol1JFd7XcWfj6G4rtLaio+rqKhIDz30kCZPnlxiXw0aNCh1v8X7Kd5H27ZtdfToUa1fv14bNmzQ8OHDFRERoQ8//LDEPg3DsNdwoT+3l/ezAPA/zKgALuqrr76y/7mgoEC7d+9WkyZNJEm1a9dWTk6Ow0LUCy9D9vDwUGFh4SXH8Pf3V3BwcKljVbS2bdvqwIEDatSoUYmHh4dHmffj5+enESNG6J133tHy5cv10UcfKTMzs0S/Zs2aad++fQ7v0fbt21WlShU1bty4Qo4JAEEFcFl///vftWrVKh06dEgTJkzQr7/+qrFjx0qSbr/9dnl7e+upp57SDz/8oKVLl5ZYANqwYUMdPXpU+/bt0y+//KK8vLxSx4mJidGsWbPsY40fP15nz56t8ON58skn9eWXX2rChAnat2+fvv/+e61du1aTJk0q8z7mzZunpKQkHTp0SEeOHNHKlStVt27dEldASdLIkSPl5eWlqKgoffvtt0pJSdGkSZM0evRo+2kpAFeOoAK4qFmzZmn27Nlq1aqVvvjiC61Zs0a1atWS9L/7mixZskTr1q3TrbfeqmXLlunZZ591eP1dd92lvn37qnv37qpdu7aWLVtW6jhTp07VmDFjFB0drQ4dOsjX11dDhgyp8ONp2bKltmzZou+//15dunRRmzZt9PTTTys4OLjM+6hevbpmz56t8PBwtW/fXseOHdO6detUpUrJvyq9vb316aefKjMzU+3bt9ewYcPUs2dPzZ8/vyIPC3B5NuPCE9EArmvHjh1TWFiY9u7dq9atW5tdDgBcEjMqAADAsggqAADAsjj1AwAALIsZFQAAYFkEFQAAYFkEFQAAYFkEFQAAYFkEFQAAYFkEFQAAYFkEFQAAYFkEFQAAYFn/B5NEG5Zk7ObpAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 2000 batches | lr 5.00 | ms/batch 24.72 | loss 90.47 | ppl 1960995409993358279990571478228337164288.00\n",
      "| epoch   1 |   600/ 2000 batches | lr 5.00 | ms/batch 25.26 | loss 37.33 | ppl 16335800054034498.00\n",
      "| epoch   1 |   900/ 2000 batches | lr 5.00 | ms/batch 14.23 | loss 27.21 | ppl 654464599731.09\n",
      "| epoch   1 |  1200/ 2000 batches | lr 5.00 | ms/batch 16.99 | loss 23.33 | ppl 13569544587.68\n",
      "| epoch   1 |  1500/ 2000 batches | lr 5.00 | ms/batch 20.33 | loss 20.32 | ppl 670103481.44\n",
      "| epoch   1 |  1800/ 2000 batches | lr 5.00 | ms/batch 16.52 | loss 18.20 | ppl 80232779.26\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 39.69s | valid loss 17.36 | valid ppl 34565249.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   2 |   300/ 2000 batches | lr 5.00 | ms/batch 25.83 | loss 15.30 | ppl 4419727.24\n",
      "| epoch   2 |   600/ 2000 batches | lr 5.00 | ms/batch 20.24 | loss 13.00 | ppl 444353.19\n",
      "| epoch   2 |   900/ 2000 batches | lr 5.00 | ms/batch 14.15 | loss 12.17 | ppl 193278.61\n",
      "| epoch   2 |  1200/ 2000 batches | lr 5.00 | ms/batch 14.62 | loss 11.49 | ppl 97664.84\n",
      "| epoch   2 |  1500/ 2000 batches | lr 5.00 | ms/batch 15.08 | loss 10.98 | ppl 58708.43\n",
      "| epoch   2 |  1800/ 2000 batches | lr 5.00 | ms/batch 14.62 | loss 10.52 | ppl 37214.48\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 34.75s | valid loss 11.95 | valid ppl 155529.37\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   3 |   300/ 2000 batches | lr 4.50 | ms/batch 14.31 | loss  8.43 | ppl  4576.12\n",
      "| epoch   3 |   600/ 2000 batches | lr 4.50 | ms/batch 14.34 | loss  7.92 | ppl  2757.83\n",
      "| epoch   3 |   900/ 2000 batches | lr 4.50 | ms/batch 14.23 | loss  7.74 | ppl  2304.50\n",
      "| epoch   3 |  1200/ 2000 batches | lr 4.50 | ms/batch 18.22 | loss  7.69 | ppl  2190.93\n",
      "| epoch   3 |  1500/ 2000 batches | lr 4.50 | ms/batch 15.88 | loss  7.60 | ppl  1996.87\n",
      "| epoch   3 |  1800/ 2000 batches | lr 4.50 | ms/batch 14.78 | loss  7.36 | ppl  1574.85\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 31.01s | valid loss 10.05 | valid ppl 23120.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   4 |   300/ 2000 batches | lr 4.50 | ms/batch 14.30 | loss  6.95 | ppl  1041.32\n",
      "| epoch   4 |   600/ 2000 batches | lr 4.50 | ms/batch 14.43 | loss  6.57 | ppl   715.45\n",
      "| epoch   4 |   900/ 2000 batches | lr 4.50 | ms/batch 14.44 | loss  6.63 | ppl   757.94\n",
      "| epoch   4 |  1200/ 2000 batches | lr 4.50 | ms/batch 14.46 | loss  6.59 | ppl   727.86\n",
      "| epoch   4 |  1500/ 2000 batches | lr 4.50 | ms/batch 14.75 | loss  6.48 | ppl   649.07\n",
      "| epoch   4 |  1800/ 2000 batches | lr 4.50 | ms/batch 14.73 | loss  6.29 | ppl   538.53\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 29.55s | valid loss  7.59 | valid ppl  1974.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   5 |   300/ 2000 batches | lr 4.05 | ms/batch 14.26 | loss  5.53 | ppl   251.53\n",
      "| epoch   5 |   600/ 2000 batches | lr 4.05 | ms/batch 14.15 | loss  5.05 | ppl   155.61\n",
      "| epoch   5 |   900/ 2000 batches | lr 4.05 | ms/batch 14.16 | loss  5.07 | ppl   158.87\n",
      "| epoch   5 |  1200/ 2000 batches | lr 4.05 | ms/batch 25.73 | loss  5.12 | ppl   167.03\n",
      "| epoch   5 |  1500/ 2000 batches | lr 4.05 | ms/batch 14.72 | loss  5.27 | ppl   194.43\n",
      "| epoch   5 |  1800/ 2000 batches | lr 4.05 | ms/batch 14.60 | loss  5.07 | ppl   159.67\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 32.69s | valid loss  7.06 | valid ppl  1165.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   6 |   300/ 2000 batches | lr 4.05 | ms/batch 14.19 | loss  4.89 | ppl   133.58\n",
      "| epoch   6 |   600/ 2000 batches | lr 4.05 | ms/batch 14.13 | loss  4.65 | ppl   104.38\n",
      "| epoch   6 |   900/ 2000 batches | lr 4.05 | ms/batch 13.97 | loss  4.76 | ppl   116.26\n",
      "| epoch   6 |  1200/ 2000 batches | lr 4.05 | ms/batch 14.24 | loss  4.77 | ppl   117.53\n",
      "| epoch   6 |  1500/ 2000 batches | lr 4.05 | ms/batch 14.66 | loss  4.73 | ppl   112.85\n",
      "| epoch   6 |  1800/ 2000 batches | lr 4.05 | ms/batch 14.52 | loss  4.66 | ppl   106.15\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 29.10s | valid loss  6.16 | valid ppl   475.51\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   7 |   300/ 2000 batches | lr 3.65 | ms/batch 14.07 | loss  4.21 | ppl    67.51\n",
      "| epoch   7 |   600/ 2000 batches | lr 3.65 | ms/batch 14.13 | loss  3.86 | ppl    47.52\n",
      "| epoch   7 |   900/ 2000 batches | lr 3.65 | ms/batch 14.00 | loss  3.93 | ppl    50.75\n",
      "| epoch   7 |  1200/ 2000 batches | lr 3.65 | ms/batch 14.18 | loss  3.98 | ppl    53.58\n",
      "| epoch   7 |  1500/ 2000 batches | lr 3.65 | ms/batch 14.63 | loss  4.07 | ppl    58.31\n",
      "| epoch   7 |  1800/ 2000 batches | lr 3.65 | ms/batch 14.57 | loss  3.95 | ppl    52.01\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 29.05s | valid loss  5.20 | valid ppl   181.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   8 |   300/ 2000 batches | lr 3.65 | ms/batch 14.38 | loss  3.85 | ppl    46.81\n",
      "| epoch   8 |   600/ 2000 batches | lr 3.65 | ms/batch 14.08 | loss  3.61 | ppl    36.91\n",
      "| epoch   8 |   900/ 2000 batches | lr 3.65 | ms/batch 14.02 | loss  3.71 | ppl    40.81\n",
      "| epoch   8 |  1200/ 2000 batches | lr 3.65 | ms/batch 14.30 | loss  3.79 | ppl    44.23\n",
      "| epoch   8 |  1500/ 2000 batches | lr 3.65 | ms/batch 14.73 | loss  3.77 | ppl    43.43\n",
      "| epoch   8 |  1800/ 2000 batches | lr 3.65 | ms/batch 14.57 | loss  3.71 | ppl    40.79\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 29.21s | valid loss  4.92 | valid ppl   136.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   9 |   300/ 2000 batches | lr 3.28 | ms/batch 14.10 | loss  3.43 | ppl    30.91\n",
      "| epoch   9 |   600/ 2000 batches | lr 3.28 | ms/batch 14.19 | loss  3.27 | ppl    26.33\n",
      "| epoch   9 |   900/ 2000 batches | lr 3.28 | ms/batch 13.96 | loss  3.32 | ppl    27.60\n",
      "| epoch   9 |  1200/ 2000 batches | lr 3.28 | ms/batch 14.09 | loss  3.35 | ppl    28.54\n",
      "| epoch   9 |  1500/ 2000 batches | lr 3.28 | ms/batch 14.63 | loss  3.38 | ppl    29.45\n",
      "| epoch   9 |  1800/ 2000 batches | lr 3.28 | ms/batch 17.33 | loss  3.35 | ppl    28.54\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 29.83s | valid loss  4.54 | valid ppl    93.48\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  10 |   300/ 2000 batches | lr 3.28 | ms/batch 13.93 | loss  3.28 | ppl    26.53\n",
      "| epoch  10 |   600/ 2000 batches | lr 3.28 | ms/batch 14.21 | loss  3.16 | ppl    23.57\n",
      "| epoch  10 |   900/ 2000 batches | lr 3.28 | ms/batch 13.99 | loss  3.18 | ppl    23.93\n",
      "| epoch  10 |  1200/ 2000 batches | lr 3.28 | ms/batch 14.21 | loss  3.23 | ppl    25.38\n",
      "| epoch  10 |  1500/ 2000 batches | lr 3.28 | ms/batch 14.66 | loss  3.26 | ppl    26.08\n",
      "| epoch  10 |  1800/ 2000 batches | lr 3.28 | ms/batch 14.45 | loss  3.24 | ppl    25.48\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 29.02s | valid loss  4.22 | valid ppl    67.97\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "epochs = 10\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs ** (1 / 3)), gamma=0.9)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            try:\n",
    "                val_ppl = math.exp(val_loss)\n",
    "            except OverflowError:\n",
    "                val_ppl = float(\"inf\")\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (2048, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# The learnt model.neural_embedding should contain a permutation of the true neural embedding.\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A.T @ A)  # (input_size, input_size)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B.T @ B)  # (input_size, input_size)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG: @title Generate new data\n",
    "\n",
    "# max_new_tokens = 100\n",
    "# data = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "# mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0).to(DEVICE)\n",
    "# data_gen = model.generate(data, mask, max_new_tokens, top_k=None)\n",
    "\n",
    "# print(mask.shape, data.shape, data_gen.shape, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 302]) torch.Size([1, 180, 302]) torch.Size([1, 100, 302])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: @title Generate new data\n",
    "\n",
    "max_new_tokens = 100\n",
    "data, _, mask, _ = test_dataset[0]\n",
    "data, mask = data.unsqueeze(0).to(DEVICE), mask.unsqueeze(0).to(DEVICE)\n",
    "data_gen = model.generate(data, mask, max_new_tokens, top_k=None)\n",
    "\n",
    "print(mask.shape, data.shape, data_gen.shape, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @markdown We want to tokenize the neural data.\n",
    "# # An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# # We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# # First run a test on data for which we know what the true token output should be.\n",
    "# # This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "# with torch.no_grad():\n",
    "#     sequence = data\n",
    "#     inp_tokens = model.tokenize_neural_data(\n",
    "#         neural_sequence=sequence,\n",
    "#         feature_mask=mask,\n",
    "#         token_matrix=embedding.weight,\n",
    "#     )\n",
    "#     # iff correct these two should match\n",
    "#     print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")  # ground-truth tokens\n",
    "#     print(text_dataset[\"test\"][\"text\"][0], end=\"\\n\\n\")  # ground-truth text\n",
    "#     print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "#     print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 69, 104, 105, 114, 117, 104, 35, 122, 104, 35, 115, 117, 114, 102, 104, 104, 103, 35, 100, 113, 124, 35, 105, 120, 117, 119, 107, 104, 117, 47, 35, 107, 104, 100, 117, 35, 112, 104, 35, 118, 115, 104, 100, 110, 49, 35, 68, 111, 111, 61, 35, 86, 115, 104, 100, 110, 47, 35, 118, 115, 104, 100, 110, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 92, 114, 120, 35, 100, 117, 104, 35, 100, 111, 111, 35, 117, 104, 118, 114, 111, 121, 104, 103, 35, 117, 100, 119, 107, 104, 117, 35, 119, 114, 35, 103, 108, 104, 35, 119, 107, 100, 113, 35, 119, 114, 35, 105, 100, 112, 108, 118, 107, 66, 35, 68, 111, 111, 61, 35, 85, 104, 118, 114, 111, 121, 104, 103, 49, 35, 117, 104, 118, 114, 111, 121, 104, 103, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119]\n",
      "\n",
      "First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Cit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: @markdown We want to tokenize the neural data.\n",
    "# An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# First run a test on data for which we know what the true token output should be.\n",
    "# This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "with torch.no_grad():\n",
    "    sequence = data\n",
    "    inp_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 108, 35, 35, 108, 117, 120, 35, 105, 101, 119, 48, 35, 107, 101, 108, 104, 35, 105, 48, 35, 107, 35, 35, 108, 35, 108, 35, 107, 35, 114, 103, 35, 107, 35, 108, 35, 105, 101, 118, 42, 35, 47, 109, 118, 100, 35, 118, 100, 103, 92, 35, 105, 120, 35, 114, 103, 100, 66, 71, 85, 102, 35, 108, 35, 103, 35, 100, 103, 70, 80, 81, 61, 76, 76, 122, 100, 103, 100, 47, 48, 107, 122, 120, 119, 105, 117, 100, 35, 108, 61, 76, 35, 107, 35, 114, 49, 76, 106, 62]\n",
      "\n",
      " i  iru fbt- hbie f- h  i i h od h i fbs',jsa sadY fu oda?DRc i d adCMN:IIwada,-hwutfra i:I h o.Ig;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence = data_gen\n",
    "    gen_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(gen_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(gen_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DEBUG\n",
    "\n",
    "# all_unique_vectors = torch.vstack(train_dataset).unique(dim=0)\n",
    "# learned_unique_vectors = model.neural_embedding.unique(dim=0)\n",
    "# print(all_unique_vectors.shape, learned_unique_vectors.shape)\n",
    "# print()\n",
    "\n",
    "# all_unique_vectors = {tuple(row.round(decimals=3).cpu().numpy()) for row in all_unique_vectors}\n",
    "# learned_unique_vectors = {\n",
    "#     tuple(row.round(decimals=3).cpu().numpy()) for row in learned_unique_vectors\n",
    "# }\n",
    "# print(f\"There are {len(all_unique_vectors)} unique embeddings that generated the neural data.\")\n",
    "# print(\n",
    "#     f\"The model learned {len(learned_unique_vectors)} unique neural embeddings. But are they the same?\"\n",
    "# )\n",
    "# print()\n",
    "\n",
    "# inter = all_unique_vectors.intersection(learned_unique_vectors)\n",
    "# diff = all_unique_vectors - learned_unique_vectors\n",
    "# print(f\"Model learned to reproduce {len(inter)}/{len(all_unique_vectors)} embeddings exactly.\")\n",
    "# print(f\"The remaining {len(diff)}/{len(all_unique_vectors)} are superpositions of embeddings!\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal index: 0 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 1 \n",
      "neural: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([ 0.9639, -0.8171, -0.6944,  0.0560, -1.6250])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 2 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 3 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 4 \n",
      "neural: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([ 0.9639, -0.8171, -0.6944,  0.0560, -1.6250])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 5 \n",
      "neural: tensor([-0.6006,  2.3145, -0.0420,  1.6895, -0.0677], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.6006,  2.3145, -0.0420,  1.6895, -0.0677], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.6006,  2.3135, -0.0420,  1.6895, -0.0677])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 6 \n",
      "neural: tensor([ 0.1946, -0.5864,  0.2783,  0.6240, -0.4431], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 12 \n",
      "mapped: tensor([ 0.1946, -0.5864,  0.2783,  0.6240, -0.4431], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1946, -0.5862,  0.2782,  0.6241, -0.4432])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 7 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 8 \n",
      "neural: tensor([ 0.4438, -1.8770,  0.6064, -0.6040, -2.3184], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 10 \n",
      "mapped: tensor([ 0.4438, -1.8770,  0.6064, -0.6040, -2.3184], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4439, -1.8765,  0.6064, -0.6042, -2.3175])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 9 \n",
      "neural: tensor([ 0.2507, -0.2094, -1.2383,  1.2451,  2.1895], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.2507, -0.2094, -1.2383,  1.2451,  2.1895], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([ 0.2508, -0.2094, -1.2386,  1.2448,  2.1894])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 10 \n",
      "neural: tensor([ 0.2041, -0.6899, -0.2078,  0.9883, -0.0795], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([ 0.2041, -0.6899, -0.2078,  0.9883, -0.0795], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([ 0.2041, -0.6897, -0.2077,  0.9882, -0.0794])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 11 \n",
      "neural: tensor([-0.1382,  0.3293,  1.2861, -1.5166, -0.2211], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 53 \n",
      "mapped: tensor([-0.1382,  0.3293,  1.2861, -1.5166, -0.2211], device='cuda:0')\n",
      "\n",
      "embedding token: 48 \n",
      "character: - \n",
      "in train set: True \n",
      "embedded: tensor([-0.1382,  0.3293,  1.2863, -1.5165, -0.2211])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 12 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 13 \n",
      "neural: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 32 \n",
      "mapped: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0890,  0.4152,  0.9854, -1.0003,  1.0852])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 14 \n",
      "neural: tensor([ 0.2507, -0.2094, -1.2383,  1.2451,  2.1895], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.2507, -0.2094, -1.2383,  1.2451,  2.1895], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([ 0.2508, -0.2094, -1.2386,  1.2448,  2.1894])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 15 \n",
      "neural: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([ 0.9639, -0.8171, -0.6944,  0.0560, -1.6250])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 16 \n",
      "neural: tensor([ 0.1851, -1.5791,  1.2471, -0.6655, -1.3779], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 0.1851, -1.5791,  1.2471, -0.6655, -1.3779], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1851, -1.5791,  1.2474, -0.6655, -1.3784])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 17 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 18 \n",
      "neural: tensor([ 0.4438, -1.8770,  0.6064, -0.6040, -2.3184], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 10 \n",
      "mapped: tensor([ 0.4438, -1.8770,  0.6064, -0.6040, -2.3184], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4439, -1.8765,  0.6064, -0.6042, -2.3175])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 19 \n",
      "neural: tensor([-0.1382,  0.3293,  1.2861, -1.5166, -0.2211], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 53 \n",
      "mapped: tensor([-0.1382,  0.3293,  1.2861, -1.5166, -0.2211], device='cuda:0')\n",
      "\n",
      "embedding token: 48 \n",
      "character: - \n",
      "in train set: True \n",
      "embedded: tensor([-0.1382,  0.3293,  1.2863, -1.5165, -0.2211])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 20 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 21 \n",
      "neural: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 32 \n",
      "mapped: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0890,  0.4152,  0.9854, -1.0003,  1.0852])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 22 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 23 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 24 \n",
      "neural: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([ 0.9639, -0.8171, -0.6944,  0.0560, -1.6250])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 25 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 26 \n",
      "neural: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([ 0.9639, -0.8171, -0.6944,  0.0560, -1.6250])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 27 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 28 \n",
      "neural: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 32 \n",
      "mapped: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0890,  0.4152,  0.9854, -1.0003,  1.0852])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 29 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 30 \n",
      "neural: tensor([ 6.5625e-01, -4.2319e-04,  1.1768e+00, -1.2129e+00, -5.2197e-01],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([ 6.5625e-01, -4.2319e-04,  1.1768e+00, -1.2129e+00, -5.2197e-01],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([ 6.5608e-01, -4.2323e-04,  1.1769e+00, -1.2130e+00, -5.2215e-01])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 31 \n",
      "neural: tensor([0.3596, 1.0605, 0.0329, 0.0947, 2.5117], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 22 \n",
      "mapped: tensor([0.3596, 1.0605, 0.0329, 0.0947, 2.5117], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([0.3597, 1.0601, 0.0329, 0.0946, 2.5120])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 32 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 33 \n",
      "neural: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 32 \n",
      "mapped: tensor([ 0.0889,  0.4153,  0.9854, -1.0000,  1.0850], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0890,  0.4152,  0.9854, -1.0003,  1.0852])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 34 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 35 \n",
      "neural: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([ 0.9639, -0.8169, -0.6943,  0.0560, -1.6250], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([ 0.9639, -0.8171, -0.6944,  0.0560, -1.6250])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 36 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 37 \n",
      "neural: tensor([ 0.4438, -1.8770,  0.6064, -0.6040, -2.3184], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 10 \n",
      "mapped: tensor([ 0.4438, -1.8770,  0.6064, -0.6040, -2.3184], device='cuda:0')\n",
      "\n",
      "embedding token: 105 \n",
      "character: f \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4439, -1.8765,  0.6064, -0.6042, -2.3175])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 38 \n",
      "neural: tensor([ 0.2507, -0.2094, -1.2383,  1.2451,  2.1895], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.2507, -0.2094, -1.2383,  1.2451,  2.1895], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([ 0.2508, -0.2094, -1.2386,  1.2448,  2.1894])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 39 \n",
      "neural: tensor([ 0.2316,  1.0752,  0.0739, -0.5493, -2.2227], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([ 0.2316,  1.0752,  0.0739, -0.5493, -2.2227], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.2316,  1.0747,  0.0739, -0.5495, -2.2217])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 40 \n",
      "neural: tensor([-0.0670,  0.0662,  0.9238,  0.6016,  1.2617], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 30 \n",
      "mapped: tensor([-0.0670,  0.0662,  0.9238,  0.6016,  1.2617], device='cuda:0')\n",
      "\n",
      "embedding token: 42 \n",
      "character: ' \n",
      "in train set: True \n",
      "embedded: tensor([-0.0670,  0.0662,  0.9240,  0.6016,  1.2618])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 41 \n",
      "neural: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-2.1992, -0.3030, -1.2109,  0.1494, -0.4287], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-2.1994, -0.3031, -1.2113,  0.1494, -0.4288])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 42 \n",
      "neural: tensor([-0.3940,  1.0391,  0.0058, -0.0897, -1.2529], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([-0.3940,  1.0391,  0.0058, -0.0897, -1.2529], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([-0.3940,  1.0391,  0.0058, -0.0897, -1.2529])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 43 \n",
      "neural: tensor([-1.0635, -0.6665,  0.0815, -1.4189,  1.2285], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 59 \n",
      "mapped: tensor([-1.0635, -0.6665,  0.0815, -1.4189,  1.2285], device='cuda:0')\n",
      "\n",
      "embedding token: 109 \n",
      "character: j \n",
      "in train set: True \n",
      "embedded: tensor([-1.0635, -0.6663,  0.0815, -1.4194,  1.2284])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 44 \n",
      "neural: tensor([ 0.2316,  1.0752,  0.0739, -0.5493, -2.2227], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([ 0.2316,  1.0752,  0.0739, -0.5493, -2.2227], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([ 0.2316,  1.0747,  0.0739, -0.5495, -2.2217])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 45 \n",
      "neural: tensor([ 0.4910,  0.9121, -1.2910,  0.4529,  0.9561], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([ 0.4910,  0.9121, -1.2910,  0.4529,  0.9561], device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4910,  0.9123, -1.2912,  0.4529,  0.9559])\n",
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The learned embedding did not converge to the true embedding!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m et \u001b[38;5;129;01min\u001b[39;00m real_train_tokens:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(neural \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not learn to map a vector it was trained on!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(\n\u001b[1;32m     33\u001b[0m         embedded\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mhalf), mapped\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mhalf)\n\u001b[1;32m     34\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe learned embedding did not converge to the true embedding!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m99\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: The learned embedding did not converge to the true embedding!"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Assert should not be raised if the model learned to correctly map the tokens in the training set\n",
    "for idx in range(data_gen.shape[1]):\n",
    "    neural = data_gen[:, [idx], :]\n",
    "    print(\"temporal index:\", idx, \"\\nneural:\", neural.squeeze()[:5], end=\"\\n\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ct = model.tokenize_neural_data(neural).item()\n",
    "    mapped = model.neural_embedding[torch.tensor(ct, dtype=torch.long)]\n",
    "    print(\"model.neural_embedding token:\", ct, \"\\nmapped:\", mapped[:5], end=\"\\n\\n\")\n",
    "\n",
    "    assert torch.allclose(neural, mapped), \"Basic check failed; Inconsistency in mapping!\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        et = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    embedded = embedding(torch.tensor(et, dtype=torch.long))\n",
    "    print(\n",
    "        \"embedding token:\",\n",
    "        et,\n",
    "        \"\\ncharacter:\",\n",
    "        tokenizer.decode([et]),\n",
    "        \"\\nin train set:\",\n",
    "        et in real_train_tokens,\n",
    "        \"\\nembedded:\",\n",
    "        embedded[:5],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    if et in real_train_tokens:\n",
    "        assert torch.any(neural != 0), \"Model did not learn to map a vector it was trained on!\"\n",
    "        assert torch.allclose(\n",
    "            embedded.to(torch.half), mapped.cpu().to(torch.half)\n",
    "        ), \"The learned embedding did not converge to the true embedding!\"\n",
    "\n",
    "    print(\"~\" * 99, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
