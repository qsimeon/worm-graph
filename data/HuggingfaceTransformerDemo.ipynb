{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from CreateSyntheticDataset import tokenize_and_chunk  # works because of nbimporter\n",
    "from utils import DEVICE, BLOCK_SIZE, NUM_TOKENS, init_random_seeds\n",
    "\n",
    "# Initialize the random seeds\n",
    "init_random_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-large\")\n",
    "\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        # initrange = 0.1\n",
    "        # self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.embedding.weight.data.normal_()\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.normal_()\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create token datasets\n",
    "\n",
    "# train_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"train\"][\"input_ids\"]]\n",
    "train_dataset = [\n",
    "    torch.LongTensor(sequence[:-1])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"test\"][\"input_ids\"]]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Instantiate a TransformerModel\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Number of attn heads = {nhead}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler, criterion\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        tokens = train_dataset[batch].unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        input = tokens[:, :-1].to(DEVICE)  # ``[batch_size=1, seq_len]``\n",
    "        target = tokens[:, 1:].reshape(-1).to(DEVICE)  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            tokens = test_dataset[batch].unsqueeze(0)\n",
    "            input = tokens[:, :-1].to(DEVICE)\n",
    "            target = tokens[:, 1:].reshape(-1).to(DEVICE)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "epochs = 20\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs ** (1 / 3)), gamma=0.9)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            val_ppl = math.exp(val_loss)\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Generate new text\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=None)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 2072\n",
      "\n",
      "test_dataset: 109\n",
      "\n",
      "data:  torch.Size([1, 510, 302]) torch.float16 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create neural datasets\n",
    "# @markdown A synthetic dataset where the neural activity is the embeddings of tokens from tiny Shakespeare.\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding = torch.nn.Embedding(\n",
    "    num_embeddings=ntokens,\n",
    "    embedding_dim=emsize,\n",
    "    dtype=torch.half,\n",
    "    _freeze=True,\n",
    ")  # fixed embedding map\n",
    "torch.nn.init.normal_(embedding.weight)\n",
    "\n",
    "# Create datasets\n",
    "# train_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "# ]\n",
    "train_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "    for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "]\n",
    "print(f\"train_dataset: {len(train_dataset)}\", end=\"\\n\\n\")\n",
    "print(f\"test_dataset: {len(test_dataset)}\", end=\"\\n\\n\")\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 2000\n",
      "\n",
      "test_dataset: 200\n",
      "\n",
      "data:  torch.Size([1, 180, 302]) torch.float16 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG: @title Create neural datasets\n",
    "\n",
    "# Load the pre-saved Shakespeare neural dataset indetas\n",
    "\n",
    "from data._utils import load_dataset, create_combined_dataset, split_combined_dataset\n",
    "\n",
    "datasets = {\"Shakespeare0000\": \"all\"}  # a real worm neural dataset (all 1 worm)\n",
    "combined_dataset, dataset_info = create_combined_dataset(datasets, num_named_neurons=None)\n",
    "num_worms = len(combined_dataset)\n",
    "\n",
    "# Split the datsaet into train and validation halves\n",
    "num_train_samples = 10\n",
    "num_test_samples = 1\n",
    "reverse = use_residual = False\n",
    "smooth_data = True\n",
    "train_split_first = False\n",
    "train_split_ratio = 0.5\n",
    "seq_len = 180\n",
    "train_dataset, test_dataset, timestep_info = split_combined_dataset(\n",
    "    combined_dataset,\n",
    "    num_train_samples,\n",
    "    num_test_samples,\n",
    "    seq_len,\n",
    "    reverse,\n",
    "    use_residual,\n",
    "    smooth_data,\n",
    "    train_split_first,\n",
    "    train_split_ratio,\n",
    ")\n",
    "print(f\"train_dataset: {len(train_dataset)}\", end=\"\\n\\n\")\n",
    "print(f\"test_dataset: {len(test_dataset)}\", end=\"\\n\\n\")\n",
    "\n",
    "# get a test sample for an example\n",
    "input, target, mask, meta = test_dataset[0]\n",
    "\n",
    "data = input.unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = mask.unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 \t {35, 36, 39, 41, 42, 47, 48, 49, 54, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "\n",
      "59 \t {35, 36, 42, 47, 48, 49, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !',-.:;?ABCDEFGHIJKLMNOPRSTUVWYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# What tokens and their corresponding characters are in the train and test set\n",
    "real_train_tokens = set()\n",
    "for sequence in text_dataset[\"train\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_train_tokens.update(tokens)\n",
    "print(len(real_train_tokens), \"\\t\", real_train_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_train_tokens)))\n",
    "print(\"\\n\", \"~\" * 333, \"\\n\")\n",
    "\n",
    "real_test_tokens = set()\n",
    "for sequence in text_dataset[\"test\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_test_tokens.update(tokens)\n",
    "print(len(real_test_tokens), \"\\t\", real_test_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_test_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Model internal tokens = 2048\n",
      "Number of attn heads = 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/om2/user/qsimeon/miniconda3/envs/worm-graph/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(\n",
    "    input_size=emsize,\n",
    "    hidden_size=d_hid,\n",
    "    version_2=True,\n",
    "    num_tokens=NUM_TOKENS,\n",
    ").to(DEVICE)\n",
    "# NOTE: In reality we don't actually know the underlying vocabulary size (i.e. num_tokens) of the embedding table used to generated the neural data.\n",
    "\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Model internal tokens = {model.num_tokens}\")\n",
    "print(f\"Number of attn heads = {model.num_heads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 179, 302]) torch.float16 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 179, 302]) torch.float16 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 179, 2048]) torch.float16 False cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's input-output functionality\n",
    "\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(input, mask)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Test NeuralTransformer model's internal tokenizer\n",
    "\n",
    "# # The code below should only work when we cheat and set the neural_embedding to be exactky the embedding table that was used to generate the neural data.\n",
    "# # This is because the neural_embedding is initialized randomly. If the model has not been trained then there is no reason for its internal tokenizer to\n",
    "# # correctly invert the ground-truth embedding, which should be unknown to us. Thereforem the goal of our optimization is ultimately to learn the\n",
    "# # a neural_embedding that is as close as possible to the ground-truth but unknown embedding map.\n",
    "\n",
    "# if embedding.weight.shape == model.neural_embedding.shape:\n",
    "#     assert not torch.allclose(\n",
    "#         embedding.weight, model.neural_embedding.cpu()\n",
    "#     ), \"The neural_embedding should be different from the embedding map!\"\n",
    "\n",
    "# # Replace model neural_embedding with the embedding map use to generate the dataset\n",
    "# tmp = model.neural_embedding  # save for later restoration\n",
    "# model.neural_embedding = embedding.weight.to(DEVICE)  # let's cheat\n",
    "\n",
    "# if tmp.shape == model.neural_embedding.shape:\n",
    "#     assert not torch.allclose(\n",
    "#         tmp, model.neural_embedding\n",
    "#     ), \"Unexpected aliasing of tmp to model.neural_embedding!\"\n",
    "\n",
    "#     assert torch.allclose(\n",
    "#         embedding.weight, model.neural_embedding.cpu()\n",
    "#     ), \"The neural_embedding should be the same as the embedding map!\"\n",
    "\n",
    "# # Get some ground-truth test data\n",
    "# token_list = text_dataset[\"test\"][\"input_ids\"][0]\n",
    "# token_target = torch.LongTensor(token_list)\n",
    "# neural_target = torch.vstack([embedding(t) for t in token_target])\n",
    "\n",
    "# # Compare the tokenized and retokenized sequences when the neural_embedding is the true embedding map\n",
    "# with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "#     retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "# print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "# print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# # The tokenized and retokenized sequences should be the same\n",
    "# assert torch.allclose(\n",
    "#     token_target, retokenized_target\n",
    "# ), \"The tokenized and retokenized sequences should be the same!\"\n",
    "\n",
    "# # Restore the model neural_embedding to its original random initialization\n",
    "# model.neural_embedding = tmp\n",
    "\n",
    "# if embedding.weight.shape == model.neural_embedding.shape:\n",
    "#     assert not torch.allclose(embedding.weight, model.neural_embedding.cpu())\n",
    "\n",
    "# # Compare the tokenized and retokenized sequences when the neural_embedding is NOT the true embedding map\n",
    "# with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "#     retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "# print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "# print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# # The tokenized and retokenized sequences should NOT be the same\n",
    "# assert not torch.allclose(\n",
    "#     token_target, retokenized_target\n",
    "# ), \"The tokenized and retokenized sequences should NOT be the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "# def train(model: torch.nn.Module) -> None:\n",
    "#     model.train()  # turn on train mode\n",
    "#     total_loss = 0.0\n",
    "#     log_interval = 300\n",
    "#     start_time = time.time()\n",
    "#     global epoch, optimizer, scheduler\n",
    "\n",
    "#     num_batches = len(train_dataset)\n",
    "#     for batch in range(num_batches):\n",
    "#         data = train_dataset[batch].unsqueeze(0)\n",
    "#         mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "#         # parse into input and target\n",
    "#         mask = mask.to(DEVICE)\n",
    "#         input = data[:, :-1, :].to(DEVICE)\n",
    "#         target = data[:, 1:, :].to(DEVICE)\n",
    "#         # forward pass\n",
    "#         output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "#         # backpropagation step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = model.loss_fn()(\n",
    "#             output, target, mask\n",
    "#         )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "#         # check if the computed loss requires gradient\n",
    "#         if loss.requires_grad:\n",
    "#             loss.backward()\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "#             optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#         if batch % log_interval == 0 and batch > 0:\n",
    "#             lr = scheduler.get_last_lr()[0]\n",
    "#             ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "#             cur_loss = total_loss / log_interval\n",
    "#             try:\n",
    "#                 ppl = math.exp(cur_loss)\n",
    "#             except OverflowError:\n",
    "#                 ppl = float(\"inf\")\n",
    "#             print(\n",
    "#                 f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "#                 f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "#                 f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "#             )\n",
    "#             total_loss = 0\n",
    "#             start_time = time.time()\n",
    "\n",
    "\n",
    "# def evaluate(model: torch.nn.Module) -> float:\n",
    "#     model.eval()  # turn on evaluation mode\n",
    "#     total_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         num_batches = len(test_dataset)\n",
    "#         for batch in range(num_batches):\n",
    "#             data = test_dataset[batch].unsqueeze(0)\n",
    "#             mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "#             mask = mask.to(DEVICE)\n",
    "#             input = data[:, :-1, :].to(DEVICE)\n",
    "#             target = data[:, 1:, :].to(DEVICE)\n",
    "#             output = model(input, mask)\n",
    "#             loss = model.loss_fn()(output, target, mask)\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#     return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        input, target, mask, _ = train_dataset[batch]\n",
    "        input, target, mask = input.unsqueeze(0), target.unsqueeze(0), mask.unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = input[:, :-1, :].to(DEVICE)\n",
    "        target = target[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target, mask\n",
    "        )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            try:\n",
    "                ppl = math.exp(cur_loss)\n",
    "            except OverflowError:\n",
    "                ppl = float(\"inf\")\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            input, target, mask, _ = test_dataset[batch]\n",
    "            input, target, mask = input.unsqueeze(0), target.unsqueeze(0), mask.unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = input[:, :-1, :].to(DEVICE)\n",
    "            target = target[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (2048, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epoch(s)...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   300/ 2000 batches | lr 5.00 | ms/batch 11.58 | loss 90.01 | ppl 1238589261851577174535526823074453258240.00\n",
      "| epoch   1 |   600/ 2000 batches | lr 5.00 | ms/batch  8.05 | loss 35.96 | ppl 4158830985813375.50\n",
      "| epoch   1 |   900/ 2000 batches | lr 5.00 | ms/batch  8.97 | loss 26.43 | ppl 300213707601.32\n",
      "| epoch   1 |  1200/ 2000 batches | lr 5.00 | ms/batch  9.62 | loss 22.66 | ppl 6901468141.18\n",
      "| epoch   1 |  1500/ 2000 batches | lr 5.00 | ms/batch  5.92 | loss 19.86 | ppl 421101904.86\n",
      "| epoch   1 |  1800/ 2000 batches | lr 5.00 | ms/batch  5.43 | loss 17.84 | ppl 56176575.20\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 16.40s | valid loss 19.60 | valid ppl 324087285.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   2 |   300/ 2000 batches | lr 5.00 | ms/batch  5.46 | loss 14.76 | ppl 2582976.89\n",
      "| epoch   2 |   600/ 2000 batches | lr 5.00 | ms/batch  5.43 | loss 12.82 | ppl 369246.14\n",
      "| epoch   2 |   900/ 2000 batches | lr 5.00 | ms/batch  5.43 | loss 11.87 | ppl 143070.64\n",
      "| epoch   2 |  1200/ 2000 batches | lr 5.00 | ms/batch  5.43 | loss 11.35 | ppl 84963.24\n",
      "| epoch   2 |  1500/ 2000 batches | lr 5.00 | ms/batch  5.43 | loss 10.77 | ppl 47347.08\n",
      "| epoch   2 |  1800/ 2000 batches | lr 5.00 | ms/batch  5.45 | loss 10.21 | ppl 27128.32\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 11.32s | valid loss 12.99 | valid ppl 437874.45\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   3 |   300/ 2000 batches | lr 4.50 | ms/batch  5.52 | loss  8.50 | ppl  4927.14\n",
      "| epoch   3 |   600/ 2000 batches | lr 4.50 | ms/batch  5.94 | loss  7.84 | ppl  2534.56\n",
      "| epoch   3 |   900/ 2000 batches | lr 4.50 | ms/batch  5.81 | loss  7.62 | ppl  2038.43\n",
      "| epoch   3 |  1200/ 2000 batches | lr 4.50 | ms/batch  5.44 | loss  7.68 | ppl  2155.37\n",
      "| epoch   3 |  1500/ 2000 batches | lr 4.50 | ms/batch  5.51 | loss  7.56 | ppl  1923.37\n",
      "| epoch   3 |  1800/ 2000 batches | lr 4.50 | ms/batch  5.45 | loss  7.30 | ppl  1475.78\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 11.63s | valid loss  9.10 | valid ppl  8969.65\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   4 |   300/ 2000 batches | lr 4.50 | ms/batch  5.47 | loss  6.79 | ppl   886.11\n",
      "| epoch   4 |   600/ 2000 batches | lr 4.50 | ms/batch  5.44 | loss  6.46 | ppl   638.22\n",
      "| epoch   4 |   900/ 2000 batches | lr 4.50 | ms/batch  5.44 | loss  6.52 | ppl   677.09\n",
      "| epoch   4 |  1200/ 2000 batches | lr 4.50 | ms/batch  5.44 | loss  6.50 | ppl   664.89\n",
      "| epoch   4 |  1500/ 2000 batches | lr 4.50 | ms/batch  5.44 | loss  6.38 | ppl   587.99\n",
      "| epoch   4 |  1800/ 2000 batches | lr 4.50 | ms/batch  5.45 | loss  6.18 | ppl   482.78\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 11.33s | valid loss  8.46 | valid ppl  4741.56\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   5 |   300/ 2000 batches | lr 4.05 | ms/batch  5.47 | loss  5.67 | ppl   291.38\n",
      "| epoch   5 |   600/ 2000 batches | lr 4.05 | ms/batch  5.45 | loss  5.08 | ppl   161.44\n",
      "| epoch   5 |   900/ 2000 batches | lr 4.05 | ms/batch  5.57 | loss  5.12 | ppl   167.09\n",
      "| epoch   5 |  1200/ 2000 batches | lr 4.05 | ms/batch  5.50 | loss  5.15 | ppl   171.61\n",
      "| epoch   5 |  1500/ 2000 batches | lr 4.05 | ms/batch  5.44 | loss  5.17 | ppl   175.82\n",
      "| epoch   5 |  1800/ 2000 batches | lr 4.05 | ms/batch  5.45 | loss  5.01 | ppl   150.31\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 11.39s | valid loss  6.54 | valid ppl   689.14\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   6 |   300/ 2000 batches | lr 4.05 | ms/batch  5.47 | loss  4.80 | ppl   121.57\n",
      "| epoch   6 |   600/ 2000 batches | lr 4.05 | ms/batch  5.45 | loss  4.73 | ppl   113.19\n",
      "| epoch   6 |   900/ 2000 batches | lr 4.05 | ms/batch  8.31 | loss  4.58 | ppl    97.20\n",
      "| epoch   6 |  1200/ 2000 batches | lr 4.05 | ms/batch  5.93 | loss  4.65 | ppl   105.04\n",
      "| epoch   6 |  1500/ 2000 batches | lr 4.05 | ms/batch  5.50 | loss  4.80 | ppl   120.99\n",
      "| epoch   6 |  1800/ 2000 batches | lr 4.05 | ms/batch  5.54 | loss  4.57 | ppl    96.66\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 12.88s | valid loss  6.14 | valid ppl   465.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   7 |   300/ 2000 batches | lr 3.65 | ms/batch  9.41 | loss  4.14 | ppl    62.64\n",
      "| epoch   7 |   600/ 2000 batches | lr 3.65 | ms/batch  9.07 | loss  3.83 | ppl    46.13\n",
      "| epoch   7 |   900/ 2000 batches | lr 3.65 | ms/batch 14.33 | loss  3.87 | ppl    48.11\n",
      "| epoch   7 |  1200/ 2000 batches | lr 3.65 | ms/batch  9.85 | loss  3.94 | ppl    51.31\n",
      "| epoch   7 |  1500/ 2000 batches | lr 3.65 | ms/batch  7.22 | loss  4.00 | ppl    54.78\n",
      "| epoch   7 |  1800/ 2000 batches | lr 3.65 | ms/batch  5.65 | loss  3.94 | ppl    51.51\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 19.93s | valid loss  5.22 | valid ppl   184.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   8 |   300/ 2000 batches | lr 3.65 | ms/batch  9.95 | loss  3.79 | ppl    44.29\n",
      "| epoch   8 |   600/ 2000 batches | lr 3.65 | ms/batch 10.86 | loss  3.61 | ppl    36.89\n",
      "| epoch   8 |   900/ 2000 batches | lr 3.65 | ms/batch 10.30 | loss  3.63 | ppl    37.67\n",
      "| epoch   8 |  1200/ 2000 batches | lr 3.65 | ms/batch  6.48 | loss  3.69 | ppl    39.93\n",
      "| epoch   8 |  1500/ 2000 batches | lr 3.65 | ms/batch  5.43 | loss  3.70 | ppl    40.36\n",
      "| epoch   8 |  1800/ 2000 batches | lr 3.65 | ms/batch  5.43 | loss  3.64 | ppl    38.10\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 16.06s | valid loss  4.81 | valid ppl   122.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   9 |   300/ 2000 batches | lr 3.28 | ms/batch  5.47 | loss  3.41 | ppl    30.38\n",
      "| epoch   9 |   600/ 2000 batches | lr 3.28 | ms/batch  5.45 | loss  3.22 | ppl    25.09\n",
      "| epoch   9 |   900/ 2000 batches | lr 3.28 | ms/batch  5.44 | loss  3.27 | ppl    26.21\n",
      "| epoch   9 |  1200/ 2000 batches | lr 3.28 | ms/batch  5.43 | loss  3.34 | ppl    28.09\n",
      "| epoch   9 |  1500/ 2000 batches | lr 3.28 | ms/batch  5.44 | loss  3.34 | ppl    28.32\n",
      "| epoch   9 |  1800/ 2000 batches | lr 3.28 | ms/batch  5.44 | loss  3.34 | ppl    28.22\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 11.33s | valid loss  4.28 | valid ppl    72.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  10 |   300/ 2000 batches | lr 3.28 | ms/batch  5.49 | loss  3.29 | ppl    26.85\n",
      "| epoch  10 |   600/ 2000 batches | lr 3.28 | ms/batch  5.44 | loss  3.11 | ppl    22.46\n",
      "| epoch  10 |   900/ 2000 batches | lr 3.28 | ms/batch  5.44 | loss  3.17 | ppl    23.73\n",
      "| epoch  10 |  1200/ 2000 batches | lr 3.28 | ms/batch  5.64 | loss  3.21 | ppl    24.89\n",
      "| epoch  10 |  1500/ 2000 batches | lr 3.28 | ms/batch  5.44 | loss  3.19 | ppl    24.24\n",
      "| epoch  10 |  1800/ 2000 batches | lr 3.28 | ms/batch  5.45 | loss  3.23 | ppl    25.29\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 11.40s | valid loss  4.19 | valid ppl    65.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "epochs = 20\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs ** (1 / 3)), gamma=0.9)\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            try:\n",
    "                val_ppl = math.exp(val_loss)\n",
    "            except OverflowError:\n",
    "                val_ppl = float(\"inf\")\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (2048, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# The learnt model.neural_embedding should contain a permutation of the true neural embedding.\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A.T @ A)  # (input_size, input_size)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B.T @ B)  # (input_size, input_size)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 302]) torch.Size([1, 180, 302]) torch.Size([1, 100, 302])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # @title Generate new data\n",
    "\n",
    "max_new_tokens = 100\n",
    "data, mask = data.to(DEVICE), mask.to(DEVICE)\n",
    "data_gen = model.generate(data, mask, max_new_tokens, top_k=None)\n",
    "\n",
    "print(mask.shape, data.shape, data_gen.shape, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120, 1]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "[228, 15, 28, 234, 73, 120, 153, 15, 73, 15, 146, 96, 135, 105, 120, 3, 96, 113, 104, 28, 96, 120, 228, 96, 120, 25, 28, 104, 252, 96, 96, 214, 120, 234, 135, 252, 120, 113, 215, 28, 73, 252, 96, 28, 172, 120, 252, 96, 234, 28, 120, 96, 96, 120, 234, 25, 96, 234, 35, 92, 120, 63, 188, 188, 105, 120, 64, 25, 96, 234, 35, 172, 120, 234, 25, 96, 234, 35, 92, 120, 228, 15, 28, 234, 73, 120, 153, 15, 73, 15, 146, 96, 135, 105, 120, 11, 104, 215, 120, 234, 28, 96, 120, 234, 188, 188, 120, 28, 96, 234, 104, 188, 105, 96, 214, 120, 28, 234, 73, 252, 96, 28, 120, 73, 104, 120, 214, 15, 96, 120, 73, 252, 234, 135, 120, 73, 104, 120, 113, 234, 96, 15, 234, 252, 160, 120, 63, 188, 188, 105, 120, 46, 96, 234, 104, 188, 105, 96, 214, 92, 120, 28, 96, 234, 104, 188, 105, 96, 214, 92, 120, 228, 15, 28, 234, 73, 120, 153, 15, 73]\n",
      "\n",
      "\f\u0019Fu\fF\f]fu\u0000]ne\u0019]u]u\u0016\u0019e]]uun\u0019F]\u0019u]\u0019u]]u\u0016] Yu<fu=\u0016] u\u0016] Yu\f\u0019Fu\fF\f]feu\u0019]uç¹¹u\u0019]ef]u\u0019F]\u0019uFeu\f]uFuFeun]\fu<fu+]ef]Yu\u0019]ef]Yu\f\u0019Fu\fF\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown We want to tokenize the neural data.\n",
    "# An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# First run a test on data for which we know what the true token output should be.\n",
    "# This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "with torch.no_grad():\n",
    "    sequence = data\n",
    "    inp_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    # iff correct these two should match\n",
    "    print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")  # ground-truth tokens\n",
    "    print(text_dataset[\"test\"][\"text\"][0], end=\"\\n\\n\")  # ground-truth text\n",
    "    print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120, 73, 228, 73, 215, 214, 120, 15, 120, 252, 120, 172, 228, 73, 234, 214, 120, 120, 135, 252, 120, 15, 252, 252, 15, 120, 15, 28, 234, 214, 214, 96, 252, 234, 120, 135, 234, 228, 73, 234, 73, 104, 234, 120, 73, 234, 120, 15, 113, 73, 15, 73, 73, 234, 73, 234, 120, 234, 234, 73, 252, 104, 28, 120, 96, 73, 104, 214, 120, 135, 120, 25, 73, 77, 120, 252, 120, 15, 120, 252, 104, 73, 104, 73, 252, 252, 104, 113, 73, 104, 96, 96, 73, 28, 135, 234, 234, 234, 214, 234]\n",
      "\n",
      "uFFu\fuuFuuu\f\fu\f\u0019]uFFeuFu\fnF\fFFFuFe\u0019u]Feuu\u0016FJuu\fueFeFenFe]]F\u0019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence = data_gen\n",
    "    gen_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(gen_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(gen_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "vstack(): argument 'tensors' (position 1) must be tuple of Tensors, not ConcatDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DEBUG\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m all_unique_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munique(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m learned_unique_vectors \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mneural_embedding\u001b[38;5;241m.\u001b[39munique(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_unique_vectors\u001b[38;5;241m.\u001b[39mshape, learned_unique_vectors\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: vstack(): argument 'tensors' (position 1) must be tuple of Tensors, not ConcatDataset"
     ]
    }
   ],
   "source": [
    "# # DEBUG\n",
    "\n",
    "# all_unique_vectors = torch.vstack(train_dataset).unique(dim=0)\n",
    "# learned_unique_vectors = model.neural_embedding.unique(dim=0)\n",
    "# print(all_unique_vectors.shape, learned_unique_vectors.shape)\n",
    "# print()\n",
    "\n",
    "# all_unique_vectors = {tuple(row.round(decimals=3).cpu().numpy()) for row in all_unique_vectors}\n",
    "# learned_unique_vectors = {\n",
    "#     tuple(row.round(decimals=3).cpu().numpy()) for row in learned_unique_vectors\n",
    "# }\n",
    "# print(f\"There are {len(all_unique_vectors)} unique embeddings that generated the neural data.\")\n",
    "# print(\n",
    "#     f\"The model learned {len(learned_unique_vectors)} unique neural embeddings. But are they the same?\"\n",
    "# )\n",
    "# print()\n",
    "\n",
    "# inter = all_unique_vectors.intersection(learned_unique_vectors)\n",
    "# diff = all_unique_vectors - learned_unique_vectors\n",
    "# print(f\"Model learned to reproduce {len(inter)}/{len(all_unique_vectors)} embeddings exactly.\")\n",
    "# print(f\"The remaining {len(diff)}/{len(all_unique_vectors)} are superpositions of embeddings!\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal index: 0 \n",
      "neural: tensor([-0.2500, -0.4995, -0.7808,  0.3044, -1.8057], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.2500, -0.4995, -0.7808,  0.3044, -1.8057], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.7109, -0.5459, -0.1017,  1.1367, -1.6426], dtype=torch.float16)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Half did not match Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m et \u001b[38;5;129;01min\u001b[39;00m real_train_tokens:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39many(neural \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel did not learn to map a vector it was trained on!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallclose\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe learned embedding did not converge to the true embedding!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m99\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Half did not match Float"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Assert should not be raised if the model learned to correctly map the tokens in the training set\n",
    "for idx in range(data_gen.shape[1]):\n",
    "    neural = data_gen[:, [idx], :]\n",
    "    print(\"temporal index:\", idx, \"\\nneural:\", neural.squeeze()[:5], end=\"\\n\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ct = model.tokenize_neural_data(neural).item()\n",
    "    mapped = model.neural_embedding[torch.tensor(ct, dtype=torch.long)]\n",
    "    print(\"model.neural_embedding token:\", ct, \"\\nmapped:\", mapped[:5], end=\"\\n\\n\")\n",
    "\n",
    "    assert torch.allclose(neural, mapped), \"Basic check failed; Inconsistency in mapping!\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        et = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    embedded = embedding(torch.tensor(et, dtype=torch.long))\n",
    "    print(\n",
    "        \"embedding token:\",\n",
    "        et,\n",
    "        \"\\ncharacter:\",\n",
    "        tokenizer.decode([et]),\n",
    "        \"\\nin train set:\",\n",
    "        et in real_train_tokens,\n",
    "        \"\\nembedded:\",\n",
    "        embedded[:5],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    if et in real_train_tokens:\n",
    "        assert torch.any(neural != 0), \"Model did not learn to map a vector it was trained on!\"\n",
    "        assert torch.allclose(\n",
    "            embedded, mapped.cpu()\n",
    "        ), \"The learned embedding did not converge to the true embedding!\"\n",
    "\n",
    "    print(\"~\" * 99, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
