{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import nbimporter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from tempfile import TemporaryDirectory\n",
    "from models._utils import NeuralTransformer\n",
    "from datasets import load_dataset as load_hf_dataset\n",
    "from CreateSyntheticDataset import tokenize_and_chunk  # works because of nbimporter\n",
    "from utils import DEVICE, BLOCK_SIZE, NUM_TOKENS, init_random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "\n",
    "init_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language modeling with tiny Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling `tokenizer.encode(text)`:\n",
      "\ttext: Welcome to the ðŸ¤— Tokenizers library.\n",
      "\ttokenized: [90, 104, 111, 102, 114, 112, 104, 35, 119, 114, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 114, 110, 104, 113, 108, 125, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: Welcome to the ðŸ¤— Tokenizers library.</s>\n",
      "\n",
      "Calling `tokenizer(text)`:\n",
      "\tobject.keys(): dict_keys(['input_ids', 'attention_mask'])\n",
      "\ttext: We are very happy to show you the ðŸ¤— Transformers library.\n",
      "\ttokenized: [90, 104, 35, 100, 117, 104, 35, 121, 104, 117, 124, 35, 107, 100, 115, 115, 124, 35, 119, 114, 35, 118, 107, 114, 122, 35, 124, 114, 120, 35, 119, 107, 104, 35, 243, 162, 167, 154, 35, 87, 117, 100, 113, 118, 105, 114, 117, 112, 104, 117, 118, 35, 111, 108, 101, 117, 100, 117, 124, 49, 1]\n",
      "\tdecoded: We are very happy to show you the ðŸ¤— Transformers library.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Tokenizers\n",
    "# @markdown Note there are two ways to call the tokenizer's encoder.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-large\")\n",
    "\n",
    "expl_text = \"Welcome to the ðŸ¤— Tokenizers library.\"\n",
    "impl_text = \"We are very happy to show you the ðŸ¤— Transformers library.\"\n",
    "expl_encode = tokenizer.encode(expl_text)\n",
    "impl_encode = tokenizer(impl_text)\n",
    "print(\n",
    "    f\"Calling `tokenizer.encode(text)`:\\n\\ttext: {expl_text}\\n\\ttokenized: {expl_encode}\\n\\tdecoded: {tokenizer.decode(expl_encode)}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Calling `tokenizer(text)`:\\n\\tobject.keys(): {impl_encode.keys()}\\n\\ttext: {impl_text}\\n\\ttokenized: {impl_encode['input_ids']}\\n\\tdecoded: {tokenizer.decode(impl_encode['input_ids'])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "train: <class 'list'> 1 <class 'str'> 1003854\n",
      "\n",
      "validation: <class 'list'> 1 <class 'str'> 55770\n",
      "\n",
      "test: <class 'list'> 1 <class 'str'> 55770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title HuggingFace Datasets\n",
    "\n",
    "text_dataset = load_hf_dataset(\"tiny_shakespeare\")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"train:\",\n",
    "    type(text_dataset[\"train\"][\"text\"]),\n",
    "    len(text_dataset[\"train\"][\"text\"]),\n",
    "    type(text_dataset[\"train\"][\"text\"][0]),\n",
    "    len(text_dataset[\"train\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"validation:\",\n",
    "    type(text_dataset[\"validation\"][\"text\"]),\n",
    "    len(text_dataset[\"validation\"][\"text\"]),\n",
    "    type(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    len(text_dataset[\"validation\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"test:\",\n",
    "    type(text_dataset[\"test\"][\"text\"]),\n",
    "    len(text_dataset[\"test\"][\"text\"]),\n",
    "    type(text_dataset[\"test\"][\"text\"][0]),\n",
    "    len(text_dataset[\"test\"][\"text\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1963\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 109\n",
      "    })\n",
      "})\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "text_dataset['train']['input_ids']:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 1963\n",
      "\n",
      "text_dataset['train']['input_ids'][0]:\n",
      " \ttype: <class 'list'> \n",
      "\tlength: 506\n",
      "\n",
      "text_dataset['train']['input_ids'][0][0]:\n",
      " \ttype: <class 'int'> \n",
      "\tvalue: 73\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Original sequence (text):\n",
      "\tFirst Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the\n",
      "\n",
      "Encoded sequence (tokens):\n",
      "\t [73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 69, 104, 105, 114, 117, 104, 35, 122, 104, 35, 115, 117, 114, 102, 104, 104, 103, 35, 100, 113, 124, 35, 105, 120, 117, 119, 107, 104, 117, 47, 35, 107, 104, 100, 117, 35, 112, 104, 35, 118, 115, 104, 100, 110, 49, 35, 68, 111, 111, 61, 35, 86, 115, 104, 100, 110, 47, 35, 118, 115, 104, 100, 110, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 92, 114, 120, 35, 100, 117, 104, 35, 100, 111, 111, 35, 117, 104, 118, 114, 111, 121, 104, 103, 35, 117, 100, 119, 107, 104, 117, 35, 119, 114, 35, 103, 108, 104, 35, 119, 107, 100, 113, 35, 119, 114, 35, 105, 100, 112, 108, 118, 107, 66, 35, 68, 111, 111, 61, 35, 85, 104, 118, 114, 111, 121, 104, 103, 49, 35, 117, 104, 118, 114, 111, 121, 104, 103, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 73, 108, 117, 118, 119, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 35, 70, 100, 108, 120, 118, 35, 80, 100, 117, 102, 108, 120, 118, 35, 108, 118, 35, 102, 107, 108, 104, 105, 35, 104, 113, 104, 112, 124, 35, 119, 114, 35, 119, 107, 104, 35, 115, 104, 114, 115, 111, 104, 49, 35, 68, 111, 111, 61, 35, 90, 104, 35, 110, 113, 114, 122, 42, 119, 47, 35, 122, 104, 35, 110, 113, 114, 122, 42, 119, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 79, 104, 119, 35, 120, 118, 35, 110, 108, 111, 111, 35, 107, 108, 112, 47, 35, 100, 113, 103, 35, 122, 104, 42, 111, 111, 35, 107, 100, 121, 104, 35, 102, 114, 117, 113, 35, 100, 119, 35, 114, 120, 117, 35, 114, 122, 113, 35, 115, 117, 108, 102, 104, 49, 35, 76, 118, 42, 119, 35, 100, 35, 121, 104, 117, 103, 108, 102, 119, 66, 35, 68, 111, 111, 61, 35, 81, 114, 35, 112, 114, 117, 104, 35, 119, 100, 111, 110, 108, 113, 106, 35, 114, 113, 42, 119, 62, 35, 111, 104, 119, 35, 108, 119, 35, 101, 104, 35, 103, 114, 113, 104, 61, 35, 100, 122, 100, 124, 47, 35, 100, 122, 100, 124, 36, 35, 86, 104, 102, 114, 113, 103, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 82, 113, 104, 35, 122, 114, 117, 103, 47, 35, 106, 114, 114, 103, 35, 102, 108, 119, 108, 125, 104, 113, 118, 49, 35, 73, 108, 117, 118, 119, 35, 70, 108, 119, 108, 125, 104, 113, 61, 35, 90, 104, 35, 100, 117, 104, 35, 100, 102, 102, 114, 120, 113, 119, 104, 103, 35, 115, 114, 114, 117, 35, 102, 108, 119, 108, 125, 104, 113, 118, 47, 35, 119, 107, 104, 1]\n",
      "\n",
      "Decoded sequence (tokens):\n",
      "\t First Citizen: Before we proceed any further, hear me speak. All: Speak, speak. First Citizen: You are all resolved rather to die than to famish? All: Resolved. resolved. First Citizen: First, you know Caius Marcius is chief enemy to the people. All: We know't, we know't. First Citizen: Let us kill him, and we'll have corn at our own price. Is't a verdict? All: No more talking on't; let it be done: away, away! Second Citizen: One word, good citizens. First Citizen: We are accounted poor citizens, the</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Tokenization and Chunking\n",
    "# @markdown Apply the tokenization and chunking to each split.\n",
    "\n",
    "text_dataset = text_dataset.map(\n",
    "    tokenize_and_chunk, batched=True, fn_kwargs=dict(tokenizer=tokenizer)\n",
    ")\n",
    "print(text_dataset, end=\"\\n\\n\")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids']:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    \"\\n\\tlength:\",\n",
    "    len(text_dataset[\"train\"][\"input_ids\"][0]),\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"text_dataset['train']['input_ids'][0][0]:\\n\",\n",
    "    \"\\ttype:\",\n",
    "    type(text_dataset[\"train\"][\"input_ids\"][0][0]),\n",
    "    \"\\n\\tvalue:\",\n",
    "    text_dataset[\"train\"][\"input_ids\"][0][0],\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\"~~~\" * 50, end=\"\\n\\n\")\n",
    "\n",
    "print(f\"Original sequence (text):\\n\\t{text_dataset['train']['text'][0]}\", end=\"\\n\\n\")\n",
    "print(\n",
    "    f\"Encoded sequence (tokens):\\n\\t {text_dataset['train']['input_ids'][0]}\",\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    f\"Decoded sequence (tokens):\\n\\t {tokenizer.decode(text_dataset['train']['input_ids'][0])}\",\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define the Transformer model\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)  # batch_first=True\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ntoken: int,\n",
    "        d_model: int,\n",
    "        nhead: int,\n",
    "        d_hid: int,\n",
    "        nlayers: int,\n",
    "        dropout: float = 0.5,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.d_model = d_model\n",
    "        self.embedding = torch.nn.Embedding(ntoken, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(\n",
    "            d_model, nhead, d_hid, dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.linear = torch.nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape [batch_size, seq_len]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [batch_size, seq_len, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            src_mask = torch.nn.Transformer.generate_square_subsequent_mask(\n",
    "                src.size(1)  # Use src.size(1) to get the seq_len\n",
    "            ).to(\n",
    "                src.device\n",
    "            )  # Use src.device to match device of src\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(\n",
    "        self,\n",
    "        idx: torch.LongTensor,\n",
    "        max_new_tokens: int,\n",
    "        temperature=1.0,\n",
    "        top_k=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Special generate method for the Transformer model.\n",
    "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "        Since we trained the model to directly predict the next token we take the index as the argmin\n",
    "        over the distance between the output and the embedding table.\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        # Loop through time\n",
    "        for _ in range(max_new_tokens):\n",
    "            # if the sequence context is growing too long we must crop it at block_size\n",
    "            idx_cond = idx if idx.size(1) <= BLOCK_SIZE else idx[:, -BLOCK_SIZE:]\n",
    "            # forward the model to get the output\n",
    "            outputs = self(idx_cond)\n",
    "            # pluck the logits at the final step and scale by desired temperature\n",
    "            logits = outputs[:, -1, :] / temperature\n",
    "            # optionally crop the logits to only the top k options\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float(\"Inf\")\n",
    "            # apply softmax to convert logits to (normalized) probabilities\n",
    "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1).view(1, 1)\n",
    "            # append sampled index to the running sequence and continue\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 510]) torch.int64 False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create token datasets\n",
    "\n",
    "# train_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"train\"][\"input_ids\"]]\n",
    "train_dataset = [\n",
    "    torch.LongTensor(sequence[:-1])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [torch.LongTensor(sequence[:-1]) for sequence in text_dataset[\"test\"][\"input_ids\"]]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Number of attn heads = 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a TransformerModel\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 1  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention (NOTE: nhead must be a divisor of d_hid)\n",
    "dropout = 0.1  # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(DEVICE)\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Number of attn heads = {nhead}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the Transformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler, criterion\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        tokens = train_dataset[batch].unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        input = tokens[:, :-1].to(DEVICE)  # ``[batch_size=1, seq_len]``\n",
    "        target = tokens[:, 1:].reshape(-1).to(DEVICE)  # ``[batch_size=1 * seq_len]``\n",
    "        # forward pass\n",
    "        output = model(input)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        output_flat = output.view(-1, ntokens)  # ``[batch_size=1 * seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output_flat, target)\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            tokens = test_dataset[batch].unsqueeze(0)\n",
    "            input = tokens[:, :-1].to(DEVICE)\n",
    "            target = tokens[:, 1:].reshape(-1).to(DEVICE)\n",
    "            output = model(input)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += criterion(output_flat, target).item()\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a previously saved model checkpoint...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous validation loss: \t  2.58\n",
      "\n",
      "Training for 1 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 2072 batches | lr 5.00 | ms/batch 34.68 | loss  2.49 | ppl    12.01\n",
      "| epoch   1 |   600/ 2072 batches | lr 5.00 | ms/batch 36.82 | loss  2.50 | ppl    12.24\n",
      "| epoch   1 |   900/ 2072 batches | lr 5.00 | ms/batch 45.90 | loss  2.53 | ppl    12.58\n",
      "| epoch   1 |  1200/ 2072 batches | lr 5.00 | ms/batch 35.25 | loss  2.51 | ppl    12.30\n",
      "| epoch   1 |  1500/ 2072 batches | lr 5.00 | ms/batch 36.32 | loss  2.50 | ppl    12.20\n",
      "| epoch   1 |  1800/ 2072 batches | lr 5.00 | ms/batch 34.70 | loss  2.48 | ppl    11.92\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 70.89s | valid loss  2.58 | valid ppl    13.17\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # loss function\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 5\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"shakespeare_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            val_ppl = math.exp(val_loss)\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 509]) torch.Size([1, 609])\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, Yo\n",
      "\n",
      " tlll pl hos m. s Buitasauce, Wh, Mim wil d, thlf thilousy cu s cis s mthre win m Tavereea masuke. a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new text\n",
    "\n",
    "max_new_tokens = 100\n",
    "idx = test_dataset[0][:-1].unsqueeze(0).to(DEVICE)\n",
    "idx_gen = model.generate(idx, max_new_tokens, top_k=None)\n",
    "\n",
    "print(idx.shape, idx_gen.shape, end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx.tolist()[0]), end=\"\\n\\n\")\n",
    "print(tokenizer.decode(idx_gen.tolist()[0][-max_new_tokens:]), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  torch.Size([1, 510, 302]) torch.float32 False cpu\n",
      "\n",
      "mask: torch.Size([1, 302]) torch.bool False cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Create neural datasets\n",
    "# @markdown A synthetic dataset where the neural activity is the embeddings of tokens from tiny Shakespeare.\n",
    "\n",
    "ntokens = tokenizer.vocab_size\n",
    "emsize = 302\n",
    "d_hid = 512\n",
    "embedding = torch.nn.Embedding(ntokens, emsize, _freeze=True)  # fixed embedding map\n",
    "\n",
    "# Create datasets\n",
    "# train_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"train\"][\"input_ids\"]\n",
    "# ]\n",
    "train_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "    for sequence in text_dataset[\"train\"][\"input_ids\"] + text_dataset[\"validation\"][\"input_ids\"]\n",
    "]\n",
    "# validation_dataset = [\n",
    "#     torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "#     for sequence in text_dataset[\"validation\"][\"input_ids\"]\n",
    "# ]\n",
    "test_dataset = [\n",
    "    torch.vstack([embedding(token) for token in torch.LongTensor(sequence[:-1])])\n",
    "    for sequence in text_dataset[\"test\"][\"input_ids\"]\n",
    "]\n",
    "\n",
    "# get a test sample for an example\n",
    "data = test_dataset[0].unsqueeze(0)\n",
    "print(\"data: \", data.shape, data.dtype, data.requires_grad, data.device, end=\"\\n\\n\")\n",
    "\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "print(\"mask:\", mask.shape, mask.dtype, mask.requires_grad, mask.device, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 \t {35, 36, 39, 41, 42, 47, 48, 49, 54, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "\n",
      " ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "\n",
      "59 \t {35, 36, 42, 47, 48, 49, 61, 62, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125}\n",
      "\t !',-.:;?ABCDEFGHIJKLMNOPRSTUVWYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# What tokens and their corresponding characters are in the train and test set\n",
    "real_train_tokens = set()\n",
    "for sequence in text_dataset[\"train\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_train_tokens.update(tokens)\n",
    "print(len(real_train_tokens), \"\\t\", real_train_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_train_tokens)))\n",
    "print(\"\\n\", \"~\" * 333, \"\\n\")\n",
    "\n",
    "real_test_tokens = set()\n",
    "for sequence in text_dataset[\"test\"][\"input_ids\"]:\n",
    "    tokens = set(sequence[:-1])\n",
    "    real_test_tokens.update(tokens)\n",
    "print(len(real_test_tokens), \"\\t\", real_test_tokens)\n",
    "print(\"\\t\", tokenizer.decode(list(real_test_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size (i.e. num tokens) = 256\n",
      "Model internal tokens = 4096\n",
      "Number of attn heads = 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Instantiate a NeuralTransformer model\n",
    "\n",
    "model = NeuralTransformer(\n",
    "    input_size=emsize,\n",
    "    hidden_size=d_hid,\n",
    "    version_2=True,\n",
    "    num_tokens=NUM_TOKENS,\n",
    ").to(DEVICE)\n",
    "# NOTE: In reality we don't actually know the underlying vocabulary size (i.e. num_tokens) of the embedding table used to generated the neural data.\n",
    "\n",
    "print(f\"Vocab size (i.e. num tokens) = {ntokens}\")\n",
    "print(f\"Model internal tokens = {model.num_tokens}\")\n",
    "print(f\"Number of attn heads = {model.num_heads}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: torch.Size([1, 509, 302]) torch.float32 False cuda:0\n",
      "\n",
      "target: torch.Size([1, 509, 302]) torch.float32 False cuda:0\n",
      "\n",
      "output: torch.Size([1, 509, 4096]) torch.float16 False cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's input-output functionality\n",
    "\n",
    "mask = mask.to(DEVICE)\n",
    "input = data[:, :-1, :].to(DEVICE)\n",
    "target = data[:, 1:, :].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    output = model(input, mask)\n",
    "\n",
    "\n",
    "print(\n",
    "    \"input:\",\n",
    "    input.shape,\n",
    "    input.dtype,\n",
    "    input.requires_grad,\n",
    "    input.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"target:\",\n",
    "    target.shape,\n",
    "    target.dtype,\n",
    "    target.requires_grad,\n",
    "    target.device,\n",
    "    end=\"\\n\\n\",\n",
    ")\n",
    "print(\n",
    "    \"output:\",\n",
    "    output.shape,\n",
    "    output.dtype,\n",
    "    output.requires_grad,\n",
    "    output.device,\n",
    "    end=\"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([117, 100, 113, 102, 104])\n",
      "\n",
      "<class 'list'> torch.Size([511, 302]) torch.Size([511]) torch.Size([511])\n",
      "\t tensor([117, 100, 113, 102, 104]) tensor([0, 0, 0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Test NeuralTransformer model's internal tokenizer\n",
    "\n",
    "# The code below should only work when we cheat and set the neural_embedding to be exactky the embedding table that was used to generate the neural data.\n",
    "# This is because the neural_embedding is initialized randomly. If the model has not been trained then there is no reason for its internal tokenizer to\n",
    "# correctly invert the ground-truth embedding, which should be unknown to us. Thereforem the goal of our optimization is ultimately to learn the\n",
    "# a neural_embedding that is as close as possible to the ground-truth but unknown embedding map.\n",
    "\n",
    "if embedding.weight.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(\n",
    "        embedding.weight, model.neural_embedding.cpu()\n",
    "    ), \"The neural_embedding should be different from the embedding map!\"\n",
    "\n",
    "# Replace model neural_embedding with the embedding map use to generate the dataset\n",
    "tmp = model.neural_embedding  # save for later restoration\n",
    "model.neural_embedding = embedding.weight.to(DEVICE)  # let's cheat\n",
    "\n",
    "if tmp.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(\n",
    "        tmp, model.neural_embedding\n",
    "    ), \"Unexpected aliasing of tmp to model.neural_embedding!\"\n",
    "\n",
    "    assert torch.allclose(\n",
    "        embedding.weight, model.neural_embedding.cpu()\n",
    "    ), \"The neural_embedding should be the same as the embedding map!\"\n",
    "\n",
    "# Get some ground-truth test data\n",
    "token_list = text_dataset[\"test\"][\"input_ids\"][0]\n",
    "token_target = torch.LongTensor(token_list)\n",
    "neural_target = torch.vstack([embedding(t) for t in token_target])\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the neural_embedding is the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should be the same\n",
    "assert torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should be the same!\"\n",
    "\n",
    "# Restore the model neural_embedding to its original random initialization\n",
    "model.neural_embedding = tmp\n",
    "\n",
    "if embedding.weight.shape == model.neural_embedding.shape:\n",
    "    assert not torch.allclose(embedding.weight, model.neural_embedding.cpu())\n",
    "\n",
    "# Compare the tokenized and retokenized sequences when the neural_embedding is NOT the true embedding map\n",
    "with torch.no_grad():  # model tokenizer takes in a neural sequence and outputs a token sequence\n",
    "    retokenized_target = model.tokenize_neural_data(neural_target.unsqueeze(0)).squeeze(0)\n",
    "print(type(token_list), neural_target.shape, token_target.shape, retokenized_target.shape)\n",
    "print(\"\\t\", token_target[:5], retokenized_target[:5], end=\"\\n\\n\")\n",
    "\n",
    "# The tokenized and retokenized sequences should NOT be the same\n",
    "assert not torch.allclose(\n",
    "    token_target, retokenized_target\n",
    "), \"The tokenized and retokenized sequences should NOT be the same!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train the NeuralTransformer model\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.0\n",
    "    log_interval = 300\n",
    "    start_time = time.time()\n",
    "    global epoch, optimizer, scheduler\n",
    "\n",
    "    num_batches = len(train_dataset)\n",
    "    for batch in range(num_batches):\n",
    "        data = train_dataset[batch].unsqueeze(0)\n",
    "        mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "        # parse into input and target\n",
    "        mask = mask.to(DEVICE)\n",
    "        input = data[:, :-1, :].to(DEVICE)\n",
    "        target = data[:, 1:, :].to(DEVICE)\n",
    "        # forward pass\n",
    "        output = model(input, mask)  # ``[batch_size=1, seq_len, ntokens]``\n",
    "        # backpropagation step\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss_fn()(\n",
    "            output, target, mask\n",
    "        )  # flattens output to ``[batch_size=1 * seq_len, ntokens]``\n",
    "\n",
    "        # check if the computed loss requires gradient\n",
    "        if loss.requires_grad:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            try:\n",
    "                ppl = math.exp(cur_loss)\n",
    "            except OverflowError:\n",
    "                ppl = float(\"inf\")\n",
    "            print(\n",
    "                f\"| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | \"\n",
    "                f\"lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | \"\n",
    "                f\"loss {cur_loss:5.2f} | ppl {ppl:8.2f}\"\n",
    "            )\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "\n",
    "def evaluate(model: torch.nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        num_batches = len(test_dataset)\n",
    "        for batch in range(num_batches):\n",
    "            data = test_dataset[batch].unsqueeze(0)\n",
    "            mask = mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0)\n",
    "            mask = mask.to(DEVICE)\n",
    "            input = data[:, :-1, :].to(DEVICE)\n",
    "            target = data[:, 1:, :].to(DEVICE)\n",
    "            output = model(input, mask)\n",
    "            loss = model.loss_fn()(output, target, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (4096, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A @ A.T)\n",
    "plt.imshow(A.T @ A)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B @ B.T)\n",
    "plt.imshow(B.T @ B)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epoch(s)...\n",
      "\n",
      "| epoch   1 |   300/ 2072 batches | lr 5.00 | ms/batch 14.27 | loss 79.76 | ppl 43457144324253423227114833561255936.00\n",
      "| epoch   1 |   600/ 2072 batches | lr 5.00 | ms/batch 12.36 | loss 27.04 | ppl 555176591703.77\n",
      "| epoch   1 |   900/ 2072 batches | lr 5.00 | ms/batch  9.74 | loss 19.23 | ppl 224983237.71\n",
      "| epoch   1 |  1200/ 2072 batches | lr 5.00 | ms/batch 10.51 | loss 15.47 | ppl 5215854.78\n",
      "| epoch   1 |  1500/ 2072 batches | lr 5.00 | ms/batch 18.34 | loss 13.53 | ppl 749109.63\n",
      "| epoch   1 |  1800/ 2072 batches | lr 5.00 | ms/batch 12.72 | loss 11.98 | ppl 160277.42\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 27.62s | valid loss  8.85 | valid ppl  6981.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   2 |   300/ 2072 batches | lr 4.95 | ms/batch 11.03 | loss  9.32 | ppl 11152.74\n",
      "| epoch   2 |   600/ 2072 batches | lr 4.95 | ms/batch 11.89 | loss  8.57 | ppl  5275.46\n",
      "| epoch   2 |   900/ 2072 batches | lr 4.95 | ms/batch 12.80 | loss  8.56 | ppl  5205.31\n",
      "| epoch   2 |  1200/ 2072 batches | lr 4.95 | ms/batch 12.48 | loss  7.94 | ppl  2817.25\n",
      "| epoch   2 |  1500/ 2072 batches | lr 4.95 | ms/batch 10.91 | loss  7.63 | ppl  2066.22\n",
      "| epoch   2 |  1800/ 2072 batches | lr 4.95 | ms/batch 10.36 | loss  7.31 | ppl  1490.82\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 24.22s | valid loss  6.71 | valid ppl   820.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   3 |   300/ 2072 batches | lr 4.90 | ms/batch  9.25 | loss  7.01 | ppl  1106.63\n",
      "| epoch   3 |   600/ 2072 batches | lr 4.90 | ms/batch  8.98 | loss  6.27 | ppl   525.95\n",
      "| epoch   3 |   900/ 2072 batches | lr 4.90 | ms/batch  7.57 | loss  6.85 | ppl   940.89\n",
      "| epoch   3 |  1200/ 2072 batches | lr 4.90 | ms/batch  8.95 | loss  6.73 | ppl   834.97\n",
      "| epoch   3 |  1500/ 2072 batches | lr 4.90 | ms/batch  8.17 | loss  6.70 | ppl   814.76\n",
      "| epoch   3 |  1800/ 2072 batches | lr 4.90 | ms/batch  9.24 | loss  6.41 | ppl   610.28\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 19.32s | valid loss  5.65 | valid ppl   283.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   4 |   300/ 2072 batches | lr 4.85 | ms/batch 15.52 | loss  6.21 | ppl   495.69\n",
      "| epoch   4 |   600/ 2072 batches | lr 4.85 | ms/batch 10.05 | loss  6.15 | ppl   466.43\n",
      "| epoch   4 |   900/ 2072 batches | lr 4.85 | ms/batch 11.56 | loss  6.03 | ppl   416.76\n",
      "| epoch   4 |  1200/ 2072 batches | lr 4.85 | ms/batch  9.45 | loss  6.10 | ppl   447.43\n",
      "| epoch   4 |  1500/ 2072 batches | lr 4.85 | ms/batch  9.74 | loss  5.95 | ppl   384.93\n",
      "| epoch   4 |  1800/ 2072 batches | lr 4.85 | ms/batch  9.30 | loss  5.85 | ppl   346.75\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 21.96s | valid loss  5.04 | valid ppl   153.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   5 |   300/ 2072 batches | lr 4.80 | ms/batch 10.19 | loss  5.69 | ppl   296.82\n",
      "| epoch   5 |   600/ 2072 batches | lr 4.80 | ms/batch  5.84 | loss  5.57 | ppl   261.17\n",
      "| epoch   5 |   900/ 2072 batches | lr 4.80 | ms/batch  6.99 | loss  5.49 | ppl   242.88\n",
      "| epoch   5 |  1200/ 2072 batches | lr 4.80 | ms/batch 10.31 | loss  5.52 | ppl   250.63\n",
      "| epoch   5 |  1500/ 2072 batches | lr 4.80 | ms/batch 10.20 | loss  5.55 | ppl   256.98\n",
      "| epoch   5 |  1800/ 2072 batches | lr 4.80 | ms/batch  9.49 | loss  5.38 | ppl   217.46\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 20.32s | valid loss  5.47 | valid ppl   236.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   300/ 2072 batches | lr 4.75 | ms/batch  9.78 | loss  5.37 | ppl   215.37\n",
      "| epoch   6 |   600/ 2072 batches | lr 4.75 | ms/batch  6.15 | loss  5.05 | ppl   155.74\n",
      "| epoch   6 |   900/ 2072 batches | lr 4.75 | ms/batch  6.20 | loss  5.18 | ppl   176.97\n",
      "| epoch   6 |  1200/ 2072 batches | lr 4.75 | ms/batch 10.72 | loss  5.20 | ppl   180.58\n",
      "| epoch   6 |  1500/ 2072 batches | lr 4.75 | ms/batch 11.21 | loss  5.09 | ppl   163.14\n",
      "| epoch   6 |  1800/ 2072 batches | lr 4.75 | ms/batch 12.52 | loss  5.10 | ppl   163.75\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 19.63s | valid loss  5.45 | valid ppl   232.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |   300/ 2072 batches | lr 4.71 | ms/batch 11.94 | loss  5.04 | ppl   154.82\n",
      "| epoch   7 |   600/ 2072 batches | lr 4.71 | ms/batch  9.36 | loss  4.81 | ppl   123.08\n",
      "| epoch   7 |   900/ 2072 batches | lr 4.71 | ms/batch  5.94 | loss  4.92 | ppl   136.35\n",
      "| epoch   7 |  1200/ 2072 batches | lr 4.71 | ms/batch  5.97 | loss  4.79 | ppl   119.74\n",
      "| epoch   7 |  1500/ 2072 batches | lr 4.71 | ms/batch  5.87 | loss  4.84 | ppl   126.77\n",
      "| epoch   7 |  1800/ 2072 batches | lr 4.71 | ms/batch  6.11 | loss  4.77 | ppl   117.93\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 15.40s | valid loss  5.89 | valid ppl   362.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |   300/ 2072 batches | lr 4.66 | ms/batch  6.50 | loss  4.61 | ppl   100.22\n",
      "| epoch   8 |   600/ 2072 batches | lr 4.66 | ms/batch 10.18 | loss  4.38 | ppl    79.79\n",
      "| epoch   8 |   900/ 2072 batches | lr 4.66 | ms/batch 10.38 | loss  4.54 | ppl    93.99\n",
      "| epoch   8 |  1200/ 2072 batches | lr 4.66 | ms/batch  8.16 | loss  4.43 | ppl    83.84\n",
      "| epoch   8 |  1500/ 2072 batches | lr 4.66 | ms/batch  8.30 | loss  4.34 | ppl    76.99\n",
      "| epoch   8 |  1800/ 2072 batches | lr 4.66 | ms/batch  7.41 | loss  4.42 | ppl    83.29\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 17.13s | valid loss  3.73 | valid ppl    41.88\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch   9 |   300/ 2072 batches | lr 4.61 | ms/batch  5.94 | loss  4.26 | ppl    71.11\n",
      "| epoch   9 |   600/ 2072 batches | lr 4.61 | ms/batch  5.84 | loss  4.05 | ppl    57.29\n",
      "| epoch   9 |   900/ 2072 batches | lr 4.61 | ms/batch  6.12 | loss  4.14 | ppl    62.65\n",
      "| epoch   9 |  1200/ 2072 batches | lr 4.61 | ms/batch  5.81 | loss  3.96 | ppl    52.55\n",
      "| epoch   9 |  1500/ 2072 batches | lr 4.61 | ms/batch  5.83 | loss  3.97 | ppl    52.91\n",
      "| epoch   9 |  1800/ 2072 batches | lr 4.61 | ms/batch  5.88 | loss  3.95 | ppl    52.10\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 12.65s | valid loss  3.39 | valid ppl    29.62\n",
      "-----------------------------------------------------------------------------------------\n",
      "Saving the newest best model...\n",
      "\n",
      "| epoch  10 |   300/ 2072 batches | lr 4.57 | ms/batch  7.24 | loss  3.79 | ppl    44.44\n",
      "| epoch  10 |   600/ 2072 batches | lr 4.57 | ms/batch  5.94 | loss  3.62 | ppl    37.29\n",
      "| epoch  10 |   900/ 2072 batches | lr 4.57 | ms/batch  5.83 | loss  3.69 | ppl    40.00\n",
      "| epoch  10 |  1200/ 2072 batches | lr 4.57 | ms/batch  6.12 | loss  3.69 | ppl    39.90\n",
      "| epoch  10 |  1500/ 2072 batches | lr 4.57 | ms/batch  9.41 | loss  3.61 | ppl    37.04\n",
      "| epoch  10 |  1800/ 2072 batches | lr 4.57 | ms/batch  9.35 | loss  3.65 | ppl    38.48\n",
      "TRAIN done.\n",
      "\n",
      "EVAL done.\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 16.01s | valid loss  3.64 | valid ppl    38.08\n",
      "-----------------------------------------------------------------------------------------\n",
      "Reloading the overall best model...\n",
      "\n",
      "Saving the overall best model to permanent location...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown Loop over epochs. Save the model if the validation loss is the best weâ€™ve seen so far. Adjust the learning rate after each epoch.\n",
    "\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.99)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 10\n",
    "\n",
    "# Load the previously saved best model checkpoint if it exists\n",
    "final_model_params_path = os.path.join(\"../models/\", \"neural_transformer_model.pt\")\n",
    "if os.path.exists(final_model_params_path):\n",
    "    print(\"Loading a previously saved model checkpoint...\\n\")\n",
    "    model.load_state_dict(torch.load(final_model_params_path))\n",
    "    best_val_loss = evaluate(model)\n",
    "    print(f\"Previous validation loss: \\t {best_val_loss:5.2f}\\n\")\n",
    "\n",
    "# Train the model\n",
    "if epochs > 0:\n",
    "    print(f\"Training for {epochs} epoch(s)...\\n\")\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start_time = time.time()\n",
    "            train(model)\n",
    "            print(f\"TRAIN done.\\n\")\n",
    "            val_loss = evaluate(model)\n",
    "            print(f\"EVAL done.\\n\")\n",
    "            try:\n",
    "                val_ppl = math.exp(val_loss)\n",
    "            except OverflowError:\n",
    "                val_ppl = float(\"inf\")\n",
    "            elapsed = time.time() - epoch_start_time\n",
    "            print(\"-\" * 89)\n",
    "            print(\n",
    "                f\"| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | \"\n",
    "                f\"valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}\"\n",
    "            )\n",
    "            print(\"-\" * 89)\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                print(f\"Saving the newest best model...\\n\")\n",
    "                torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        if os.path.exists(best_model_params_path):\n",
    "            print(f\"Reloading the overall best model...\\n\")\n",
    "            model.load_state_dict(torch.load(best_model_params_path))  # reload the final best model\n",
    "            print(f\"Saving the overall best model to permanent location...\\n\")\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                final_model_params_path,\n",
    "            )  # save the final best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "\n",
      "neural_embedding trainable? False\n",
      "\n",
      "neural_embedding trained? False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "print(len(model.neural_embedding.unique(dim=0)), end=\"\\n\\n\")\n",
    "print(\"neural_embedding trainable?\", model.neural_embedding.requires_grad, end=\"\\n\\n\")\n",
    "print(\"neural_embedding trained?\", model.neural_embedding.grad is not None, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 302) (4096, 302)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAFLCAYAAAD4cKfRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAt1klEQVR4nO3deVxU9eL/8fcgAqKIghumIl1zzxXr4pIb7ppLpXVdUMvKFcMWyfpZlqG2mOmNskwyv4pauHTTFhU1ta64lbnWzYWumCYpYorCnN8f98E8GkFjYPAcnNfz8ZhHns+cOZ/3YUZ8d86ZGZthGIYAAAAsyMvsAAAAANdDUQEAAJZFUQEAAJZFUQEAAJZFUQEAAJZFUQEAAJZFUQEAAJZFUQEAAJZFUQEAAJZFUQFMcOzYMdlsNiUkJLj82E2bNslms2nTpk1uz2U1tWvX1vDhw82Oka+EhATZbDbt3Lmz2Od64YUXZLPZCrSuzWbTCy+84FjOzXns2LHiCQcUM4oKANzCevXqpW+++UYhISFmRwEKxdvsAAA8Q05OjrKzs+Xr62t2FI9SuXJlVa5c2ewYQKFxRAUeK/dw+vfff68HHnhAgYGBCgoKUkxMjLKzs3X48GF1795dAQEBql27tmbNmuX0+BMnTmjIkCGqUqWKfH191aBBA73++uuy2+1O6508eVIDBw5UQECAAgMDNWjQIJ06dSrfTDt37tS9996roKAg+fn5qXnz5lq+fHmh9i/3kH9ycrJGjx6tSpUqKTg4WAMGDNDJkyfzrL9s2TJFRESobNmyKleunLp166Y9e/Y4rdOhQwd16NAhz2OHDx+u2rVrO5ZzT23NmjVLL7/8ssLCwuTr66vk5GRdvnxZkyZNUrNmzRw/84iICK1evbpQ+5mfguzL8OHDVa5cOR06dEjdunVT2bJlFRISohkzZkiSvv32W7Vt21Zly5ZV3bp19eGHH+Y71++//64RI0YoKChIZcuWVZ8+ffTzzz/nWW/9+vXq3LmzypcvL39/f7Vp00YbNmzIs95nn32mZs2aydfXV2FhYXrttdfynTcjI0OjRo1ScHCwypUrp+7du+vIkSN51svv1E+HDh3UuHFjpaSkqF27dvL399ftt9+uGTNm5Hn97t+/X127dpW/v78qV66ssWPH6rPPPvOY048wH0UFHm/gwIFq2rSpPvnkE40aNUqzZ8/WE088oX79+qlXr15auXKlOnXqpGeeeUZJSUmSpDNnzqh169b68ssv9dJLL2nNmjWKjIzUk08+qXHjxjm2fenSJUVGRurLL79UXFycVqxYoWrVqmnQoEF5ciQnJ6tNmzY6d+6c3nnnHa1evVrNmjXToEGDCnUtS65HHnlEpUuX1pIlSzRr1ixt2rRJQ4YMcVrnlVde0UMPPaSGDRtq+fLl+uijj3ThwgW1a9dOBw4cKPTcb731ljZu3KjXXntN69atU/369ZWVlaX09HQ9+eSTWrVqlZYuXaq2bdtqwIABWrRoUaHnKsy+XL16VQMGDFCvXr20evVq9ejRQ7GxsXr22WcVFRWlkSNHauXKlapXr56GDx+uXbt25Znv4YcflpeXl5YsWaI333xTO3bsUIcOHXTu3DnHOosXL1bXrl1Vvnx5ffjhh1q+fLmCgoLUrVs3p7KyYcMG9e3bVwEBAUpMTNSrr76q5cuXa+HChU5zGoahfv366aOPPtKkSZO0cuVK/f3vf1ePHj0K/HM6deqUBg8erCFDhmjNmjWOfV+8eLFjnbS0NLVv316HDx9WfHy8Fi1apAsXLji9xoFiZwAeaurUqYYk4/XXX3cab9asmSHJSEpKcoxdvXrVqFy5sjFgwADDMAxj8uTJhiTj3//+t9NjR48ebdhsNuPw4cOGYRhGfHy8IclYvXq103qjRo0yJBkLFy50jNWvX99o3ry5cfXqVad1e/fubYSEhBg5OTmGYRhGcnKyIclITk6+4f4tXLjQkGSMGTPGaXzWrFmGJCMtLc0wDMM4ceKE4e3tbYwfP95pvQsXLhjVqlUzBg4c6Bhr37690b59+zxzRUVFGaGhoY7lo0ePGpKMv/3tb8aVK1dumDM7O9u4evWq8fDDDxvNmzd3ui80NNSIioq64eP/zJV9iYqKMiQZn3zyiWMs93mWZOzevdsxfvbsWaNUqVJGTEyMYyz359u/f3+nubZt22ZIMl5++WXDMAzj4sWLRlBQkNGnTx+n9XJycoymTZsad911l2Ps7rvvNqpXr25cunTJMZaRkWEEBQUZf/51vW7dOkOSMWfOHKdtTp8+3ZBkTJ06NU/Oo0ePOsbat2+f7+u3YcOGRrdu3RzLTz31lGGz2Yz9+/c7rdetW7cCvQYBd+CICjxe7969nZYbNGggm83m9H+n3t7eqlOnjo4fPy5J2rhxoxo2bKi77rrL6bHDhw+XYRjauHGjpP8dJQkICNC9997rtN4//vEPp+WffvpJhw4d0uDBgyVJ2dnZjlvPnj2Vlpamw4cPF2r/rp27SZMmkuTYly+++ELZ2dkaNmyY07x+fn5q3759kQ7v33vvvSpdunSe8RUrVqhNmzYqV66cvL29Vbp0aS1YsEAHDx4s9FyS6/tis9nUs2dPx3Lu8xwSEqLmzZs7xoOCglSlShXHz+zPcp+zXK1bt1ZoaKiSk5MlSdu3b1d6erqioqKcMtntdnXv3l0pKSm6ePGiLl68qJSUFA0YMEB+fn6O7QUEBKhPnz5Oc+Ru+9q5r31d3Ui1atXyvH6bNGnitI+bN29W48aN1bBhQ6f1HnrooQLPAxQVF9PC4wUFBTkt+/j4yN/f3+kfi9zxjIwMSdLZs2edrsnIVb16dcf9uf+tWrVqnvWqVavmtPzrr79Kkp588kk9+eST+eb87bffCrA3eQUHBzst517MeunSJae5W7Vqle/jvbwK//8z+b3TJCkpSQMHDtQDDzygp556StWqVZO3t7fi4+P1wQcfFHouyfV9ud7zfO1rInf88uXLecavfS5zx3JfA7mZ7r///uvmTk9Pl81mk91uv+72/uzs2bPy9vbO89zm99jrufax0v9eG7mvi9x5wsLC8qyX32saKC4UFaAQgoODlZaWlmc89yLVSpUqOdbbsWNHnvWuvZg2d/3Y2FgNGDAg3znr1atXpMzXkzv3xx9/rNDQ0Buu6+fnp/Pnz+cZv16Jyu+zPxYvXqywsDAtW7bM6f6srCxXYufLlX1xl/wujD516pTq1KnjlGnu3Ln6+9//nu82qlatqqtXr8pms113e38WHBys7OxsnT171qlwXO8i7cIKDg52FK0b5QGKE6d+gELo3LmzDhw4oN27dzuNL1q0SDabTR07dpQkdezYURcuXNCaNWuc1luyZInTcr169XTHHXfou+++U3h4eL63gICAYtmXbt26ydvbW//5z3+uO3eu2rVr68iRI06l4uzZs9q+fXuB57PZbPLx8XEqKadOnXLLu35c2Rd3+b//+z+n5e3bt+v48eOOd0e1adNGFSpU0IEDB66bycfHR2XLltVdd92lpKQkpyM3Fy5c0Keffuo0R+7r69q5r31dFVX79u31ww8/5LkIOTEx0a3zADfCERWgEJ544gktWrRIvXr10rRp0xQaGqrPPvtMb7/9tkaPHq26detKkoYNG6bZs2dr2LBhmj59uu644w6tXbtWX3zxRZ5tvvvuu+rRo4e6deum4cOH67bbblN6eroOHjyo3bt3a8WKFdfNs2jRIo0cOVIffPCBhg0b5tK+1K5dW9OmTdOUKVP0888/q3v37qpYsaJ+/fVX7dixQ2XLltWLL74oSRo6dKjeffddDRkyRKNGjdLZs2c1a9YslS9fvsDz9e7dW0lJSRozZozuv/9+paam6qWXXlJISIh+/PFHl7IXZV/cZefOnXrkkUf0wAMPKDU1VVOmTNFtt92mMWPGSJLKlSunuXPnKioqSunp6br//vtVpUoVnTlzRt99953OnDmj+Ph4SdJLL72k7t27q0uXLpo0aZJycnI0c+ZMlS1bVunp6Y45u3btqnvuuUdPP/20Ll68qPDwcG3btk0fffSRW/dt4sSJ+uCDD9SjRw9NmzZNVatW1ZIlS3To0CFJRTstCBQUrzKgECpXrqzt27erU6dOio2NVe/evfXFF19o1qxZmjt3rmM9f39/bdy4UZGRkZo8ebLuv/9+/fLLL/n+H2nHjh21Y8cOVahQQRMnTlRkZKRGjx6t9evXKzIy8oZ57Ha7cnJy8nwGRkHFxsbq448/1pEjRxQVFaVu3brp6aef1vHjx3XPPfc41mvTpo0+/PBD7d+/X3379tXLL7+s2NjYfD9b5XpGjBihGTNmaN26derZs6dmzpypyZMnu3QhqDv2xV0WLFigK1eu6MEHH9SECRMUHh6uTZs2OV3nMmTIECUnJyszM1OPPfaYIiMjFR0drd27d6tz586O9bp06aJVq1YpIyNDgwYNUkxMjO677z6NHDnSaU4vLy+tWbNGgwcP1qxZs9SvXz9t375da9eudeu+Va9eXZs3b1bdunX1+OOPa/DgwfLx8dG0adMkSRUqVHDrfEB+bIZhGGaHAACUHI8++qiWLl2qs2fPysfHx+w4uMVx6gcAcF3Tpk1T9erVdfvttyszM1P/+te/9P777+u5556jpOCmoKgAKBFycnJ0owPANptNpUqVuomJPEPp0qX16quv6pdfflF2drbuuOMOvfHGG4qOjjY7GjwEp34AlAi1a9fO9wPXchX1w+kAWBNHVACUCJ9++ukNP2uluN6+DcBcHFEBAACWxduTAQCAZZXoUz92u10nT55UQEBAvh/VDQAArMcwDF24cEHVq1f/yw8OLNFF5eTJk6pZs6bZMQAAQCGkpqaqRo0aN1ynRBeV3Ivnbh/3/1TK1+8v1ra2y3XzfitrSePtk212BLco7VO4T3e1mqg7vjU7QpH934KuZkdwC3tpsxO4R7V5/zY7QpGtPLLP7Ahu0XL7g2ZHKBL7pSwdG/16gS6CL9FFJfd0TylfvxJfVLzKmJ2g6Lx8b42iUsonx+wIbuFXrkT/9ZakEv/3OpftFikq3rfAjpQPuDUuzfTyv0X+bhTgso1b4xkDAAC3JIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLIoKAACwLNOLyttvv62wsDD5+fmpZcuW+vrrr82OBAAALMLUorJs2TJNnDhRU6ZM0Z49e9SuXTv16NFDJ06cMDMWAACwCFOLyhtvvKGHH35YjzzyiBo0aKA333xTNWvWVHx8vJmxAACARZhWVK5cuaJdu3apa9euTuNdu3bV9u3b831MVlaWMjIynG4AAODWZVpR+e2335STk6OqVas6jVetWlWnTp3K9zFxcXEKDAx03GrWrHkzogIAAJOYfjGtzWZzWjYMI89YrtjYWJ0/f95xS01NvRkRAQCASbzNmrhSpUoqVapUnqMnp0+fznOUJZevr698fX1vRjwAAGABph1R8fHxUcuWLfXVV185jX/11Vdq3bq1SakAAICVmHZERZJiYmI0dOhQhYeHKyIiQvPnz9eJEyf0+OOPmxkLAABYhKlFZdCgQTp79qymTZumtLQ0NW7cWGvXrlVoaKiZsQAAgEWYWlQkacyYMRozZozZMQAAgAWZ/q4fAACA66GoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy6KoAAAAy/I2O4A7eF2VvEp45fI74md2hCLzvSvd7AhuEfymv9kR3GJezx5mRygyI8xudgS3qHVnmtkR3OJYxQizIxRZ05mtzY7gFg+O3Gx2hCLJyryqVwu4bgn/5x0AANzKKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyKCoAAMCyTC0qW7ZsUZ8+fVS9enXZbDatWrXKzDgAAMBiTC0qFy9eVNOmTTVv3jwzYwAAAIvyNnPyHj16qEePHmZGAAAAFmZqUXFVVlaWsrKyHMsZGRkmpgEAAMWtRF1MGxcXp8DAQMetZs2aZkcCAADFqEQVldjYWJ0/f95xS01NNTsSAAAoRiXq1I+vr698fX3NjgEAAG6SEnVEBQAAeBZTj6hkZmbqp59+ciwfPXpUe/fuVVBQkGrVqmViMgAAYAWmFpWdO3eqY8eOjuWYmBhJUlRUlBISEkxKBQAArMLUotKhQwcZhmFmBAAAYGFcowIAACyLogIAACyLogIAACyLogIAACzL5aKyfv3669737rvvFikMAADAn7lcVHr16qVJkybpypUrjrEzZ86oT58+io2NdWs4AADg2VwuKlu2bNGnn36qVq1aaf/+/frss8/UuHFjZWZm6rvvviuOjAAAwEO5XFTuvvtu7dmzR02aNFHLli3Vv39/TZo0SRs3buTbjAEAgFsV6mLaw4cPKyUlRTVq1JC3t7cOHTqkP/74w93ZAACAh3O5qMyYMUMRERHq0qWLfvjhB6WkpDiOsHzzzTfFkREAAHgol4vKnDlztGrVKs2dO1d+fn5q1KiRduzYoQEDBqhDhw7FEBEAAHgql7/rZ9++fapUqZLTWOnSpfXqq6+qd+/ebgsGAADg8hGVSpUq6dy5c3r//fcVGxur9PR0SdLu3btVp04dtwcEAACey+UjKt9//70iIyMVGBioY8eOadSoUQoKCtLKlSt1/PhxLVq0qDhyAgAAD+TyEZWYmBgNHz5cP/74o/z8/BzjPXr00JYtW9waDgAAeDaXi0pKSooee+yxPOO33XabTp065ZZQAAAAUiGKip+fnzIyMvKMHz58WJUrV3ZLKAAAAKkQRaVv376aNm2arl69Kkmy2Ww6ceKEJk+erPvuu8/tAQEAgOdy+WLa1157TT179lSVKlV06dIltW/fXqdOnVJERISmT59eHBn/0h8Ns+RVxmbK3O5SPzTN7AhF9vvlMmZHcItLz5wzO4Jb+GytZnaEIrtc1W52BLewv1XV7Ahu4dOgZP+elaTK3102O4JbpKSHmh2hSLIvZhV4XZeLSvny5bV161Zt3LhRu3fvlt1uV4sWLRQZGenqpgAAAG7I5aKSq1OnTurUqZM7swAAADgpUFF56623CrzBCRMmFDoMAADAnxWoqMyePdtp+cyZM/rjjz9UoUIFSdK5c+fk7++vKlWqUFQAAIDbFOhdP0ePHnXcpk+frmbNmungwYNKT09Xenq6Dh48qBYtWuill14q7rwAAMCDuPz25Oeff15z585VvXr1HGP16tXT7Nmz9dxzz7k1HAAA8GwuF5W0tDTHZ6j8WU5Ojn799Ve3hAIAAJAKUVQ6d+6sUaNGaefOnTIMQ5K0c+dOPfbYY7xFGQAAuJXLReWDDz7Qbbfdprvuukt+fn7y9fXV3XffrZCQEL3//vvFkREAAHgolz9HpXLlylq7dq2OHDmiQ4cOyTAMNWjQQHXr1i2OfAAAwIMV+gPf6tatSzkBAADFyuWikpOTo4SEBG3YsEGnT5+W3e78XRwbN250WzgAAODZXC4q0dHRSkhIUK9evdS4cWPZbCX/S6oAAIA1uVxUEhMTtXz5cvXs2bM48gAAADi4/K4fHx8f1alTpziyAAAAOHG5qEyaNElz5sxxfIYKAABAcXH51M/WrVuVnJysdevWqVGjRipdurTT/UlJSW4LBwAAPJvLRaVChQrq379/cWQBAABw4nJRWbhwYXHkAAAAyMPla1QAAABulgIdUWnRooU2bNigihUrqnnz5jf87JTdu3cXePK4uDglJSXp0KFDKlOmjFq3bq2ZM2eqXr16Bd4GAAC4dRWoqPTt21e+vr6SpH79+rlt8s2bN2vs2LFq1aqVsrOzNWXKFHXt2lUHDhxQ2bJl3TYPAAAomQpUVKZOnZrvn4vq888/d1peuHChqlSpol27dumee+5x2zwAAKBkKvSXEhaH8+fPS5KCgoLyvT8rK0tZWVmO5YyMjJuSCwAAmMMyF9MahqGYmBi1bdtWjRs3zneduLg4BQYGOm41a9a8ySkBAMDNZJmiMm7cOH3//fdaunTpddeJjY3V+fPnHbfU1NSbmBAAANxsljj1M378eK1Zs0ZbtmxRjRo1rruer6+v46JeAABw6zO1qBiGofHjx2vlypXatGmTwsLCzIwDAAAsxuWikpOTo4SEBG3YsEGnT5+W3W53un/jxo0F3tbYsWO1ZMkSrV69WgEBATp16pQkKTAwUGXKlHE1GgAAuMW4XFSio6OVkJCgXr16qXHjxjf88Le/Eh8fL0nq0KGD0/jChQs1fPjwQm8XAADcGlwuKomJiVq+fLl69uxZ5MkNwyjyNgAAwK3L5Xf9+Pj4qE6dOsWRBQAAwInLRWXSpEmaM2cOR0MAAECxc/nUz9atW5WcnKx169apUaNGKl26tNP9SUlJbgsHAAA8m8tFpUKFCurfv39xZAEAAHDiclFZuHBhceQAAADIo1AfoZ+dna3169fr3Xff1YULFyRJJ0+eVGZmplvDAQAAz+byEZXjx4+re/fuOnHihLKystSlSxcFBARo1qxZunz5st55553iyAkAADyQy0dUoqOjFR4ert9//93p02P79++vDRs2uDUcAADwbIV618+2bdvk4+PjNB4aGqr//ve/bgsGAADg8hEVu92unJycPOO//PKLAgIC3BIKAABAKkRR6dKli958803Hss1mU2ZmpqZOneqWj9UHAADI5fKpn9mzZ6tjx45q2LChLl++rH/84x/68ccfValSJS1durQ4MgIAAA/lclGpXr269u7dq8TERO3atUt2u10PP/ywBg8e7HRxLQAAQFG5XFQWL16sIUOGaMSIERoxYoTTfU899ZReffVVt4UDAACezeVrVMaNG6d//etfecafeOIJLV682C2hAAAApEIUlcTERA0ZMkRbtmxxjI0fP17Lly9XcnKyW8MBAADP5nJR6d69u9555x3169dPO3fu1JgxY5SUlKTk5GTVr1+/ODICAAAP5fI1KpL04IMP6vfff1fbtm1VuXJlbd68WXXq1HF3tgLzOearUn6+ps3vDqe3hZodocgqHrpsdgS3CJn1H7MjuMXXf6todoQi8yt3xewIbnHub7fGZ0wF/pz3M7RKGp+T582O4BZnLpYzO0KR5PxRusDrFqioxMTE5DtepUoVNW/eXG+//bZj7I033ijw5AAAADdSoKKyZ8+efMf/9re/KSMjw3G/zWZzXzIAAODxClRUuEgWAACYweWLaf/sl19+4YsIAQBAsSnUlxJOmzZNgYGBCg0NVa1atVShQgW99NJLstvtxZERAAB4KJff9TNlyhQtWLBAM2bMUJs2bWQYhrZt26YXXnhBly9f1vTp04sjJwAA8EAuF5UPP/xQ77//vu69917HWNOmTXXbbbdpzJgxFBUAAOA2Lp/6SU9Pz/eD3erXr6/09HS3hAIAAJAKUVSaNm2qefPm5RmfN2+emjZt6pZQAAAAUiFO/cyaNUu9evXS+vXrFRERIZvNpu3btys1NVVr164tjowAAMBDuXxEpX379jpy5Ij69++vc+fOKT09XQMGDNDhw4fVrl274sgIAAA8lMtHVE6cOKGaNWvme9HsiRMnVKtWLbcEAwAAcPmISlhYmM6cOZNn/OzZswoLC3NLKAAAAKkQRcUwjHy/0yczM1N+fn5uCQUAACC5cOon9xuUbTabnn/+efn7+zvuy8nJ0b///W81a9bM7QEBAIDnKnBRyf2GZMMwtG/fPvn4+Dju8/HxUdOmTfXkk0+6PyEAAPBYBS4qud+gPGLECM2ZM0fly5cvtlAAAABSId71s3DhwuLIAQAAkIfLF9MCAADcLBQVAABgWaYWlfj4eDVp0kTly5dX+fLlFRERoXXr1pkZCQAAWIipRaVGjRqaMWOGdu7cqZ07d6pTp07q27ev9u/fb2YsAABgES5fTOtOffr0cVqePn264uPj9e2336pRo0YmpQIAAFZhalH5s5ycHK1YsUIXL15UREREvutkZWUpKyvLsZyRkXGz4gEAABOYfjHtvn37VK5cOfn6+urxxx/XypUr1bBhw3zXjYuLU2BgoONWs2bNm5wWAADcTKYXlXr16mnv3r369ttvNXr0aEVFRenAgQP5rhsbG6vz5887bqmpqTc5LQAAuJlMP/Xj4+OjOnXqSJLCw8OVkpKiOXPm6N13382zrq+vr3x9fW92RAAAYBLTj6hcyzAMp+tQAACA5zL1iMqzzz6rHj16qGbNmrpw4YISExO1adMmff7552bGAgAAFmFqUfn11181dOhQpaWlKTAwUE2aNNHnn3+uLl26mBkLAABYhKlFZcGCBWZODwAALM5y16gAAADkoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADL8jY7gDsY9TNl9882O0aRpAeXMTtCkd0edcLsCG6x7ZuGZkdwi7DPS/bfCUl6cM4GsyO4xewf+pkdwS3K7LpidoQi67f6G7MjuMWMjX3MjlAk9kuXC7wuR1QAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlUVQAAIBlWaaoxMXFyWazaeLEiWZHAQAAFmGJopKSkqL58+erSZMmZkcBAAAWYnpRyczM1ODBg/Xee++pYsWKZscBAAAWYnpRGTt2rHr16qXIyMi/XDcrK0sZGRlONwAAcOvyNnPyxMRE7d69WykpKQVaPy4uTi+++GIxpwIAAFZh2hGV1NRURUdHa/HixfLz8yvQY2JjY3X+/HnHLTU1tZhTAgAAM5l2RGXXrl06ffq0WrZs6RjLycnRli1bNG/ePGVlZalUqVJOj/H19ZWvr+/NjgoAAExiWlHp3Lmz9u3b5zQ2YsQI1a9fX88880yekgIAADyPaUUlICBAjRs3dhorW7asgoOD84wDAADPZPq7fgAAAK7H1Hf9XGvTpk1mRwAAABbCERUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZFBUAAGBZ3mYHKArDMCRJ9ktZJicpOvslm9kRiuzqxStmR3AL++XLZkdwi+zsbLMjFNmlzJK/D5KUc8u8pkr+ftwqryn7pZL9XOT+ns39d/xGbEZB1rKoX375RTVr1jQ7BgAAKITU1FTVqFHjhuuU6KJit9t18uRJBQQEyGYrniMSGRkZqlmzplJTU1W+fPlimQMFw3NhHTwX1sLzYR08FwVjGIYuXLig6tWry8vrxlehlOhTP15eXn/ZxNylfPnyvOgsgufCOngurIXnwzp4Lv5aYGBggdbjYloAAGBZFBUAAGBZFJW/4Ovrq6lTp8rX19fsKB6P58I6eC6shefDOngu3K9EX0wLAABubRxRAQAAlkVRAQAAlkVRAQAAlkVRAQAAlkVRuYG3335bYWFh8vPzU8uWLfX111+bHckjxcXFqVWrVgoICFCVKlXUr18/HT582OxY0P+eG5vNpokTJ5odxSP997//1ZAhQxQcHCx/f381a9ZMu3btMjuWx8nOztZzzz2nsLAwlSlTRrfffrumTZsmu91udrRbAkXlOpYtW6aJEydqypQp2rNnj9q1a6cePXroxIkTZkfzOJs3b9bYsWP17bff6quvvlJ2dra6du2qixcvmh3No6WkpGj+/Plq0qSJ2VE80u+//642bdqodOnSWrdunQ4cOKDXX39dFSpUMDuax5k5c6beeecdzZs3TwcPHtSsWbP06quvau7cuWZHuyXw9uTruPvuu9WiRQvFx8c7xho0aKB+/fopLi7OxGQ4c+aMqlSpos2bN+uee+4xO45HyszMVIsWLfT222/r5ZdfVrNmzfTmm2+aHcujTJ48Wdu2beNIrwX07t1bVatW1YIFCxxj9913n/z9/fXRRx+ZmOzWwBGVfFy5ckW7du1S165dnca7du2q7du3m5QKuc6fPy9JCgoKMjmJ5xo7dqx69eqlyMhIs6N4rDVr1ig8PFwPPPCAqlSpoubNm+u9994zO5ZHatu2rTZs2KAjR45Ikr777jtt3bpVPXv2NDnZraFEfylhcfntt9+Uk5OjqlWrOo1XrVpVp06dMikVpP9942ZMTIzatm2rxo0bmx3HIyUmJmr37t1KSUkxO4pH+/nnnxUfH6+YmBg9++yz2rFjhyZMmCBfX18NGzbM7Hge5ZlnntH58+dVv359lSpVSjk5OZo+fboeeughs6PdEigqN2Cz2ZyWDcPIM4aba9y4cfr++++1detWs6N4pNTUVEVHR+vLL7+Un5+f2XE8mt1uV3h4uF555RVJUvPmzbV//37Fx8dTVG6yZcuWafHixVqyZIkaNWqkvXv3auLEiapevbqioqLMjlfiUVTyUalSJZUqVSrP0ZPTp0/nOcqCm2f8+PFas2aNtmzZoho1apgdxyPt2rVLp0+fVsuWLR1jOTk52rJli+bNm6esrCyVKlXKxISeIyQkRA0bNnQaa9CggT755BOTEnmup556SpMnT9aDDz4oSbrzzjt1/PhxxcXFUVTcgGtU8uHj46OWLVvqq6++chr/6quv1Lp1a5NSeS7DMDRu3DglJSVp48aNCgsLMzuSx+rcubP27dunvXv3Om7h4eEaPHiw9u7dS0m5idq0aZPnbfpHjhxRaGioSYk81x9//CEvL+d/TkuVKsXbk92EIyrXERMTo6FDhyo8PFwRERGaP3++Tpw4occff9zsaB5n7NixWrJkiVavXq2AgADHka7AwECVKVPG5HSeJSAgIM+1QWXLllVwcDDXDN1kTzzxhFq3bq1XXnlFAwcO1I4dOzR//nzNnz/f7Ggep0+fPpo+fbpq1aqlRo0aac+ePXrjjTc0cuRIs6PdGgxc1z//+U8jNDTU8PHxMVq0aGFs3rzZ7EgeSVK+t4ULF5odDYZhtG/f3oiOjjY7hkf69NNPjcaNGxu+vr5G/fr1jfnz55sdySNlZGQY0dHRRq1atQw/Pz/j9ttvN6ZMmWJkZWWZHe2WwOeoAAAAy+IaFQAAYFkUFQAAYFkUFQAAYFkUFQAAYFkUFQAAYFkUFQAAYFkUFQAAYFkUFQAAYFkUFaCE69ChgyZOnGh2DJcMHz5c/fr1cyyXlH2w2WxatWqV2TEAj8J3/QAlXFJSkkqXLn3T533hhRe0atUq7d27t8jbMmsfXJWWlqaKFSuaHQPwKBQVoIQLCgoyO0KRlZR9qFatmtkRAI/DqR+ghLv2tEnt2rX1yiuvaOTIkQoICFCtWrWcvlH32LFjstlsSkxMVOvWreXn56dGjRpp06ZNjnUSEhJUoUIFp3lWrVolm83muP/FF1/Ud999J5vNJpvNpoSEhHzz5eTkKCYmRhUqVFBwcLCefvppXfsVY/ntw8svv6xhw4apXLlyCg0N1erVq3XmzBn17dtX5cqV05133qmdO3c6bWf79u265557VKZMGdWsWVMTJkzQxYsXC/yzuXLlisaNG6eQkBD5+fmpdu3aiouLc9x/7amfffv2qVOnTipTpoyCg4P16KOPKjMz03F/7imu1157TSEhIQoODtbYsWN19erVfH9WAPKiqAC3oNdff13h4eHas2ePxowZo9GjR+vQoUNO6zz11FOaNGmS9uzZo9atW+vee+/V2bNnC7T9QYMGadKkSWrUqJHS0tKUlpamQYMGXTfLBx98oAULFmjr1q1KT0/XypUr/3KO2bNnq02bNtqzZ4969eqloUOHatiwYRoyZIh2796tOnXqaNiwYY7Ss2/fPnXr1k0DBgzQ999/r2XLlmnr1q0aN25cgX82b731ltasWaPly5fr8OHDWrx4sWrXrp1vvj/++EPdu3dXxYoVlZKSohUrVmj9+vV55ktOTtZ//vMfJScn68MPP1RCQsJ1Sx2AfJj75c0Aiqp9+/ZGdHS0Yzk0NNQYMmSIY9lutxtVqlQx4uPjDcMwjKNHjxqSjBkzZjjWuXr1qlGjRg1j5syZhmEYxsKFC43AwECneVauXGn8+VfG1KlTjaZNm/5lvpCQkHzn6tu3b4H3IS0tzZBkPP/8846xb775xpBkpKWlGYZhGEOHDjUeffRRp7m//vprw8vLy7h06VKBfjbjx483OnXqZNjt9nz3RZKxcuVKwzAMY/78+UbFihWNzMxMx/2fffaZ4eXlZZw6dcowDMOIiooyQkNDjezsbMc6DzzwgDFo0KDr/8AAOOGICnALatKkiePPNptN1apV0+nTp53WiYiIcPzZ29tb4eHhOnjwoFtznD9/XmlpafnO9Vf+vA9Vq1aVJN155515xnL3a9euXUpISFC5cuUct27duslut+vo0aP5bvfan83w4cO1d+9e1atXTxMmTNCXX3553XwHDx5U06ZNVbZsWcdYmzZtZLfbdfjwYcdYo0aNVKpUKcdySEhInucCwPVxMS1wC7r2HTQ2m012u/0vH5d7DYqXl1ee60hu9nUVf96H3Fz5jeXul91u12OPPaYJEybk2VatWrXy3W7udnK30aJFCx09elTr1q3T+vXrNXDgQEVGRurjjz/Os03DMBwZrvXn8cI+FwD+hyMqgIf69ttvHX/Ozs7Wrl27VL9+fUlS5cqVdeHCBacLUa99G7KPj49ycnJuOEdgYKBCQkLyncvdWrRoof3796tOnTp5bj4+PgXeTvny5TVo0CC99957WrZsmT755BOlp6fnWa9hw4bau3ev089o27Zt8vLyUt26dd2yTwAoKoDH+uc//6mVK1fq0KFDGjt2rH7//XeNHDlSknT33XfL399fzz77rH766SctWbIkzwWgtWvX1tGjR7V371799ttvysrKynee6OhozZgxwzHXmDFjdO7cObfvzzPPPKNvvvlGY8eO1d69e/Xjjz9qzZo1Gj9+fIG3MXv2bCUmJurQoUM6cuSIVqxYoWrVquV5B5QkDR48WH5+foqKitIPP/yg5ORkjR8/XkOHDnWclgJQdBQVwEPNmDFDM2fOVNOmTfX1119r9erVqlSpkqT/fa7J4sWLtXbtWt15551aunSpXnjhBafH33ffferevbs6duyoypUra+nSpfnOM2nSJA0bNkzDhw9XRESEAgIC1L9/f7fvT5MmTbR582b9+OOPateunZo3b67nn39eISEhBd5GuXLlNHPmTIWHh6tVq1Y6duyY1q5dKy+vvL8q/f399cUXXyg9PV2tWrXS/fffr86dO2vevHnu3C3A49mMa09EA7ilHTt2TGFhYdqzZ4+aNWtmdhwAuCGOqAAAAMuiqAAAAMvi1A8AALAsjqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADLoqgAAADL+v/71zs9ECk/6gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# The learnt model.neural_embedding should contain a permutation of the true neural embedding.\n",
    "\n",
    "A = embedding.weight.numpy()\n",
    "B = model.neural_embedding.detach().cpu().numpy()\n",
    "\n",
    "print(A.shape, B.shape)\n",
    "\n",
    "plt.imshow(A.T @ A)  # (input_size, input_size)\n",
    "plt.imshow(A[:5, :10])\n",
    "plt.title(\"true neural embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(B.T @ B)  # (input_size, input_size)\n",
    "plt.imshow(B[:5, :10])\n",
    "plt.title(\"model.neural_embedding\")\n",
    "plt.ylabel(\"token index\")\n",
    "plt.xlabel(\"input dimension\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 302]) torch.Size([1, 509, 302]) torch.Size([1, 100, 302])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Generate new data\n",
    "\n",
    "max_new_tokens = 100\n",
    "mask = torch.ones(emsize, dtype=torch.bool).unsqueeze(0).to(DEVICE)\n",
    "data = test_dataset[0][:-1, :].unsqueeze(0).to(DEVICE)\n",
    "data_gen = model.generate(data, mask, max_new_tokens, top_k=None)\n",
    "\n",
    "print(mask.shape, data.shape, data_gen.shape, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114, 120, 1]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, You\n",
      "\n",
      "[117, 100, 113, 102, 104, 35, 119, 100, 42, 104, 113, 35, 68, 118, 35, 118, 107, 100, 111, 111, 35, 122, 108, 119, 107, 35, 104, 108, 119, 107, 104, 117, 35, 115, 100, 117, 119, 42, 118, 35, 100, 106, 117, 104, 104, 112, 104, 113, 119, 35, 118, 119, 100, 113, 103, 66, 35, 69, 68, 83, 87, 76, 86, 87, 68, 61, 35, 81, 114, 119, 35, 108, 113, 35, 112, 124, 35, 107, 114, 120, 118, 104, 47, 35, 79, 120, 102, 104, 113, 119, 108, 114, 62, 35, 105, 114, 117, 47, 35, 124, 114, 120, 35, 110, 113, 114, 122, 47, 35, 83, 108, 119, 102, 107, 104, 117, 118, 35, 107, 100, 121, 104, 35, 104, 100, 117, 118, 47, 35, 100, 113, 103, 35, 76, 35, 107, 100, 121, 104, 35, 112, 100, 113, 124, 35, 118, 104, 117, 121, 100, 113, 119, 118, 61, 35, 69, 104, 118, 108, 103, 104, 118, 47, 35, 114, 111, 103, 35, 74, 117, 104, 112, 108, 114, 35, 108, 118, 35, 107, 104, 100, 117, 110, 104, 113, 108, 113, 106, 35, 118, 119, 108, 111, 111, 62, 35, 68, 113, 103, 35, 107, 100, 115, 115, 108, 111, 124, 35, 122, 104, 35, 112, 108, 106, 107, 119, 35, 101, 104, 35, 108, 113, 119, 104, 117, 117, 120, 115, 119, 104, 103, 49, 35, 87, 85, 68, 81, 76, 82, 61, 35, 87, 107, 104, 113, 35, 100, 119, 35, 112, 124, 35, 111, 114, 103, 106, 108, 113, 106, 47, 35, 100, 113, 35, 108, 119, 35, 111, 108, 110, 104, 35, 124, 114, 120, 61, 35, 87, 107, 104, 117, 104, 35, 103, 114, 119, 107, 35, 112, 124, 35, 105, 100, 119, 107, 104, 117, 35, 111, 108, 104, 62, 35, 100, 113, 103, 35, 119, 107, 104, 117, 104, 47, 35, 119, 107, 108, 118, 35, 113, 108, 106, 107, 119, 47, 35, 90, 104, 42, 111, 111, 35, 115, 100, 118, 118, 35, 119, 107, 104, 35, 101, 120, 118, 108, 113, 104, 118, 118, 35, 115, 117, 108, 121, 100, 119, 104, 111, 124, 35, 100, 113, 103, 35, 122, 104, 111, 111, 49, 35, 86, 104, 113, 103, 35, 105, 114, 117, 35, 124, 114, 120, 117, 35, 103, 100, 120, 106, 107, 119, 104, 117, 35, 101, 124, 35, 124, 114, 120, 117, 35, 118, 104, 117, 121, 100, 113, 119, 35, 107, 104, 117, 104, 61, 35, 80, 124, 35, 101, 114, 124, 35, 118, 107, 100, 111, 111, 35, 105, 104, 119, 102, 107, 35, 119, 107, 104, 35, 118, 102, 117, 108, 121, 104, 113, 104, 117, 35, 115, 117, 104, 118, 104, 113, 119, 111, 124, 49, 35, 87, 107, 104, 35, 122, 114, 117, 118, 119, 35, 108, 118, 35, 119, 107, 108, 118, 47, 35, 119, 107, 100, 119, 47, 35, 100, 119, 35, 118, 114, 35, 118, 111, 104, 113, 103, 104, 117, 35, 122, 100, 117, 113, 108, 113, 106, 47, 35, 92, 114]\n",
      "\n",
      "rance ta'en As shall with either part's agreement stand? BAPTISTA: Not in my house, Lucentio; for, you know, Pitchers have ears, and I have many servants: Besides, old Gremio is hearkening still; And happily we might be interrupted. TRANIO: Then at my lodging, an it like you: There doth my father lie; and there, this night, We'll pass the business privately and well. Send for your daughter by your servant here: My boy shall fetch the scrivener presently. The worst is this, that, at so slender warning, Yo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @markdown We want to tokenize the neural data.\n",
    "# An oracle told us that the neural data itself is an embedding of tokens from some unknown vocabulary.\n",
    "# We can do this by using the tokenize_neural_data method of our model.\n",
    "\n",
    "# First run a test on data for which we know what the true token output should be.\n",
    "# This is just to confirm if our tokenize_neural_data method is working as expected.\n",
    "with torch.no_grad():\n",
    "    sequence = data\n",
    "    inp_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    # iff correct these two should match\n",
    "    print(text_dataset[\"test\"][\"input_ids\"][0], end=\"\\n\\n\")  # ground-truth tokens\n",
    "    print(text_dataset[\"test\"][\"text\"][0], end=\"\\n\\n\")  # ground-truth text\n",
    "    print(inp_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(inp_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47, 35, 104, 118, 107, 104, 111, 114, 100, 113, 118, 107, 73, 100, 81, 100, 124, 35, 103, 100, 100, 120, 117, 104, 35, 117, 35, 35, 118, 119, 107, 124, 87, 107, 114, 101, 108, 117, 104, 108, 117, 35, 103, 104, 117, 35, 90, 107, 35, 117, 104, 35, 101, 100, 124, 35, 35, 120, 113, 119, 35, 103, 100, 113, 124, 35, 92, 114, 120, 35, 118, 61, 35, 35, 90, 107, 100, 124, 35, 107, 35, 79, 120, 117, 47, 35, 35, 103, 35, 103, 113, 106, 107, 104, 122, 47, 35, 103, 35, 101]\n",
      "\n",
      ", esheloanshFaNay daaure r  sthyThobireir der Wh re bay  unt dany You s:  Whay h Lur,  d dnghew, d b\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now do the same thing on the newly generated data\n",
    "with torch.no_grad():\n",
    "    sequence = data_gen\n",
    "    gen_tokens = model.tokenize_neural_data(\n",
    "        neural_sequence=sequence,\n",
    "        feature_mask=mask,\n",
    "        token_matrix=embedding.weight,\n",
    "    )\n",
    "    print(gen_tokens.squeeze().tolist(), end=\"\\n\\n\")  # decoded tokens\n",
    "    print(tokenizer.decode(gen_tokens.squeeze().tolist()), end=\"\\n\\n\")  # decoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 302]) torch.Size([65, 302])\n",
      "\n",
      "There are 64 unique embeddings that generated the neural data.\n",
      "The model learned 65 unique neural embeddings. But are they the same?\n",
      "\n",
      "Model learned to reproduce 62/64 embeddings exactly.\n",
      "The remaining 2/64 are superpositions of embeddings!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "all_unique_vectors = torch.vstack(train_dataset).unique(dim=0)\n",
    "learned_unique_vectors = model.neural_embedding.unique(dim=0)\n",
    "print(all_unique_vectors.shape, learned_unique_vectors.shape)\n",
    "print()\n",
    "\n",
    "all_unique_vectors = {tuple(row.round(decimals=3).cpu().numpy()) for row in all_unique_vectors}\n",
    "learned_unique_vectors = {\n",
    "    tuple(row.round(decimals=3).cpu().numpy()) for row in learned_unique_vectors\n",
    "}\n",
    "print(f\"There are {len(all_unique_vectors)} unique embeddings that generated the neural data.\")\n",
    "print(\n",
    "    f\"The model learned {len(learned_unique_vectors)} unique neural embeddings. But are they the same?\"\n",
    ")\n",
    "print()\n",
    "\n",
    "inter = all_unique_vectors.intersection(learned_unique_vectors)\n",
    "diff = all_unique_vectors - learned_unique_vectors\n",
    "print(f\"Model learned to reproduce {len(inter)}/{len(all_unique_vectors)} embeddings exactly.\")\n",
    "print(f\"The remaining {len(diff)}/{len(all_unique_vectors)} are superpositions of embeddings!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal index: 0 \n",
      "neural: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 20 \n",
      "mapped: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 1 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 2 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 3 \n",
      "neural: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 4 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 5 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 6 \n",
      "neural: tensor([ 0.3363,  0.9476,  0.7681,  0.7826, -0.3173], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 2 \n",
      "mapped: tensor([ 0.3363,  0.9476,  0.7681,  0.7826, -0.3173], device='cuda:0')\n",
      "\n",
      "embedding token: 111 \n",
      "character: l \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3363,  0.9476,  0.7681,  0.7826, -0.3173])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 7 \n",
      "neural: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 8 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 9 \n",
      "neural: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 10 \n",
      "neural: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 11 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 12 \n",
      "neural: tensor([-0.1698,  0.1502,  0.3260,  0.8460,  0.0127], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 21 \n",
      "mapped: tensor([-0.1698,  0.1502,  0.3260,  0.8460,  0.0127], device='cuda:0')\n",
      "\n",
      "embedding token: 73 \n",
      "character: F \n",
      "in train set: True \n",
      "embedded: tensor([-0.1698,  0.1502,  0.3260,  0.8460,  0.0127])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 13 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 14 \n",
      "neural: tensor([ 1.4702,  1.8208, -0.8600, -0.7780, -0.6608], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 26 \n",
      "mapped: tensor([ 1.4702,  1.8208, -0.8600, -0.7780, -0.6608], device='cuda:0')\n",
      "\n",
      "embedding token: 81 \n",
      "character: N \n",
      "in train set: True \n",
      "embedded: tensor([ 1.4702,  1.8208, -0.8600, -0.7780, -0.6608])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 15 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 16 \n",
      "neural: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 45 \n",
      "mapped: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "embedding token: 124 \n",
      "character: y \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 17 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 18 \n",
      "neural: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 19 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 20 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 21 \n",
      "neural: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 57 \n",
      "mapped: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 22 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 23 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 24 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 25 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 26 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 27 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 28 \n",
      "neural: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 29 \n",
      "neural: tensor([-0.0547, -0.7046,  0.9982,  0.6798, -0.5764], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([-0.0547, -0.7046,  0.9982,  0.6798, -0.5764], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.0547, -0.7046,  0.9982,  0.6798, -0.5764])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 30 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 31 \n",
      "neural: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 45 \n",
      "mapped: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "embedding token: 124 \n",
      "character: y \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 32 \n",
      "neural: tensor([-1.4437, -0.4867, -0.6843, -0.5322, -0.9437], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 18 \n",
      "mapped: tensor([-1.4437, -0.4867, -0.6843, -0.5322, -0.9437], device='cuda:0')\n",
      "\n",
      "embedding token: 87 \n",
      "character: T \n",
      "in train set: True \n",
      "embedded: tensor([-1.4437, -0.4867, -0.6843, -0.5322, -0.9437])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 33 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 34 \n",
      "neural: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 35 \n",
      "neural: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 48 \n",
      "mapped: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 36 \n",
      "neural: tensor([-1.2384,  1.7962, -0.6179,  0.4637, -0.0990], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([-1.2384,  1.7962, -0.6179,  0.4637, -0.0990], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.2384,  1.7962, -0.6179,  0.4637, -0.0990])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 37 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 38 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 39 \n",
      "neural: tensor([-1.2384,  1.7962, -0.6179,  0.4637, -0.0990], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 6 \n",
      "mapped: tensor([-1.2384,  1.7962, -0.6179,  0.4637, -0.0990], device='cuda:0')\n",
      "\n",
      "embedding token: 108 \n",
      "character: i \n",
      "in train set: True \n",
      "embedded: tensor([-1.2384,  1.7962, -0.6179,  0.4637, -0.0990])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 40 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 41 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 42 \n",
      "neural: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 43 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 44 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 45 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 46 \n",
      "neural: tensor([ 1.4645, -0.1240, -0.1942,  0.2262, -0.3106], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 22 \n",
      "mapped: tensor([ 1.4645, -0.1240, -0.1942,  0.2262, -0.3106], device='cuda:0')\n",
      "\n",
      "embedding token: 90 \n",
      "character: W \n",
      "in train set: True \n",
      "embedded: tensor([ 1.4645, -0.1240, -0.1942,  0.2262, -0.3106])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 47 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 48 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 49 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 50 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 51 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 52 \n",
      "neural: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 48 \n",
      "mapped: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 53 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 54 \n",
      "neural: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 45 \n",
      "mapped: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "embedding token: 124 \n",
      "character: y \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 55 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 56 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 57 \n",
      "neural: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 57 \n",
      "mapped: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 58 \n",
      "neural: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 59 \n",
      "neural: tensor([-0.0547, -0.7046,  0.9982,  0.6798, -0.5764], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 29 \n",
      "mapped: tensor([-0.0547, -0.7046,  0.9982,  0.6798, -0.5764], device='cuda:0')\n",
      "\n",
      "embedding token: 119 \n",
      "character: t \n",
      "in train set: True \n",
      "embedded: tensor([-0.0547, -0.7046,  0.9982,  0.6798, -0.5764])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 60 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 61 \n",
      "neural: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 62 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 63 \n",
      "neural: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 64 \n",
      "neural: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 45 \n",
      "mapped: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "embedding token: 124 \n",
      "character: y \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 65 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 66 \n",
      "neural: tensor([1.4368, 0.4406, 0.7256, 0.6194, 0.8896], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 52 \n",
      "mapped: tensor([1.4368, 0.4406, 0.7256, 0.6194, 0.8896], device='cuda:0')\n",
      "\n",
      "embedding token: 92 \n",
      "character: Y \n",
      "in train set: True \n",
      "embedded: tensor([1.4368, 0.4406, 0.7256, 0.6194, 0.8896])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 67 \n",
      "neural: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 9 \n",
      "mapped: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522], device='cuda:0')\n",
      "\n",
      "embedding token: 114 \n",
      "character: o \n",
      "in train set: True \n",
      "embedded: tensor([1.4569, 1.3243, 0.5484, 0.5818, 0.5522])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 68 \n",
      "neural: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 57 \n",
      "mapped: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 69 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 70 \n",
      "neural: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 1 \n",
      "mapped: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514], device='cuda:0')\n",
      "\n",
      "embedding token: 118 \n",
      "character: s \n",
      "in train set: True \n",
      "embedded: tensor([-0.4834, -0.3367,  0.6652, -1.3343, -0.0514])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 71 \n",
      "neural: tensor([-0.3317,  0.4330, -1.1026,  1.4446, -2.1696], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 37 \n",
      "mapped: tensor([-0.3317,  0.4330, -1.1026,  1.4446, -2.1696], device='cuda:0')\n",
      "\n",
      "embedding token: 61 \n",
      "character: : \n",
      "in train set: True \n",
      "embedded: tensor([-0.3317,  0.4330, -1.1026,  1.4446, -2.1696])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 72 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 73 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 74 \n",
      "neural: tensor([ 1.4645, -0.1240, -0.1942,  0.2262, -0.3106], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 22 \n",
      "mapped: tensor([ 1.4645, -0.1240, -0.1942,  0.2262, -0.3106], device='cuda:0')\n",
      "\n",
      "embedding token: 90 \n",
      "character: W \n",
      "in train set: True \n",
      "embedded: tensor([ 1.4645, -0.1240, -0.1942,  0.2262, -0.3106])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 75 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 76 \n",
      "neural: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 4 \n",
      "mapped: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00],\n",
      "       device='cuda:0')\n",
      "\n",
      "embedding token: 100 \n",
      "character: a \n",
      "in train set: True \n",
      "embedded: tensor([ 5.1679e-01,  8.6784e-02,  1.0570e+00,  3.9565e-04, -1.2517e+00])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 77 \n",
      "neural: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 45 \n",
      "mapped: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109], device='cuda:0')\n",
      "\n",
      "embedding token: 124 \n",
      "character: y \n",
      "in train set: True \n",
      "embedded: tensor([ 0.3745, -1.3950, -1.7024, -0.6333,  0.8109])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 78 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 79 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 80 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 81 \n",
      "neural: tensor([-1.5364,  1.0786, -0.2787, -0.7804,  0.5690], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 27 \n",
      "mapped: tensor([-1.5364,  1.0786, -0.2787, -0.7804,  0.5690], device='cuda:0')\n",
      "\n",
      "embedding token: 79 \n",
      "character: L \n",
      "in train set: True \n",
      "embedded: tensor([-1.5364,  1.0786, -0.2787, -0.7804,  0.5690])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 82 \n",
      "neural: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 57 \n",
      "mapped: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378], device='cuda:0')\n",
      "\n",
      "embedding token: 120 \n",
      "character: u \n",
      "in train set: True \n",
      "embedded: tensor([ 0.4284,  0.2211, -1.5318,  1.8892, -0.0378])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 83 \n",
      "neural: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 3 \n",
      "mapped: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208], device='cuda:0')\n",
      "\n",
      "embedding token: 117 \n",
      "character: r \n",
      "in train set: True \n",
      "embedded: tensor([-0.2765, -0.7346, -1.3783,  1.1209,  0.3208])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 84 \n",
      "neural: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 20 \n",
      "mapped: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 85 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 86 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 87 \n",
      "neural: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 88 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 89 \n",
      "neural: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 90 \n",
      "neural: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 8 \n",
      "mapped: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626], device='cuda:0')\n",
      "\n",
      "embedding token: 113 \n",
      "character: n \n",
      "in train set: True \n",
      "embedded: tensor([ 3.0722,  0.6266,  0.6302, -0.3986,  0.7626])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 91 \n",
      "neural: tensor([ 1.5104, -0.0371, -0.1259,  0.9550, -2.3700], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 11 \n",
      "mapped: tensor([ 1.5104, -0.0371, -0.1259,  0.9550, -2.3700], device='cuda:0')\n",
      "\n",
      "embedding token: 106 \n",
      "character: g \n",
      "in train set: True \n",
      "embedded: tensor([ 1.5104, -0.0371, -0.1259,  0.9550, -2.3700])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 92 \n",
      "neural: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 7 \n",
      "mapped: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967], device='cuda:0')\n",
      "\n",
      "embedding token: 107 \n",
      "character: h \n",
      "in train set: True \n",
      "embedded: tensor([ 1.7663, -0.7250,  3.2579,  0.1593,  0.4967])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 93 \n",
      "neural: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 35 \n",
      "mapped: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632], device='cuda:0')\n",
      "\n",
      "embedding token: 104 \n",
      "character: e \n",
      "in train set: True \n",
      "embedded: tensor([ 0.1269, -0.0224,  0.8625,  1.0221,  0.8632])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 94 \n",
      "neural: tensor([ 0.0807, -0.4743, -0.3186,  2.7648, -0.1959], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 10 \n",
      "mapped: tensor([ 0.0807, -0.4743, -0.3186,  2.7648, -0.1959], device='cuda:0')\n",
      "\n",
      "embedding token: 122 \n",
      "character: w \n",
      "in train set: True \n",
      "embedded: tensor([ 0.0807, -0.4743, -0.3186,  2.7648, -0.1959])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 95 \n",
      "neural: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 20 \n",
      "mapped: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424], device='cuda:0')\n",
      "\n",
      "embedding token: 47 \n",
      "character: , \n",
      "in train set: True \n",
      "embedded: tensor([ 0.7509, -1.1675, -0.1910, -1.9385, -0.2424])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 96 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 97 \n",
      "neural: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 23 \n",
      "mapped: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224], device='cuda:0')\n",
      "\n",
      "embedding token: 103 \n",
      "character: d \n",
      "in train set: True \n",
      "embedded: tensor([-0.4850,  2.2402, -0.3711,  0.6949,  1.0224])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 98 \n",
      "neural: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 0 \n",
      "mapped: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816], device='cuda:0')\n",
      "\n",
      "embedding token: 35 \n",
      "character:   \n",
      "in train set: True \n",
      "embedded: tensor([-0.3899,  0.3568,  0.4981,  0.5968,  1.4816])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "temporal index: 99 \n",
      "neural: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939], device='cuda:0')\n",
      "\n",
      "model.neural_embedding token: 48 \n",
      "mapped: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939], device='cuda:0')\n",
      "\n",
      "embedding token: 101 \n",
      "character: b \n",
      "in train set: True \n",
      "embedded: tensor([-0.6620, -0.2256, -0.9905,  0.2322, -0.9939])\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "\n",
    "# Assert should not be raised if the model learned to correctly map the tokens in the training set\n",
    "for idx in range(data_gen.shape[1]):\n",
    "    neural = data_gen[:, [idx], :]\n",
    "    print(\"temporal index:\", idx, \"\\nneural:\", neural.squeeze()[:5], end=\"\\n\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ct = model.tokenize_neural_data(neural).item()\n",
    "    mapped = model.neural_embedding[torch.tensor(ct, dtype=torch.long)]\n",
    "    print(\"model.neural_embedding token:\", ct, \"\\nmapped:\", mapped[:5], end=\"\\n\\n\")\n",
    "\n",
    "    assert torch.allclose(neural, mapped), \"Basic check failed; Inconsistency in mapping!\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        et = model.tokenize_neural_data(neural, token_matrix=embedding.weight).item()\n",
    "    embedded = embedding(torch.tensor(et, dtype=torch.long))\n",
    "    print(\n",
    "        \"embedding token:\",\n",
    "        et,\n",
    "        \"\\ncharacter:\",\n",
    "        tokenizer.decode([et]),\n",
    "        \"\\nin train set:\",\n",
    "        et in real_train_tokens,\n",
    "        \"\\nembedded:\",\n",
    "        embedded[:5],\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    if et in real_train_tokens:\n",
    "        assert torch.any(neural != 0), \"Model did not learn to map a vector it was trained on!\"\n",
    "        assert torch.allclose(\n",
    "            embedded, mapped.cpu()\n",
    "        ), \"The learned embedding did not converge to the true embedding!\"\n",
    "\n",
    "    print(\"~\" * 99, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
