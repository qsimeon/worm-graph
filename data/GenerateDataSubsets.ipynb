{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create worm datasets of various sizes by subsampling a larger combined datasets\n",
    "---\n",
    "*Last updated: 14 November 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from itertools import combinations\n",
    "from utils import init_random_seeds\n",
    "from data._utils import generate_all_subsets, generate_subsets_of_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "init_random_seeds(seed)\n",
    "\n",
    "# Load combined dataset and print some information about it\n",
    "datadir = \"combined_dataset\"\n",
    "file = os.path.join(datadir, \"combined_dataset.pickle\")\n",
    "combined_dataset = pickle.load(open(file, \"rb\"))  # a few GBs large\n",
    "num_worms = len(combined_dataset.keys())\n",
    "print(f\"number of worms (N): {num_worms}\", end=\"\\n\\n\")\n",
    "print(f\"all worm Ids:\\n {list(combined_dataset.keys())}\", end=\"\\n\\n\")\n",
    "print(f\"data keys for each worm' data:\\n {list(combined_dataset['worm0'].keys())}\")\n",
    "\n",
    "# Example of coosing all subsets of size N-1 of the wormIDs when N\n",
    "all_worm_ids = list(combined_dataset.keys())\n",
    "worm_subsets = combinations(all_worm_ids, len(all_worm_ids) - 1)\n",
    "for i, subset in enumerate(worm_subsets):\n",
    "    print(f\"{i}: {subset[-5:]}\")\n",
    "    if i == 2:\n",
    "        break\n",
    "print()\n",
    "\n",
    "# Generate 10 of all the possible size-3 subsets\n",
    "# returns list of datasets containing 3 worms\n",
    "subsets_3 = generate_subsets_of_size(combined_dataset, subset_size=3, max_subsets=10)\n",
    "print(type(subsets_3))\n",
    "print(len(subsets_3))\n",
    "print(type(subsets_3[0]))\n",
    "print()\n",
    "for _, subset in enumerate(subsets_3):\n",
    "    print(f\"{_}: {tuple(subset.keys())}\")\n",
    "print()\n",
    "\n",
    "# Generate 10 of each size-n subset for n from 1 to 20;\n",
    "# returns dict mapping n to list of datasets containing n worms\n",
    "all_subsets = generate_all_subsets(\n",
    "    combined_dataset,\n",
    "    max_subsets_per_size=10,\n",
    "    max_size=20,\n",
    ")\n",
    "print(type(all_subsets))\n",
    "print(len(all_subsets))\n",
    "print()\n",
    "for size, subsets in all_subsets.items():\n",
    "    print(f\"size {size}: \\t num. subsets: {len(subsets)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
