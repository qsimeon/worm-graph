{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create worm datasets of various sizes by subsampling a larger combined datasets\n",
    "---\n",
    "*Last updated: 14 November 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "from itertools import combinations\n",
    "from utils import init_random_seeds\n",
    "from data._utils import generate_all_subsets, generate_subsets_of_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "init_random_seeds(seed)\n",
    "\n",
    "# Settings for pretty printing\n",
    "pp = PrettyPrinter(indent=4, width=100, compact=True)\n",
    "\n",
    "# Load combined dataset and print some information about it\n",
    "# datadir = \"custom\"\n",
    "datadir = \"processed/neural\"\n",
    "# file = os.path.join(datadir, \"combined_dataset.pickle\")\n",
    "file = os.path.join(datadir, \"VanDerPol0000.pickle\")\n",
    "combined_dataset = pickle.load(open(file, \"rb\"))  # a few GBs large\n",
    "num_worms = len(combined_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of worms (N): 6\n",
      "\n",
      "\"all worm IDs: ['worm0', 'worm1', 'worm2', 'worm3', 'worm4', 'worm5']\"\n",
      "\n",
      "data keys for each worm' data:\n",
      "[   'dataset', 'smooth_method', 'worm', 'calcium_data', 'smooth_calcium_data', 'residual_calcium',\n",
      "    'smooth_residual_calcium', 'max_timesteps', 'time_in_seconds', 'dt', 'resample_median_dt',\n",
      "    'num_neurons', 'num_named_neurons', 'num_unknown_neurons', 'named_neurons_mask',\n",
      "    'unknown_neurons_mask', 'neurons_mask', 'slot_to_named_neuron', 'named_neuron_to_slot',\n",
      "    'slot_to_unknown_neuron', 'unknown_neuron_to_slot', 'slot_to_neuron', 'neuron_to_slot',\n",
      "    'original_time_in_seconds', 'original_dt', 'original_median_dt', 'original_calcium_data',\n",
      "    'original_smooth_calcium_data', 'original_residual_calcium',\n",
      "    'original_smooth_residual_calcium']\n",
      "\n",
      "Last 5 items of the first 3 subset sizes:\n",
      "\t0: ('worm0', 'worm1', 'worm2', 'worm3', 'worm4')\n",
      "\t1: ('worm0', 'worm1', 'worm2', 'worm3', 'worm5')\n",
      "\t2: ('worm0', 'worm1', 'worm2', 'worm4', 'worm5')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the dataset\n",
    "print(f\"number of worms (N): {num_worms}\", end=\"\\n\\n\")\n",
    "pp.pprint(\"all worm IDs: {}\".format(list(combined_dataset.keys())))\n",
    "print()\n",
    "print(f\"data keys for each worm' data:\")\n",
    "pp.pprint(list(combined_dataset[\"worm0\"].keys()))\n",
    "print()\n",
    "\n",
    "# Example of choosing all subsets of size n = N-1 of the wormIDs,\n",
    "# where N is the number of worms in the combined dataset\n",
    "all_worm_ids = list(combined_dataset.keys())\n",
    "N = num_worms\n",
    "worm_subsets = combinations(all_worm_ids, N - 1)\n",
    "\n",
    "# Print some information about the subsets\n",
    "first_n_subsets = 3  # can be very long if we display all\n",
    "last_x_items = 5  # can be very long if we display all\n",
    "print(f\"Last {last_x_items} items of the first {first_n_subsets} subset sizes:\")\n",
    "for i, subset in enumerate(worm_subsets):\n",
    "    print(f\"\\t{i}: {subset[-last_x_items:]}\")\n",
    "    if i == first_n_subsets - 1:\n",
    "        break\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(subsets_n): <class 'list'>\n",
      "len(subsets_n): 5\n",
      "type(subsets_n[0]): <class 'dict'>\n",
      "\n",
      "\tExample # \t Dataset/Worms\n",
      "\t----------------------------------------\n",
      "\t\t1: \t ('VanDerPol0000',)\n",
      "\t\t2: \t ('VanDerPol0000',)\n",
      "\t\t3: \t ('VanDerPol0000',)\n",
      "\t\t4: \t ('VanDerPol0000',)\n",
      "\t\t5: \t ('VanDerPol0000',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate `num_examples` of all the possible size-n subsets;\n",
    "# Returns a list of the data(sub)sets containing n worms.\n",
    "num_examples = 5\n",
    "n = 3\n",
    "subsets_n = generate_subsets_of_size(\n",
    "    combined_dataset,\n",
    "    subset_size=n,\n",
    "    max_subsets=num_examples,\n",
    "    as_assignment=True,\n",
    ")\n",
    "print(f\"type(subsets_n): {type(subsets_n)}\")\n",
    "print(f\"len(subsets_n): {len(subsets_n)}\")\n",
    "print(f\"type(subsets_n[0]): {type(subsets_n[0])}\")\n",
    "print()\n",
    "print(f\"\\tExample # \\t Dataset/Worms\")\n",
    "print(f\"\\t{'-'*40}\")\n",
    "for _, subset in enumerate(subsets_n):\n",
    "    print(f\"\\t\\t{_+1}: \\t {tuple(subset.keys())}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttype(all_subsets): <class 'dict'>\n",
      "\tlen(all_subsets): 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 2 examples of each size-n subset for n from 1 to N-1,\n",
    "# where N is the number of worms in the combined dataset;\n",
    "# returns dict mapping n to list of datasets containing n worms\n",
    "num_examples = 2\n",
    "N = len(combined_dataset)\n",
    "all_subsets = generate_all_subsets(\n",
    "    combined_dataset,\n",
    "    max_subsets_per_size=num_examples,  # `max_subsets_per_size` examples\n",
    "    max_size=N - 1,  # n = max_size, the size of the largest subset to generate\n",
    "    as_assignment=True,\n",
    ")\n",
    "print(f\"\\ttype(all_subsets): {type(all_subsets)}\")\n",
    "print(f\"\\tlen(all_subsets): {len(all_subsets)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of worms in the first assignment:\n",
      "size 1: \t num. subsets: 2 \t example: {'VanDerPol0000': 1}\n",
      "size 2: \t num. subsets: 2 \t example: {'VanDerPol0000': 2}\n",
      "size 3: \t num. subsets: 2 \t example: {'VanDerPol0000': 3}\n",
      "size 4: \t num. subsets: 2 \t example: {'VanDerPol0000': 4}\n",
      "size 5: \t num. subsets: 2 \t example: {'VanDerPol0000': 5}\n",
      "\n",
      "Distribution of worms in the the second assignment:\n",
      "size 1: \t num. subsets: 2 \t example: {'VanDerPol0000': 1}\n",
      "size 2: \t num. subsets: 2 \t example: {'VanDerPol0000': 2}\n",
      "size 3: \t num. subsets: 2 \t example: {'VanDerPol0000': 3}\n",
      "size 4: \t num. subsets: 2 \t example: {'VanDerPol0000': 4}\n",
      "size 5: \t num. subsets: 2 \t example: {'VanDerPol0000': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By using the `as_assignment=True` argument, we get a way to distribute worms to different\n",
    "# experimental datasets such that we achieve the desired combined dataset size.\n",
    "print(\"Distribution of worms in the first assignment:\")\n",
    "for size, subsets in all_subsets.items():\n",
    "    print(f\"size {size}: \\t num. subsets: {len(subsets)} \\t example: {subsets[0]}\")\n",
    "print()\n",
    "\n",
    "print(\"Distribution of worms in the the second assignment:\")\n",
    "for size, subsets in all_subsets.items():\n",
    "    print(f\"size {size}: \\t num. subsets: {len(subsets)} \\t example: {subsets[1]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttype(all_subsets): <class 'dict'>\n",
      "\tlen(all_subsets): 5\n",
      "\n",
      "Distribution of worms in assignment:\n",
      "\n",
      "size 1: \t num. subsets: 1 \t example: {'VanDerPol0000': 1}\n",
      "size 2: \t num. subsets: 1 \t example: {'VanDerPol0000': 2}\n",
      "size 3: \t num. subsets: 1 \t example: {'VanDerPol0000': 3}\n",
      "size 4: \t num. subsets: 1 \t example: {'VanDerPol0000': 4}\n",
      "size 5: \t num. subsets: 1 \t example: {'VanDerPol0000': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do one assignment for data subset sizes from 1 and N-1\n",
    "num_examples = 1\n",
    "N = len(combined_dataset)\n",
    "all_subsets = generate_all_subsets(\n",
    "    combined_dataset,\n",
    "    max_subsets_per_size=num_examples,\n",
    "    max_size=N - 1,  #  `max_size=None`/ `max_size=N` subsets of all sizes from 1 to N\n",
    "    as_assignment=True,\n",
    ")\n",
    "print(f\"\\ttype(all_subsets): {type(all_subsets)}\")\n",
    "print(f\"\\tlen(all_subsets): {len(all_subsets)}\")\n",
    "print()\n",
    "print(\"Distribution of worms in assignment:\", end=\"\\n\\n\")\n",
    "for size, subsets in all_subsets.items():\n",
    "    print(f\"size {size}: \\t num. subsets: {len(subsets)} \\t example: {subsets[0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{VanDerPol0000:1},{VanDerPol0000:2},{VanDerPol0000:3},{VanDerPol0000:4},{VanDerPol0000:5}\n"
     ]
    }
   ],
   "source": [
    "# Example of how to get the Hydra config string\n",
    "hydra_str = \"\"\n",
    "for size, subsets in all_subsets.items():\n",
    "    # removing quotes is important as hydra config parser treats parameters as a string\n",
    "    _str = str(subsets[0]).replace(\"'\", \"\")\n",
    "    # need to remive space after colon (:) as hydra config parser throws an error otherwise\n",
    "    _str = _str.replace(\": \", \":\")\n",
    "    hydra_str += f\"{_str},\"\n",
    "hydra_str = hydra_str[:-1]\n",
    "print(f\"{hydra_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
