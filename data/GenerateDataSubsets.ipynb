{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create worm datasets of various sizes by subsampling a larger combined datasets\n",
    "---\n",
    "*Last updated: 14 November 2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from pprint import PrettyPrinter\n",
    "from itertools import combinations\n",
    "from utils import init_random_seeds\n",
    "from data._utils import generate_all_subsets, generate_subsets_of_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "init_random_seeds(seed)\n",
    "\n",
    "# Settings for pretty printing\n",
    "pp = PrettyPrinter(indent=4, width=100, compact=True)\n",
    "\n",
    "# Load combined dataset and print some information about it\n",
    "# datadir = \"custom\"\n",
    "datadir = \"processed/neural\"\n",
    "# file = os.path.join(datadir, \"combined_dataset.pickle\")\n",
    "file = os.path.join(datadir, \"VanDerPol0000.pickle\")\n",
    "combined_dataset = pickle.load(open(file, \"rb\"))  # a few GBs large\n",
    "num_worms = len(combined_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of worms (N): 6\n",
      "\n",
      "\"all worm IDs: ['worm0', 'worm1', 'worm2', 'worm3', 'worm4', 'worm5']\"\n",
      "\n",
      "data keys for each worm' data:\n",
      "[   'dataset', 'smooth_method', 'worm', 'calcium_data', 'smooth_calcium_data', 'residual_calcium',\n",
      "    'smooth_residual_calcium', 'max_timesteps', 'time_in_seconds', 'dt', 'resample_median_dt',\n",
      "    'num_neurons', 'num_named_neurons', 'num_unknown_neurons', 'named_neurons_mask',\n",
      "    'unknown_neurons_mask', 'neurons_mask', 'slot_to_named_neuron', 'named_neuron_to_slot',\n",
      "    'slot_to_unknown_neuron', 'unknown_neuron_to_slot', 'slot_to_neuron', 'neuron_to_slot',\n",
      "    'original_time_in_seconds', 'original_dt', 'original_median_dt', 'original_calcium_data',\n",
      "    'original_smooth_calcium_data', 'original_residual_calcium',\n",
      "    'original_smooth_residual_calcium']\n",
      "\n",
      "Last five items of the first three subset sizes:\n",
      "\t0: ('worm0', 'worm1', 'worm2', 'worm3', 'worm4')\n",
      "\t1: ('worm0', 'worm1', 'worm2', 'worm3', 'worm5')\n",
      "\t2: ('worm0', 'worm1', 'worm2', 'worm4', 'worm5')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information about the dataset\n",
    "print(f\"number of worms (N): {num_worms}\", end=\"\\n\\n\")\n",
    "pp.pprint(\"all worm IDs: {}\".format(list(combined_dataset.keys())))\n",
    "print()\n",
    "print(f\"data keys for each worm' data:\")\n",
    "pp.pprint(list(combined_dataset[\"worm0\"].keys()))\n",
    "print()\n",
    "\n",
    "# Example of choosing all subsets of size N-1 of the wormIDs when N\n",
    "all_worm_ids = list(combined_dataset.keys())\n",
    "worm_subsets = combinations(all_worm_ids, len(all_worm_ids) - 1)\n",
    "print(\"Last five items of the first three subset sizes:\")\n",
    "for i, subset in enumerate(worm_subsets):\n",
    "    print(f\"\\t{i}: {subset[-5:]}\")\n",
    "    if i == 2:\n",
    "        break\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttype(subsets_3): <class 'list'>\n",
      "\tlen(subsets_3): 5\n",
      "\ttype(subsets_3[0]): <class 'dict'>\n",
      "\n",
      "1: ('VanDerPol0000',)\n",
      "2: ('VanDerPol0000',)\n",
      "3: ('VanDerPol0000',)\n",
      "4: ('VanDerPol0000',)\n",
      "5: ('VanDerPol0000',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 examples of all the possible size-3 subsets\n",
    "# returns list of datasets containing 3 worms\n",
    "subsets_3 = generate_subsets_of_size(\n",
    "    combined_dataset,\n",
    "    subset_size=3,\n",
    "    max_subsets=5,\n",
    "    as_assignment=True,\n",
    ")\n",
    "print(f\"\\ttype(subsets_3): {type(subsets_3)}\")\n",
    "print(f\"\\tlen(subsets_3): {len(subsets_3)}\")\n",
    "print(f\"\\ttype(subsets_3[0]): {type(subsets_3[0])}\")\n",
    "print()\n",
    "for _, subset in enumerate(subsets_3):\n",
    "    print(f\"{_+1}: {tuple(subset.keys())}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttype(all_subsets): <class 'dict'>\n",
      "\tlen(all_subsets): 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate 2 examples of each size-n subset for n from 1 to 20;\n",
    "# returns dict mapping n to list of datasets containing n worms\n",
    "all_subsets = generate_all_subsets(\n",
    "    combined_dataset,\n",
    "    max_subsets_per_size=2,\n",
    "    max_size=5,  # 20,\n",
    "    as_assignment=True,\n",
    ")\n",
    "print(f\"\\ttype(all_subsets): {type(all_subsets)}\")\n",
    "print(f\"\\tlen(all_subsets): {len(all_subsets)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of worms in the first assignment:\n",
      "size 1: \t num. subsets: 2 \t example: {'VanDerPol0000': 1}\n",
      "size 2: \t num. subsets: 2 \t example: {'VanDerPol0000': 2}\n",
      "size 3: \t num. subsets: 2 \t example: {'VanDerPol0000': 3}\n",
      "size 4: \t num. subsets: 2 \t example: {'VanDerPol0000': 4}\n",
      "size 5: \t num. subsets: 2 \t example: {'VanDerPol0000': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# By using the `as_assignment=True` argument, we get a way to distribute worms to different\n",
    "# experimental datasets such that we achieve the desired combined dataset size.\n",
    "print(\"Distribution of worms in the first assignment:\")\n",
    "for size, subsets in all_subsets.items():\n",
    "    print(f\"size {size}: \\t num. subsets: {len(subsets)} \\t example: {subsets[0]}\")\n",
    "print()\n",
    "\n",
    "# print(\"Distribution of worms in the the second assignment:\")\n",
    "# for size, subsets in all_subsets.items():\n",
    "#     print(f\"size {size}: \\t num. subsets: {len(subsets)} \\t example: {subsets[1]}\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttype(all_subsets): <class 'dict'>\n",
      "\tlen(all_subsets): 6\n",
      "\n",
      "Distribution of worms in assignment:\n",
      "size 1: \t num. subsets: 1 \t example: {'VanDerPol0000': 1}\n",
      "size 2: \t num. subsets: 1 \t example: {'VanDerPol0000': 2}\n",
      "size 3: \t num. subsets: 1 \t example: {'VanDerPol0000': 3}\n",
      "size 4: \t num. subsets: 1 \t example: {'VanDerPol0000': 4}\n",
      "size 5: \t num. subsets: 1 \t example: {'VanDerPol0000': 5}\n",
      "size 6: \t num. subsets: 1 \t example: {'VanDerPol0000': 6}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do one assignment for all possible data subset sizes\n",
    "all_subsets = generate_all_subsets(\n",
    "    combined_dataset,\n",
    "    max_subsets_per_size=1,\n",
    "    max_size=None,\n",
    "    as_assignment=True,\n",
    ")\n",
    "print(f\"\\ttype(all_subsets): {type(all_subsets)}\")\n",
    "print(f\"\\tlen(all_subsets): {len(all_subsets)}\")\n",
    "print()\n",
    "print(\"Distribution of worms in assignment:\")\n",
    "for size, subsets in all_subsets.items():\n",
    "    print(f\"size {size}: \\t num. subsets: {len(subsets)} \\t example: {subsets[0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{VanDerPol0000:1},{VanDerPol0000:2},{VanDerPol0000:3},{VanDerPol0000:4},{VanDerPol0000:5},{VanDerPol0000:6}\n"
     ]
    }
   ],
   "source": [
    "# Example of how to get the Hydra config string\n",
    "hydra_str = \"\"\n",
    "for size, subsets in all_subsets.items():\n",
    "    # removing quotes is important as hydra config parser treats parameters as a string\n",
    "    _str = str(subsets[0]).replace(\"'\", \"\")\n",
    "    # need to remive space after colon (:) as hydra config parser throws an error otherwise\n",
    "    _str = _str.replace(\": \", \":\")\n",
    "    hydra_str += f\"{_str},\"\n",
    "hydra_str = hydra_str[:-1]\n",
    "print(f\"{hydra_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
