{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from visualize._utils import draw_connectome\n",
    "from utils import ROOT_DIR\n",
    "from torch_geometric.data import Data\n",
    "from tests.leandro.plots import *\n",
    "from data._main import get_dataset\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph attributes: ['n_id', 'y', 'node_type', 'pos', 'edge_index', 'num_classes', 'edge_attr', 'idx_to_neuron', 'x']\n",
      "Num. nodes: 302, Num. edges: 4396, Num. node features: 1024\n"
     ]
    }
   ],
   "source": [
    "# load the connectome data\n",
    "graph_tensors = torch.load(\n",
    "    os.path.join(ROOT_DIR, \"data\", \"processed\", \"connectome\", \"graph_tensors.pt\")\n",
    ")\n",
    "\n",
    "# make the graph\n",
    "graph = Data(**graph_tensors)\n",
    "\n",
    "print('Graph attributes: {}'.format(graph.keys))\n",
    "print('Num. nodes: {}, Num. edges: {}, Num. node features: {}'.format(graph.num_nodes, graph.num_edges, graph.num_node_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_to_idx = {u: v for (v, u) in graph.idx_to_neuron.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4396])\n",
      "torch.Size([4396, 2])\n"
     ]
    }
   ],
   "source": [
    "def get_connected_neuron_indexes(graph, neuron_name):\n",
    "\n",
    "    neuron_to_idx = {u: v for (v, u) in graph.idx_to_neuron.items()}\n",
    "\n",
    "    # Get the edge indices corresponding to the given node\n",
    "    node_index = neuron_to_idx[neuron_name]\n",
    "    connected_edge_indices = (graph.edge_index[0] == node_index).nonzero()\n",
    "\n",
    "    # Get the connected nodes by extracting the second row of the connected_edge_indices\n",
    "    connected_nodes = graph.edge_index[1, connected_edge_indices].flatten()\n",
    "    \n",
    "    return connected_nodes\n",
    "\n",
    "print(graph.edge_index.shape) # Row 0: source, Row 1: target\n",
    "\n",
    "print(graph.edge_attr.shape) # Column 0: gap junction connections, Column 1: chemical synapse connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   6,  10,  12,  13,  53,  54,  55,  56,  57,  58,  59,  67,\n",
       "        155, 179, 191, 192, 199, 201, 247, 250, 254])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_neurons = get_connected_neuron_indexes(graph, 'ADAL')\n",
    "connected_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen dataset(s): ['Flavell2023']\n",
      "Num. worms: 50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(\"/home/lrvnc/Projects/worm-graph/conf/dataset.yaml\")\n",
    "flavell_dataset = get_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worm ID: worm48\n"
     ]
    }
   ],
   "source": [
    "def get_one_worm_data(dataset):\n",
    "    wormid = np.random.choice([key for key in dataset.keys()])\n",
    "    oneWorm = dataset[wormid]\n",
    "    print('Worm ID: {}'.format(wormid))\n",
    "    calcium_data = oneWorm['calcium_data']\n",
    "    time_vector = oneWorm['time_in_seconds']\n",
    "    return oneWorm, calcium_data, time_vector\n",
    "\n",
    "oneWorm, calcium_data, time_vector = get_one_worm_data(flavell_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the HTML page containing the table\n",
    "url = \"https://www.wormatlas.org/neurons/Individual%20Neurons/Neuronframeset.html\"\n",
    "\n",
    "# Send a GET request to fetch the HTML content\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table in the HTML using its tag (e.g., <table>)\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Extract the data from the table\n",
    "data = []\n",
    "for row in table.find_all(\"tr\"):\n",
    "    # Extract each cell value in the row\n",
    "    row_data = []\n",
    "    for cell in row.find_all([\"th\", \"td\"]):\n",
    "        row_data.append(cell.get_text(strip=True))\n",
    "    data.append(row_data)\n",
    "\n",
    "neuron_texts = {}\n",
    "\n",
    "# Print the scraped data\n",
    "for row in data[5:-4]:\n",
    "    neuron_texts[row[0]] = [row[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ring interneuron']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_texts['ADAL']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible classes: motor, sensory, interneuron, sex, unknown + (polymodal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"\"\"\n",
    "You are a highly skilled specialist in the intricate classification of C. elegans neurons, the subject of much scientific fascination. Equipped with your expertise, you possess the ability to accurately classify each neuron you encounter. Upon receiving a message, you swiftly analyze the neuron and provide its classification as a Python dictionary in the following format:\n",
    "\n",
    "{\n",
    "    'class': <class>,\n",
    "    'sex': <sex>\n",
    "}\n",
    "\n",
    "In this format, the <class> key represents the specific category to which the neuron belongs, encompassing motor neurons responsible for movement, interneurons facilitating communication within the nervous system, and sensory neurons detecting and transmitting external stimuli. If a same neuron belongs to more than one class, write both of them separate by a comma. The <sex> key captures the gender identity of the C. elegans organism, which can be male, hermaphrodite, or a combination of both.\n",
    "\n",
    "By employing your expert knowledge and utilizing this standardized format, you contribute to the scientific understanding of C. elegans neurons and their diverse classifications, ultimately advancing our knowledge of neural circuitry and behavior.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dbd893c7d7416ee6c2fdeff774cde09b in your message.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m text \u001b[39m=\u001b[39m text[\u001b[39m0\u001b[39m]\n\u001b[1;32m     34\u001b[0m messages\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: text})\n\u001b[0;32m---> 35\u001b[0m response \u001b[39m=\u001b[39m get_completion(messages)\n\u001b[1;32m     36\u001b[0m \u001b[39mprint\u001b[39m(neuron, text, response)\n\u001b[1;32m     37\u001b[0m messages\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m: response})\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(messages, model)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion\u001b[39m(messages, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m      9\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m     10\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[1;32m     11\u001b[0m         temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, \u001b[39m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/om2/user/lrvenan/miniconda/envs/worm-graph/lib/python3.9/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/om2/user/lrvenan/miniconda/envs/worm-graph/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/om2/user/lrvenan/miniconda/envs/worm-graph/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/om2/user/lrvenan/miniconda/envs/worm-graph/lib/python3.9/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    613\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    614\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    615\u001b[0m         )\n\u001b[1;32m    616\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    617\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m/om2/user/lrvenan/miniconda/envs/worm-graph/lib/python3.9/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    681\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dbd893c7d7416ee6c2fdeff774cde09b in your message.)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import itertools\n",
    "\n",
    "API_KEY = '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'\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "def get_completion(messages, model=\"gpt-3.5-turbo\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "start_message = \"\"\"\n",
    "You are a highly skilled specialist in the intricate classification of C. elegans neurons, the subject of much scientific fascination. Equipped with your expertise, you possess the ability to accurately classify each neuron you encounter. Upon receiving a message, you swiftly analyze the neuron and provide its classification as a Python dictionary in the following format:\n",
    "\n",
    "{\n",
    "    'class': <class>,\n",
    "    'sex': <sex>\n",
    "}\n",
    "\n",
    "In this format, the <class> key represents the specific category to which the neuron belongs, encompassing motor neurons responsible for movement, interneurons facilitating communication within the nervous system, and sensory neurons detecting and transmitting external stimuli. If a same neuron belongs to more than one class, write both of them separate by a comma. The <sex> key captures the gender identity of the C. elegans organism, which can be male, hermaphrodite, or a combination of both.\n",
    "Output just the python dictionary, nothing else.\n",
    "By employing your expert knowledge and utilizing this standardized format, you contribute to the scientific understanding of C. elegans neurons and their diverse classifications, ultimately advancing our knowledge of neural circuitry and behavior.\n",
    "\"\"\"\n",
    "\n",
    "messages =  [  \n",
    "{'role':'system', 'content': start_message},    \n",
    "]\n",
    "\n",
    "for neuron, text in itertools.islice(neuron_texts.items(), 15):\n",
    "    text = text[0]\n",
    "    messages.append({'role':'user', 'content': text})\n",
    "    response = get_completion(messages)\n",
    "    print(neuron, text, response)\n",
    "    messages.append({'role':'assistant', 'content': response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_classification = {}\n",
    "\n",
    "for neuron in neuron_texts:\n",
    "    text = neuron_texts[neuron][0]\n",
    "    neuron_classification[neuron] = []\n",
    "\n",
    "    if 'SENSORY' in text.upper():\n",
    "        neuron_classification[neuron].append('sensory')\n",
    "\n",
    "    if 'AMPHID' in text.upper():\n",
    "        neuron_classification[neuron].append('sensory')\n",
    "    \n",
    "    if 'INTERNEURON' in text.upper():\n",
    "        neuron_classification[neuron].append('interneuron')\n",
    "\n",
    "    if 'MOTOR' in text:\n",
    "        neuron_classification[neuron].append('motor')\n",
    "    \n",
    "    if not 'Hermaphrodite' in text:\n",
    "        neuron_classification[neuron].append('male')\n",
    "\n",
    "    if not 'Male' in text.upper():\n",
    "        neuron_classification[neuron].append('hermaphrodite')\n",
    "\n",
    "for neuron in neuron_classification:\n",
    "    if len(neuron_classification[neuron]) == 2 and 'male' in neuron_classification[neuron] and 'hermaphrodite' in neuron_classification[neuron]:\n",
    "        neuron_classification[neuron].append('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALA ['male', 'hermaphrodite', 'unknown'] ['Neuron, sends processes laterally and along dorsal cord']\n",
      "ALML ['male', 'hermaphrodite', 'unknown'] ['Anterior lateral microtubule cell']\n",
      "ALMR ['male', 'hermaphrodite', 'unknown'] ['Anterior lateral microtubule cell']\n",
      "ALNL ['male', 'hermaphrodite', 'unknown'] ['Neuron associated with ALM']\n",
      "ALNR ['male', 'hermaphrodite', 'unknown'] ['Neuron associated with ALM']\n",
      "AQR ['male', 'hermaphrodite', 'unknown'] ['Neuron, basal body. not part of a sensillum, projects into ring']\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for neuron in neuron_classification:\n",
    "    classification = neuron_classification[neuron]\n",
    "    if 'unknown' in classification:\n",
    "        print(neuron, classification, neuron_texts[neuron])\n",
    "        i+=1\n",
    "        input()\n",
    "print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
