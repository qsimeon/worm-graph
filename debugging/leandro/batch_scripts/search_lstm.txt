[32m[I 2023-08-08 15:23:13,172][0m A new study created in memory with name: hyperparameter_search[0m
[2023-08-08 15:23:13,172][HYDRA] Study name: hyperparameter_search
[2023-08-08 15:23:13,172][HYDRA] Storage: None
[2023-08-08 15:23:13,173][HYDRA] Sampler: TPESampler
[2023-08-08 15:23:13,173][HYDRA] Directions: ['minimize']
[2023-08-08 15:23:13,220][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 15:23:13,226][HYDRA] 	#0 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=16 submodule.model.hidden_size=128 +experiment=hyperparameter_lstm
[2023-08-08 15:27:41,758][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 15:27:41,761][HYDRA] 	#1 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 15:35:42,911][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 15:35:42,915][HYDRA] 	#2 : submodule.train.optimizer=Adagrad submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=16 submodule.model.hidden_size=128 +experiment=hyperparameter_lstm
[2023-08-08 15:37:20,725][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 15:37:20,728][HYDRA] 	#3 : submodule.train.optimizer=Adagrad submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 15:42:19,280][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 15:42:19,282][HYDRA] 	#4 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 15:54:29,313][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 15:54:29,315][HYDRA] 	#5 : submodule.train.optimizer=Adam submodule.train.learn_rate=1e-05 submodule.train.seq_len=120 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 16:03:16,555][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:03:16,558][HYDRA] 	#6 : submodule.train.optimizer=Adam submodule.train.learn_rate=0.0001 submodule.train.seq_len=120 submodule.train.num_samples=16 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 16:09:17,305][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:09:17,307][HYDRA] 	#7 : submodule.train.optimizer=Adam submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=8 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 16:17:39,410][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:17:39,412][HYDRA] 	#8 : submodule.train.optimizer=AdamW submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=16 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 16:33:40,821][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:33:40,824][HYDRA] 	#9 : submodule.train.optimizer=Adagrad submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=8 submodule.model.hidden_size=128 +experiment=hyperparameter_lstm
[2023-08-08 16:35:02,686][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:35:02,688][HYDRA] 	#10 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=120 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 16:40:12,314][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:40:12,316][HYDRA] 	#11 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 16:53:43,386][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 16:53:43,388][HYDRA] 	#12 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 17:07:30,686][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:07:30,688][HYDRA] 	#13 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_lstm
[2023-08-08 17:20:33,836][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:20:33,838][HYDRA] 	#14 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 17:29:19,100][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:29:19,102][HYDRA] 	#15 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 17:35:19,909][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:35:19,911][HYDRA] 	#16 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=8 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 17:40:18,573][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:40:18,575][HYDRA] 	#17 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 17:46:05,313][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:46:05,315][HYDRA] 	#18 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 17:51:40,178][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_23_13
[2023-08-08 17:51:40,180][HYDRA] 	#19 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=8 submodule.model.hidden_size=512 +experiment=hyperparameter_lstm
[2023-08-08 17:56:14,808][HYDRA] Best parameters: {'submodule.train.optimizer': 'AdamW', 'submodule.train.learn_rate': 0.001, 'submodule.train.seq_len': 240, 'submodule.train.num_samples': 32, 'submodule.model.hidden_size': 256}
[2023-08-08 17:56:14,808][HYDRA] Best value: 0.004542529117316008
