[32m[I 2023-08-08 15:24:02,639][0m A new study created in memory with name: hyperparameter_search[0m
[2023-08-08 15:24:02,640][HYDRA] Study name: hyperparameter_search
[2023-08-08 15:24:02,640][HYDRA] Storage: None
[2023-08-08 15:24:02,640][HYDRA] Sampler: TPESampler
[2023-08-08 15:24:02,640][HYDRA] Directions: ['minimize']
[2023-08-08 15:24:02,693][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:24:02,697][HYDRA] 	#0 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=16 submodule.model.hidden_size=128 +experiment=hyperparameter_linear
[2023-08-08 15:26:31,412][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:26:31,416][HYDRA] 	#1 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 15:32:41,465][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:32:41,469][HYDRA] 	#2 : submodule.train.optimizer=Adagrad submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=16 submodule.model.hidden_size=128 +experiment=hyperparameter_linear
[2023-08-08 15:34:52,758][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:34:52,762][HYDRA] 	#3 : submodule.train.optimizer=Adagrad submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 15:38:30,441][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:38:30,445][HYDRA] 	#4 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 15:44:56,708][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:44:56,711][HYDRA] 	#5 : submodule.train.optimizer=Adam submodule.train.learn_rate=1e-05 submodule.train.seq_len=120 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 15:54:50,624][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:54:50,628][HYDRA] 	#6 : submodule.train.optimizer=Adam submodule.train.learn_rate=0.0001 submodule.train.seq_len=120 submodule.train.num_samples=16 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 15:57:36,072][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 15:57:36,075][HYDRA] 	#7 : submodule.train.optimizer=Adam submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=8 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 16:03:38,221][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:03:38,225][HYDRA] 	#8 : submodule.train.optimizer=AdamW submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=16 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 16:12:36,295][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:12:36,298][HYDRA] 	#9 : submodule.train.optimizer=Adagrad submodule.train.learn_rate=1e-05 submodule.train.seq_len=240 submodule.train.num_samples=8 submodule.model.hidden_size=128 +experiment=hyperparameter_linear
[2023-08-08 16:14:08,414][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:14:08,418][HYDRA] 	#10 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=120 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 16:17:19,921][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:17:19,924][HYDRA] 	#11 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 16:24:42,370][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:24:42,374][HYDRA] 	#12 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 16:31:57,853][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:31:57,857][HYDRA] 	#13 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.0001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=256 +experiment=hyperparameter_linear
[2023-08-08 16:39:29,358][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:39:29,362][HYDRA] 	#14 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 16:49:42,471][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:49:42,475][HYDRA] 	#15 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=60 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 16:52:58,122][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:52:58,125][HYDRA] 	#16 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.001 submodule.train.seq_len=240 submodule.train.num_samples=8 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 16:57:38,999][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 16:57:39,002][HYDRA] 	#17 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=240 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 17:04:56,561][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 17:04:56,563][HYDRA] 	#18 : submodule.train.optimizer=RMSprop submodule.train.learn_rate=0.001 submodule.train.seq_len=120 submodule.train.num_samples=32 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 17:12:48,161][HYDRA] Submitit 'slurm' sweep output dir : logs/hydra/2023_08_08_15_24_02
[2023-08-08 17:12:48,165][HYDRA] 	#19 : submodule.train.optimizer=AdamW submodule.train.learn_rate=0.001 submodule.train.seq_len=120 submodule.train.num_samples=8 submodule.model.hidden_size=512 +experiment=hyperparameter_linear
[2023-08-08 17:15:36,670][HYDRA] Best parameters: {'submodule.train.optimizer': 'AdamW', 'submodule.train.learn_rate': 0.001, 'submodule.train.seq_len': 240, 'submodule.train.num_samples': 32, 'submodule.model.hidden_size': 256}
[2023-08-08 17:15:36,670][HYDRA] Best value: 0.01087017823010683
