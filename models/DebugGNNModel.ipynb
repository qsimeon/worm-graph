{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Graph Neural Network Model based on the _C. elegans_ connectome.\n",
    "---\n",
    "Last Modified: 15 November, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from utils import ROOT_DIR\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Graph Convolutional Network (GCN): Core / Inner Model for NetworkGCN (work-in-progress)\n",
    "# TODO: Work on this model more.\n",
    "class GCNModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Convolutional Network (GCN) model for _C. elegans_ connectome graph.\n",
    "    THIS IS A WORK-IN-PROGRESS\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Load the connectome graph\n",
    "        graph_tensors = torch.load(\n",
    "            os.path.join(\n",
    "                ROOT_DIR, \"data\", \"processed\", \"connectome\", \"graph_tensors.pt\"\n",
    "            )\n",
    "        )\n",
    "        graph = Data(**graph_tensors)\n",
    "        assert (\n",
    "            graph.num_nodes == input_size\n",
    "        ), \"Input size must match number of nodes in connectome.\"\n",
    "\n",
    "        # Set attributes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.edge_index = graph.edge_index\n",
    "        self.edge_attr = graph.edge_attr\n",
    "\n",
    "        # Define the GCN layers\n",
    "        self.elec_conv = GCNConv(\n",
    "            in_channels=-1,\n",
    "            out_channels=self.hidden_size,\n",
    "            improved=True,\n",
    "        )  # electrical synapse convolutions,\n",
    "        self.chem_conv = GCNConv(\n",
    "            in_channels=-1,\n",
    "            out_channels=self.hidden_size,\n",
    "            improved=True,\n",
    "        )  # chemical synapse convolutions\n",
    "        self.hid_proj = torch.nn.Linear(\n",
    "            in_features=2 * self.hidden_size, out_features=self.hidden_size\n",
    "        )  # projection to latent space (i.e hidden state)\n",
    "\n",
    "        # Check if first forward call\n",
    "        self.first_forward = True\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.random_projection = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        GCNConv layers:\n",
    "            - input: node features (|V|, F_in), edge indices (2,|E|), edge weights (|E|) (optional)\n",
    "            - output: node features (|V|, F_out)\n",
    "\n",
    "        x: input tensor w/ shape (batch_size, seq_len, input_size)\n",
    "\n",
    "        input_size = 302, which is the number of nodes |V| in the connectome graph of _C. elegans_.\n",
    "        \"\"\"\n",
    "        # Check that the input shape is as expected\n",
    "        batch_size, seq_len, input_size = x.shape\n",
    "        assert input_size == self.input_size, \"Incorrectly shaped input tensor.\"\n",
    "\n",
    "        # Move GCNConv layers to same device as data\n",
    "        if self.first_forward:\n",
    "            self.device = x.device\n",
    "            self.elec_conv = self.elec_conv.to(self.device)\n",
    "            self.chem_conv = self.chem_conv.to(self.device)\n",
    "            self.random_projection = torch.randn(\n",
    "                self.input_size,\n",
    "                seq_len,\n",
    "                requires_grad=False,\n",
    "                dtype=torch.float,\n",
    "                device=self.device,\n",
    "            )  # (hidden_size, seq_len)\n",
    "            self.first_forward = False\n",
    "\n",
    "        # Reshape the input (batch_size, |V| = input_size = 302, seq_len)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "\n",
    "        # Create a list of Data objects.\n",
    "        data_list = [\n",
    "            Data(\n",
    "                x=x[i].to(self.device),\n",
    "                edge_index=self.edge_index.to(self.device),\n",
    "                edge_attr=self.edge_attr.to(self.device),\n",
    "            )\n",
    "            for i in range(x.size(0))\n",
    "        ]\n",
    "\n",
    "        # Convert this list into a Batch object.\n",
    "        batch = Batch.from_data_list(data_list)\n",
    "\n",
    "        # Chemical synapses convolution\n",
    "        elec_weight = batch.edge_attr[:, 0]\n",
    "        elec_hidden = self.elec_conv(\n",
    "            x=batch.x,\n",
    "            edge_index=batch.edge_index,\n",
    "            edge_weight=elec_weight,\n",
    "        )\n",
    "\n",
    "        # Gap junctions convolution\n",
    "        chem_weight = batch.edge_attr[:, 1]\n",
    "        chem_hidden = self.chem_conv(\n",
    "            x=batch.x,\n",
    "            edge_index=batch.edge_index,\n",
    "            edge_weight=chem_weight,\n",
    "        )\n",
    "\n",
    "        # Concatenate into a single latent\n",
    "        hidden = torch.cat([elec_hidden, chem_hidden], dim=-1)\n",
    "\n",
    "        # Transform back to the input space\n",
    "        x = self.hid_proj(hidden).T  # (batch_size, input_size, hidden_size)\n",
    "        x = x.reshape(self.hidden_size, batch_size, self.input_size)\n",
    "        x = x @ self.random_projection  # (hidden_size, batch_size, seq_len)\n",
    "        x = x.reshape(batch_size, seq_len, self.hidden_size)\n",
    "\n",
    "        return x  # (batch_size, seq_len, hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worm-graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
