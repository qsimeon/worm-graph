defaults: 
  - preprocess
  - dataset
  - model
  - visualize
  - train
  - slurm_default
  - _self_
globals:
  random_seed: 0
  use_residual: false
  shuffle: false # whether to shuffle worms
# If you want your primary config to override the values of configs
# from the Defaults List, append _self_ to the end of the Defaults List
hydra:
  mode: MULTIRUN # options: RUN, MULTIRUN
  job:
    chdir: true # important! this changes the working directory to the log directory
  run:
    dir: logs/hydra/${now:%Y_%m_%d_%H_%M_%S}
  sweep:
    dir: logs/hydra/${now:%Y_%m_%d_%H_%M_%S}
    subdir: ${hydra.job.num}
  sweeper:
    params:
      # GLOBALS
      globals.random_seed: 0 #range(0,10,1)
      # TRAIN
      train.epochs: 400 #100, 200, 300, 400
      train.save_freq: 100
      train.seq_len: 99 #range(1,100,8)
      train.k_splits: 2 #2, 5, 7, 10
      train.num_batches: 10 # 1, 2, 3, 4, 5, 6, 7, 8, 9, *10*
      train.tau_in: 1 #range(0,99,9)
      train.tau_out: 1 #range(0,99,9)
      train.train_size: 1000 #1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, *500*, 600, 700, 800, 900, 10000
      train.test_size: 500
      train.learn_rate: 0.01 #0.0001, 0.001, 0.01, 0.1, 1.0
      train.optimizer: SGD #Adam, *SGD*
      train.smooth_data: true 
      train.shuffle: true 
      train.reverse: false 
      # MODEL
      model.type: LinearNN, NetworkLSTM, NeuralTransformer # NeuralCFC
      model.hidden_size: 1024 #8, 16, 32, 64, 128, 512, *1024*
      model.num_layers: 1 #*1*, 2, 3, 4
      # DATASET
      dataset.name: [Kato2015, Nichols2017, Skora2018, Kaplan2020] #Uzel2022, Leifer2023, Flavell2023 